{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g5Nk-MI4-nLz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import kron\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import kron\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import pickle\n",
    "with open(\"list_of_grads1\", \"rb\") as fp:   #Pickling\n",
    "    list_of_grads = pickle.load(fp)\n",
    "\n",
    "list_of_grads = torch.stack(list_of_grads, dim=0)\n",
    "\n",
    "grad_vectors = torch.stack([grad.T.reshape(-1) for grad in list_of_grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([625, 192, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0007,  0.0016,  0.0000,  ...,  0.0044, -0.0017, -0.0002],\n",
       "        [ 0.0016,  0.0045,  0.0000,  ...,  0.0030, -0.0043,  0.0024],\n",
       "        [-0.0015, -0.0033,  0.0000,  ..., -0.0031, -0.0017, -0.0003],\n",
       "        ...,\n",
       "        [ 0.0003, -0.0004,  0.0000,  ..., -0.0003, -0.0010, -0.0001],\n",
       "        [ 0.0122,  0.0169,  0.0000,  ...,  0.0046, -0.0025,  0.0029],\n",
       "        [-0.0028, -0.0018,  0.0000,  ..., -0.0017,  0.0068,  0.0002]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_grads[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list_of_grads[0].shape[0]\n",
    "n = list_of_grads[0].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vectors = torch.stack([grad.T.reshape(-1) for grad in list_of_grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 768\n",
      "torch.Size([625, 147456])\n",
      "matvec\n",
      "36864 1024 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 36 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Operator created\n",
      "Performing SVD...\n",
      "rmatvec\n",
      "matvec\n",
      "36864 1024 36\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "print (m, n)\n",
    "\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "\n",
    "\n",
    "grad_vectors = torch.stack([grad.T.reshape(-1) for grad in list_of_grads])\n",
    "print (grad_vectors.shape)\n",
    "d_grad_vectors = cuda.to_device(grad_vectors)\n",
    "\n",
    "reduce_init_val = 0.0\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def getitem_fmatrices_permuted(d_grad_vectors, p, q):\n",
    "    reduce_init_val = 0.0\n",
    "    for idx in range(d_grad_vectors.shape[0]):\n",
    "        #reduce_init_val+= d_grad_vectors[idx][p]*d_grad_vectors[idx][q]\n",
    "        elem = d_grad_vectors[idx]\n",
    "        reduce_init_val += elem[p] * elem[q]\n",
    "\n",
    "    return reduce_init_val/d_grad_vectors.shape[0]\n",
    "\n",
    "@cuda.jit\n",
    "def matvec_kernel(d_grad_vectors, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*getitem_fmatrices_permuted(d_grad_vectors, (pd)*n +qd, (pn)*n + qn)#d_grad_vector[(pd)*n +qd]*d_grad_vector[(pn)*n + qn] \n",
    "        res[idx] = sum_\n",
    "\n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_grad_vectors, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        pd, pn = divmod(np.int32(idx), n)\n",
    "        for jnd in range(x.size):\n",
    "            jd, jn = divmod(jnd, m)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*getitem_fmatrices_permuted(d_grad_vectors, jd*n +pd, jn*n + pn)# d_grad_vector[(jnd//m)*n +pd]*d_grad_vector[(jnd%m)*n + pn]  #grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n]\n",
    "        res[idx] = sum_\n",
    "\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 1024\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "    print (m**2, threads_per_block, blocks_per_grid)\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_grad_vectors, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    print (res)\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    print (\"rmatvec\")\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 1024\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_grad_vectors, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "\n",
    "linop_v = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n",
    "# Compute SVD\n",
    "print(\"Performing SVD...\", flush=True)\n",
    "v, s, u = svds(linop_v, k = 3, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5209037 , 0.22825046, 0.22730228], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "#np.li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2992203e-03, -2.0863640e-03,  5.2899041e-04, ...,\n",
       "         2.1026177e-05, -7.7487185e-04,  9.5214468e-04],\n",
       "       [-2.0864853e-03, -3.1914932e-03,  6.1957870e-04, ...,\n",
       "         1.9511606e-05, -4.8029647e-04,  6.2608899e-04],\n",
       "       [ 5.2901125e-04,  6.1957882e-04, -3.4995459e-04, ...,\n",
       "         6.6825905e-06,  3.0172875e-04, -2.5753380e-04],\n",
       "       ...,\n",
       "       [ 2.1026184e-05,  1.9511606e-05,  6.6825919e-06, ...,\n",
       "        -2.0335838e-05,  3.5387606e-05,  9.9923554e-06],\n",
       "       [-7.7487197e-04, -4.8029659e-04,  3.0172878e-04, ...,\n",
       "         3.5387602e-05, -3.9137211e-03,  1.3470693e-03],\n",
       "       [ 9.5214479e-04,  6.2608905e-04, -2.5753386e-04, ...,\n",
       "         9.9923554e-06,  1.3470695e-03, -1.2041409e-03]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "is_pos_def(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B1 = cp.asnumpy(s[0] * u[-1, :].reshape(n, n))\n",
    "#C1 = cp.asnumpy(v[:, -1].reshape(m, m))\n",
    "\n",
    "#np.save(\"B1_small_nn.npy\", B1)\n",
    "#np.save(\"C1_small_nn.npy\", C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pos_def(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0\n",
    "\n",
    "С_new = (1 - alpha)*C1  + alpha*np.eye(len(np.diag(C1)))\n",
    "\n",
    "while (not is_pos_def(С_new)):\n",
    "    alpha += 0.01\n",
    "    С_new = (1 - alpha)*C1  + alpha*np.eye(len(np.diag(C1)))\n",
    "\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0\n",
    "\n",
    "B_new = (1 - alpha)*B1  + alpha*np.eye(len(np.diag(B1)))\n",
    "\n",
    "while (not is_pos_def(B_new)):\n",
    "    alpha += 0.05\n",
    "    B_new = (1 - alpha)*B1  + alpha*np.eye(len(np.diag(B1)))\n",
    "\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(С_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(B_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bnew_square = np.linalg.cholesky(B_new)\n",
    "Cnew_square = np.linalg.cholesky(С_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_square = np.linalg.cholesky(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Bnew_square.npy\", Bnew_square)\n",
    "np.save(\"Cnew_square.npy\", Cnew_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = np.load(\"B1_small_nn.npy\")\n",
    "C1 = np.load(\"C1_small_nn.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147456, 147456)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 = np.kron(B1, C1)\n",
    "matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([625, 147456])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import kron\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import pickle\n",
    "with open(\"list_of_grads\", \"rb\") as fp:   #Pickling\n",
    "    list_of_grads = pickle.load(fp)\n",
    "\n",
    "list_of_grads = torch.stack(list_of_grads, dim=0)\n",
    "\n",
    "grad_vectors = torch.stack([grad.T.reshape(-1) for grad in list_of_grads])\n",
    "\n",
    "import numpy as np\n",
    "matrix2 = np.zeros((147456, 147456), dtype=float)\n",
    "for ind, vector in enumerate(grad_vectors):\n",
    "    print (ind, flush = True)\n",
    "    for i, ielem in enumerate(vector):\n",
    "        if (i%500 == 0):\n",
    "            print (i,  flush = True)\n",
    "        for j in range(i, len(vector)):\n",
    "            matrix2[i][j] += ielem*jelem\n",
    "            matrix2[j][i] += ielem*jelem\n",
    "\n",
    "np.save(matrix2, \"matrix2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-video_vika]",
   "language": "python",
   "name": "conda-env-.mlspace-video_vika-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
