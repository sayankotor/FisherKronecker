2025-04-24 15:32:20,783 - INFO - Loading model: unsloth/llama-2-7b
[2025-04-24 15:32:26,167] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/jovyan/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Loading checkpoint shards:   0%|                                                               | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████████████▎                                    | 1/3 [00:00<00:01,  1.53it/s]Loading checkpoint shards:  67%|████████████████████████████████████▋                  | 2/3 [00:01<00:00,  1.53it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.61it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.59it/s]
2025-04-24 15:32:30,010 - INFO - Model loaded with dtype torch.bfloat16
2025-04-24 15:33:08,782 - INFO - Model moved to cuda:0
2025-04-24 15:33:08,782 - INFO - Found 225 linear layers to potentially compress.
sensitivity_dict {'lm_head': 1, 'model.layers.31.mlp.gate_proj': 1, 'model.layers.31.mlp.up_proj': 1, 'model.layers.31.mlp.down_proj': 1, 'model.layers.31.self_attn.q_proj': 0.5, 'model.layers.31.self_attn.k_proj': 0.5, 'model.layers.31.self_attn.v_proj': 1, 'model.layers.31.self_attn.o_proj': 0.6, 'model.layers.30.mlp.gate_proj': 1, 'model.layers.30.mlp.up_proj': 1, 'model.layers.30.mlp.down_proj': 1, 'model.layers.30.self_attn.q_proj': 0.7, 'model.layers.30.self_attn.k_proj': 0.8, 'model.layers.30.self_attn.v_proj': 1, 'model.layers.30.self_attn.o_proj': 0.8, 'model.layers.29.mlp.gate_proj': 1, 'model.layers.29.mlp.up_proj': 1, 'model.layers.29.mlp.down_proj': 1, 'model.layers.29.self_attn.q_proj': 0.4, 'model.layers.29.self_attn.k_proj': 0.6, 'model.layers.29.self_attn.v_proj': 1, 'model.layers.29.self_attn.o_proj': 0.7, 'model.layers.28.mlp.gate_proj': 0.9, 'model.layers.28.mlp.up_proj': 1, 'model.layers.28.mlp.down_proj': 1, 'model.layers.28.self_attn.q_proj': 0.6, 'model.layers.28.self_attn.k_proj': 0.7, 'model.layers.28.self_attn.v_proj': 1, 'model.layers.28.self_attn.o_proj': 0.7, 'model.layers.27.mlp.gate_proj': 1, 'model.layers.27.mlp.up_proj': 1, 'model.layers.27.mlp.down_proj': 1, 'model.layers.27.self_attn.q_proj': 0.4, 'model.layers.27.self_attn.k_proj': 0.3, 'model.layers.27.self_attn.v_proj': 0.9, 'model.layers.27.self_attn.o_proj': 0.8, 'model.layers.26.mlp.gate_proj': 1, 'model.layers.26.mlp.up_proj': 1, 'model.layers.26.mlp.down_proj': 1, 'model.layers.26.self_attn.q_proj': 0.5, 'model.layers.26.self_attn.k_proj': 0.4, 'model.layers.26.self_attn.v_proj': 1, 'model.layers.26.self_attn.o_proj': 0.6, 'model.layers.25.mlp.gate_proj': 0.9, 'model.layers.25.mlp.up_proj': 0.9, 'model.layers.25.mlp.down_proj': 1, 'model.layers.25.self_attn.q_proj': 0.8, 'model.layers.25.self_attn.k_proj': 1, 'model.layers.25.self_attn.v_proj': 1, 'model.layers.25.self_attn.o_proj': 0.7, 'model.layers.24.mlp.gate_proj': 0.7, 'model.layers.24.mlp.up_proj': 0.7, 'model.layers.24.mlp.down_proj': 0.9, 'model.layers.24.self_attn.q_proj': 0.1, 'model.layers.24.self_attn.k_proj': 0.1, 'model.layers.24.self_attn.v_proj': 0.7, 'model.layers.24.self_attn.o_proj': 0.4, 'model.layers.23.mlp.gate_proj': 1, 'model.layers.23.mlp.up_proj': 0.9, 'model.layers.23.mlp.down_proj': 1, 'model.layers.23.self_attn.q_proj': 0.5, 'model.layers.23.self_attn.k_proj': 0.5, 'model.layers.23.self_attn.v_proj': 0.8, 'model.layers.23.self_attn.o_proj': 0.8, 'model.layers.22.mlp.gate_proj': 1, 'model.layers.22.mlp.up_proj': 1, 'model.layers.22.mlp.down_proj': 1, 'model.layers.22.self_attn.q_proj': 0.7, 'model.layers.22.self_attn.k_proj': 0.6, 'model.layers.22.self_attn.v_proj': 1, 'model.layers.22.self_attn.o_proj': 0.8, 'model.layers.21.mlp.gate_proj': 1, 'model.layers.21.mlp.up_proj': 1, 'model.layers.21.mlp.down_proj': 1, 'model.layers.21.self_attn.q_proj': 0.6, 'model.layers.21.self_attn.k_proj': 0.5, 'model.layers.21.self_attn.v_proj': 0.7, 'model.layers.21.self_attn.o_proj': 0.9, 'model.layers.20.mlp.gate_proj': 1, 'model.layers.20.mlp.up_proj': 1, 'model.layers.20.mlp.down_proj': 1, 'model.layers.20.self_attn.q_proj': 0.2, 'model.layers.20.self_attn.k_proj': 0.1, 'model.layers.20.self_attn.v_proj': 0.8, 'model.layers.20.self_attn.o_proj': 0.7, 'model.layers.19.mlp.gate_proj': 1, 'model.layers.19.mlp.up_proj': 1, 'model.layers.19.mlp.down_proj': 1, 'model.layers.19.self_attn.q_proj': 0.7, 'model.layers.19.self_attn.k_proj': 0.6, 'model.layers.19.self_attn.v_proj': 1, 'model.layers.19.self_attn.o_proj': 0.9, 'model.layers.18.mlp.gate_proj': 1, 'model.layers.18.mlp.up_proj': 1, 'model.layers.18.mlp.down_proj': 1, 'model.layers.18.self_attn.q_proj': 0.5, 'model.layers.18.self_attn.k_proj': 0.7, 'model.layers.18.self_attn.v_proj': 1, 'model.layers.18.self_attn.o_proj': 0.8, 'model.layers.17.mlp.gate_proj': 1, 'model.layers.17.mlp.up_proj': 1, 'model.layers.17.mlp.down_proj': 1, 'model.layers.17.self_attn.q_proj': 0.6, 'model.layers.17.self_attn.k_proj': 0.5, 'model.layers.17.self_attn.v_proj': 1, 'model.layers.17.self_attn.o_proj': 1, 'model.layers.16.mlp.gate_proj': 1, 'model.layers.16.mlp.up_proj': 1, 'model.layers.16.mlp.down_proj': 1, 'model.layers.16.self_attn.q_proj': 0.4, 'model.layers.16.self_attn.k_proj': 0.3, 'model.layers.16.self_attn.v_proj': 1, 'model.layers.16.self_attn.o_proj': 0.9, 'model.layers.15.mlp.gate_proj': 1, 'model.layers.15.mlp.up_proj': 1, 'model.layers.15.mlp.down_proj': 1, 'model.layers.15.self_attn.q_proj': 0.5, 'model.layers.15.self_attn.k_proj': 0.7, 'model.layers.15.self_attn.v_proj': 1, 'model.layers.15.self_attn.o_proj': 1, 'model.layers.14.mlp.gate_proj': 1, 'model.layers.14.mlp.up_proj': 1, 'model.layers.14.mlp.down_proj': 1, 'model.layers.14.self_attn.q_proj': 0.5, 'model.layers.14.self_attn.k_proj': 0.6, 'model.layers.14.self_attn.v_proj': 1, 'model.layers.14.self_attn.o_proj': 1, 'model.layers.13.mlp.gate_proj': 1, 'model.layers.13.mlp.up_proj': 1, 'model.layers.13.mlp.down_proj': 1, 'model.layers.13.self_attn.q_proj': 0.6, 'model.layers.13.self_attn.k_proj': 0.7, 'model.layers.13.self_attn.v_proj': 1, 'model.layers.13.self_attn.o_proj': 0.8, 'model.layers.12.mlp.gate_proj': 0.5, 'model.layers.12.mlp.up_proj': 0.6, 'model.layers.12.mlp.down_proj': 0.9, 'model.layers.12.self_attn.q_proj': 0.3, 'model.layers.12.self_attn.k_proj': 0.5, 'model.layers.12.self_attn.v_proj': 1, 'model.layers.12.self_attn.o_proj': 0.7, 'model.layers.11.mlp.gate_proj': 1, 'model.layers.11.mlp.up_proj': 1, 'model.layers.11.mlp.down_proj': 1, 'model.layers.11.self_attn.q_proj': 0.2, 'model.layers.11.self_attn.k_proj': 0.2, 'model.layers.11.self_attn.v_proj': 1, 'model.layers.11.self_attn.o_proj': 0.8, 'model.layers.10.mlp.gate_proj': 1, 'model.layers.10.mlp.up_proj': 1, 'model.layers.10.mlp.down_proj': 1, 'model.layers.10.self_attn.q_proj': 0.5, 'model.layers.10.self_attn.k_proj': 0.6, 'model.layers.10.self_attn.v_proj': 1, 'model.layers.10.self_attn.o_proj': 1, 'model.layers.9.mlp.gate_proj': 1, 'model.layers.9.mlp.up_proj': 1, 'model.layers.9.mlp.down_proj': 1, 'model.layers.9.self_attn.q_proj': 0.5, 'model.layers.9.self_attn.k_proj': 0.5, 'model.layers.9.self_attn.v_proj': 1, 'model.layers.9.self_attn.o_proj': 0.9, 'model.layers.8.mlp.gate_proj': 1, 'model.layers.8.mlp.up_proj': 1, 'model.layers.8.mlp.down_proj': 1, 'model.layers.8.self_attn.q_proj': 0.5, 'model.layers.8.self_attn.k_proj': 0.5, 'model.layers.8.self_attn.v_proj': 1, 'model.layers.8.self_attn.o_proj': 0.7, 'model.layers.7.mlp.gate_proj': 0.9, 'model.layers.7.mlp.up_proj': 1, 'model.layers.7.mlp.down_proj': 1, 'model.layers.7.self_attn.q_proj': 0.5, 'model.layers.7.self_attn.k_proj': 0.4, 'model.layers.7.self_attn.v_proj': 1, 'model.layers.7.self_attn.o_proj': 0.7, 'model.layers.6.mlp.gate_proj': 1, 'model.layers.6.mlp.up_proj': 1, 'model.layers.6.mlp.down_proj': 1, 'model.layers.6.self_attn.q_proj': 0.3, 'model.layers.6.self_attn.k_proj': 0.3, 'model.layers.6.self_attn.v_proj': 1, 'model.layers.6.self_attn.o_proj': 0.8, 'model.layers.5.mlp.gate_proj': 1, 'model.layers.5.mlp.up_proj': 1, 'model.layers.5.mlp.down_proj': 1, 'model.layers.5.self_attn.q_proj': 0.2, 'model.layers.5.self_attn.k_proj': 0.7, 'model.layers.5.self_attn.v_proj': 1, 'model.layers.5.self_attn.o_proj': 0.5, 'model.layers.4.mlp.gate_proj': 0.9, 'model.layers.4.mlp.up_proj': 1, 'model.layers.4.mlp.down_proj': 0.9, 'model.layers.4.self_attn.q_proj': 0.4, 'model.layers.4.self_attn.k_proj': 0.3, 'model.layers.4.self_attn.v_proj': 1, 'model.layers.4.self_attn.o_proj': 0.7, 'model.layers.3.mlp.gate_proj': 0.9, 'model.layers.3.mlp.up_proj': 1, 'model.layers.3.mlp.down_proj': 0.9, 'model.layers.3.self_attn.q_proj': 0.4, 'model.layers.3.self_attn.k_proj': 0.2, 'model.layers.3.self_attn.v_proj': 1, 'model.layers.3.self_attn.o_proj': 0.5, 'model.layers.2.mlp.gate_proj': 0.9, 'model.layers.2.mlp.up_proj': 1, 'model.layers.2.mlp.down_proj': 1, 'model.layers.2.self_attn.q_proj': 0.5, 'model.layers.2.self_attn.k_proj': 0.4, 'model.layers.2.self_attn.v_proj': 0.9, 'model.layers.2.self_attn.o_proj': 0.8, 'model.layers.1.mlp.gate_proj': 0.6, 'model.layers.1.mlp.up_proj': 0.7, 'model.layers.1.mlp.down_proj': 1, 'model.layers.1.self_attn.q_proj': 0.1, 'model.layers.1.self_attn.k_proj': 0.1, 'model.layers.1.self_attn.v_proj': 0.5, 'model.layers.1.self_attn.o_proj': 0.4, 'model.layers.0.mlp.gate_proj': 0.4, 'model.layers.0.mlp.up_proj': 0.4, 'model.layers.0.mlp.down_proj': 0.6, 'model.layers.0.self_attn.q_proj': 0.1, 'model.layers.0.self_attn.k_proj': 0.1, 'model.layers.0.self_attn.v_proj': 0.3, 'model.layers.0.self_attn.o_proj': 0.1}
Compressing Layers:   0%|                                                                    | 0/225 [00:00<?, ?it/s]2025-04-24 15:33:08,784 - INFO - Layer: model.layers.0.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 15:33:08,786 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_q_proj.safetensors
2025-04-24 15:33:08,786 - INFO - exists: True
2025-04-24 15:33:08,787 - INFO - factorize_layer_kron_svd
2025-04-24 15:33:09,923 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:33:11,163 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:33:12,361 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:33:13,604 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_q_proj.safetensors True
Layer: model.layers.0.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [2.2687174e-04 1.1153770e-04 8.2521896e-05 7.4318777e-05 5.9026988e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 15:33:34,724 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 15:33:34,724 - INFO - Replacing 'model.layers.0.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:   0%|▎                                                         | 1/225 [00:25<1:36:50, 25.94s/it]2025-04-24 15:33:34,724 - INFO - Layer: model.layers.0.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 15:33:34,725 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_k_proj.safetensors
2025-04-24 15:33:34,725 - INFO - exists: True
2025-04-24 15:33:34,731 - INFO - factorize_layer_kron_svd
2025-04-24 15:33:35,916 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:33:37,189 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:33:38,277 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:33:39,508 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_k_proj.safetensors True
Layer: model.layers.0.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [4.0663555e-04 1.7498253e-04 9.6088203e-05 8.4267405e-05 5.7348043e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 15:34:01,526 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 15:34:01,527 - INFO - Replacing 'model.layers.0.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:   1%|▌                                                         | 2/225 [00:52<1:38:17, 26.45s/it]2025-04-24 15:34:01,527 - INFO - Layer: model.layers.0.self_attn.v_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:34:01,528 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_v_proj.safetensors
2025-04-24 15:34:01,528 - INFO - exists: True
2025-04-24 15:34:01,535 - INFO - factorize_layer_kron_svd
2025-04-24 15:34:02,788 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:34:04,095 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:34:05,207 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:34:06,458 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_v_proj.safetensors True
Layer: model.layers.0.self_attn.v_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.5722213e-04 1.7444632e-04 6.2943713e-05 2.4491763e-05 1.8496392e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (616,4096), (4096,616)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)
2025-04-24 15:34:26,366 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)')
2025-04-24 15:34:26,366 - INFO - Replacing 'model.layers.0.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:   1%|▊                                                         | 3/225 [01:17<1:35:08, 25.71s/it]2025-04-24 15:34:26,367 - INFO - Layer: model.layers.0.self_attn.o_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 15:34:26,371 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_o_proj.safetensors
2025-04-24 15:34:26,371 - INFO - exists: True
2025-04-24 15:34:26,378 - INFO - factorize_layer_kron_svd
2025-04-24 15:34:27,763 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:34:29,047 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:34:30,138 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:34:31,399 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_self_attn_o_proj.safetensors True
Layer: model.layers.0.self_attn.o_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.2752346e-04 1.1654778e-04 7.8801531e-05 2.0858788e-05 1.5365338e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 15:34:53,259 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 15:34:53,259 - INFO - Replacing 'model.layers.0.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:   2%|█                                                         | 4/225 [01:44<1:36:25, 26.18s/it]2025-04-24 15:34:53,259 - INFO - Layer: model.layers.0.mlp.gate_proj | Ratio: 0.400 -> Target Rank: 1200 (Align: 8)
2025-04-24 15:34:53,260 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_gate_proj.safetensors
2025-04-24 15:34:53,260 - INFO - exists: True
2025-04-24 15:34:53,267 - INFO - factorize_layer_kron_svd
2025-04-24 15:34:54,578 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:34:55,828 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:34:57,091 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 15:34:59,140 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:35:02,454 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_gate_proj.safetensors True
Layer: model.layers.0.mlp.gate_proj | Ratio: 0.400 -> Target Rank: 1200 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [1.62766388e-04 8.60974760e-05 3.33992612e-05 1.43659045e-05
 1.18921280e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1200,4096), (11008,1200)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1200, bias=False)
  (1): Linear(in_features=1200, out_features=11008, bias=False)
)
2025-04-24 15:35:49,968 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1200, bias=False)
  (1): Linear(in_features=1200, out_features=11008, bias=False)
)')
2025-04-24 15:35:49,969 - INFO - Replacing 'model.layers.0.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:   2%|█▎                                                        | 5/225 [02:41<2:16:21, 37.19s/it]2025-04-24 15:35:49,970 - INFO - Layer: model.layers.0.mlp.up_proj | Ratio: 0.400 -> Target Rank: 1200 (Align: 8)
2025-04-24 15:35:49,972 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_up_proj.safetensors
2025-04-24 15:35:49,972 - INFO - exists: True
2025-04-24 15:35:50,010 - INFO - factorize_layer_kron_svd
2025-04-24 15:35:51,327 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:35:52,513 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:35:53,785 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 15:35:55,901 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:35:59,025 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_up_proj.safetensors True
Layer: model.layers.0.mlp.up_proj | Ratio: 0.400 -> Target Rank: 1200 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [2.1327082e-04 7.0809328e-05 5.0785864e-05 3.5060402e-05 2.8840335e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1200,4096), (11008,1200)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1200, bias=False)
  (1): Linear(in_features=1200, out_features=11008, bias=False)
)
2025-04-24 15:36:53,805 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1200, bias=False)
  (1): Linear(in_features=1200, out_features=11008, bias=False)
)')
2025-04-24 15:36:53,805 - INFO - Replacing 'model.layers.0.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:   3%|█▌                                                        | 6/225 [03:45<2:48:48, 46.25s/it]2025-04-24 15:36:53,805 - INFO - Layer: model.layers.0.mlp.down_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
2025-04-24 15:36:53,807 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_down_proj.safetensors
2025-04-24 15:36:53,807 - INFO - exists: True
2025-04-24 15:36:53,844 - INFO - factorize_layer_kron_svd
2025-04-24 15:36:56,270 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:36:59,108 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:37:02,197 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 15:37:03,326 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:37:04,556 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_0_mlp_down_proj.safetensors True
Layer: model.layers.0.mlp.down_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x11008)...
  SVD complete. Singular values (top 5): [0.00360306 0.00047922 0.00020495 0.00012077 0.00011648]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1792,11008), (4096,1792)
factorized_sequential Sequential(
  (0): Linear(in_features=11008, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=4096, bias=False)
)
2025-04-24 15:37:58,104 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=11008, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=4096, bias=False)
)')
2025-04-24 15:37:58,105 - INFO - Replacing 'model.layers.0.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)
Compressing Layers:   3%|█▊                                                        | 7/225 [04:49<3:09:28, 52.15s/it]2025-04-24 15:37:58,105 - INFO - Layer: model.layers.1.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 15:37:58,108 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_q_proj.safetensors
2025-04-24 15:37:58,108 - INFO - exists: True
2025-04-24 15:37:58,142 - INFO - factorize_layer_kron_svd
2025-04-24 15:37:59,367 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:00,585 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:38:01,692 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:02,932 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_q_proj.safetensors True
Layer: model.layers.1.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.43146583e-04 1.54433030e-04 1.13500086e-04 9.13513068e-05
 6.67410131e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 15:38:24,854 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 15:38:24,854 - INFO - Replacing 'model.layers.1.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:   4%|██                                                        | 8/225 [05:16<2:39:21, 44.06s/it]2025-04-24 15:38:24,855 - INFO - Layer: model.layers.1.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 15:38:24,856 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_k_proj.safetensors
2025-04-24 15:38:24,856 - INFO - exists: True
2025-04-24 15:38:24,866 - INFO - factorize_layer_kron_svd
2025-04-24 15:38:26,097 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:27,336 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:38:28,427 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:29,617 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_k_proj.safetensors True
Layer: model.layers.1.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.0266426e-04 1.2620199e-04 8.1441554e-05 8.0446305e-05 6.2994521e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 15:38:51,655 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 15:38:51,655 - INFO - Replacing 'model.layers.1.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:   4%|██▎                                                       | 9/225 [05:42<2:19:12, 38.67s/it]2025-04-24 15:38:51,655 - INFO - Layer: model.layers.1.self_attn.v_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:38:51,656 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_v_proj.safetensors
2025-04-24 15:38:51,656 - INFO - exists: True
2025-04-24 15:38:51,685 - INFO - factorize_layer_kron_svd
2025-04-24 15:38:53,109 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:54,323 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:38:55,387 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:38:56,551 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:38:57,757 - INFO -   Factor is positive definite (alpha=1.00e-03)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_v_proj.safetensors True
Layer: model.layers.1.self_attn.v_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.3037748e-03 7.5241107e-05 4.6876405e-05 2.5140183e-05 2.1678547e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:39:23,039 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:39:23,040 - INFO - Replacing 'model.layers.1.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:   4%|██▌                                                      | 10/225 [06:14<2:10:30, 36.42s/it]2025-04-24 15:39:23,040 - INFO - Layer: model.layers.1.self_attn.o_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:39:23,042 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_o_proj.safetensors
2025-04-24 15:39:23,042 - INFO - exists: True
2025-04-24 15:39:23,070 - INFO - factorize_layer_kron_svd
2025-04-24 15:39:24,361 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:39:25,413 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:39:26,452 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:39:27,542 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:39:28,581 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:39:29,777 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 15:39:30,835 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:39:31,886 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:39:32,941 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:39:34,003 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:39:35,059 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:39:36,235 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_self_attn_o_proj.safetensors True
Layer: model.layers.1.self_attn.o_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [3.8689141e-06 3.1313011e-06 2.2400243e-06 2.0631737e-06 2.0335660e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 15:39:58,225 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 15:39:58,225 - INFO - Replacing 'model.layers.1.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:   5%|██▊                                                      | 11/225 [06:49<2:08:32, 36.04s/it]2025-04-24 15:39:58,225 - INFO - Layer: model.layers.1.mlp.gate_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
2025-04-24 15:39:58,226 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_mlp_gate_proj.safetensors
2025-04-24 15:39:58,226 - INFO - exists: True
2025-04-24 15:39:58,291 - INFO - factorize_layer_kron_svd
2025-04-24 15:40:00,347 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:40:01,551 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:40:02,773 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 15:40:05,562 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_mlp_gate_proj.safetensors True
Layer: model.layers.1.mlp.gate_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [2.5756116e-04 2.0590835e-05 1.7721311e-05 1.4897599e-05 1.3294678e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1792,4096), (11008,1792)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=11008, bias=False)
)
2025-04-24 15:40:51,932 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=11008, bias=False)
)')
2025-04-24 15:40:51,932 - INFO - Replacing 'model.layers.1.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:   5%|███                                                      | 12/225 [07:43<2:27:01, 41.42s/it]2025-04-24 15:40:51,932 - INFO - Layer: model.layers.1.mlp.up_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
2025-04-24 15:40:51,935 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_mlp_up_proj.safetensors
2025-04-24 15:40:51,935 - INFO - exists: True
2025-04-24 15:40:52,022 - INFO - factorize_layer_kron_svd
2025-04-24 15:40:54,253 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:40:55,347 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:40:56,395 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:40:57,467 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:40:58,515 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:40:59,704 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 15:41:01,332 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:41:03,198 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:41:05,014 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:41:06,867 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:41:08,894 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:41:11,922 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_1_mlp_up_proj.safetensors True
Layer: model.layers.1.mlp.up_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [7.3754545e-06 4.6838541e-06 4.6829132e-06 4.5144598e-06 4.4679359e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)
2025-04-24 15:41:58,443 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)')
2025-04-24 15:41:58,443 - INFO - Replacing 'model.layers.1.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:   6%|███▎                                                     | 13/225 [08:49<2:53:11, 49.02s/it]2025-04-24 15:41:58,444 - INFO - Skipping layer model.layers.1.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:41:58,444 - INFO - Layer: model.layers.2.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:41:58,446 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_q_proj.safetensors
2025-04-24 15:41:58,447 - INFO - exists: True
2025-04-24 15:41:58,478 - INFO - factorize_layer_kron_svd
2025-04-24 15:41:59,851 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:01,050 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:42:02,104 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:03,290 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_q_proj.safetensors True
Layer: model.layers.2.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.73210399e-03 1.81858835e-04 1.07483946e-04 9.33050178e-05
 6.15373719e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:42:25,960 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:42:25,961 - INFO - Replacing 'model.layers.2.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:   7%|███▊                                                     | 15/225 [09:17<1:54:18, 32.66s/it]2025-04-24 15:42:25,961 - INFO - Layer: model.layers.2.self_attn.k_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:42:25,962 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_k_proj.safetensors
2025-04-24 15:42:25,962 - INFO - exists: True
2025-04-24 15:42:25,981 - INFO - factorize_layer_kron_svd
2025-04-24 15:42:27,337 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:28,572 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:42:29,667 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:30,899 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_k_proj.safetensors True
Layer: model.layers.2.self_attn.k_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.9114357e-03 1.4245549e-04 1.0586168e-04 7.6874050e-05 6.1492065e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 15:42:53,193 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 15:42:53,193 - INFO - Replacing 'model.layers.2.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:   7%|████                                                     | 16/225 [09:44<1:49:03, 31.31s/it]2025-04-24 15:42:53,193 - INFO - Layer: model.layers.2.self_attn.v_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 15:42:53,194 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_v_proj.safetensors
2025-04-24 15:42:53,194 - INFO - exists: True
2025-04-24 15:42:53,214 - INFO - factorize_layer_kron_svd
2025-04-24 15:42:55,623 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:56,831 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:42:57,875 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:42:59,060 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_v_proj.safetensors True
Layer: model.layers.2.self_attn.v_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.9212312e-04 4.9278322e-05 1.8895498e-05 1.5295736e-05 1.3105318e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1848,4096), (4096,1848)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)
2025-04-24 15:43:21,939 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)')
2025-04-24 15:43:21,940 - INFO - Replacing 'model.layers.2.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:   8%|████▎                                                    | 17/225 [10:13<1:46:12, 30.64s/it]2025-04-24 15:43:21,940 - INFO - Layer: model.layers.2.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 15:43:21,942 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_o_proj.safetensors
2025-04-24 15:43:21,942 - INFO - exists: True
2025-04-24 15:43:21,964 - INFO - factorize_layer_kron_svd
2025-04-24 15:43:23,228 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:43:24,309 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:43:25,351 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:43:26,416 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:43:27,462 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:43:28,646 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 15:43:29,692 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:43:30,739 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:43:31,810 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:43:32,878 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:43:33,948 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:43:35,164 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_self_attn_o_proj.safetensors True
Layer: model.layers.2.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.0198013e-06 2.9007442e-06 2.8069910e-06 2.7654496e-06 2.7077651e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 15:43:58,118 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 15:43:58,118 - INFO - Replacing 'model.layers.2.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:   8%|████▌                                                    | 18/225 [10:49<1:50:54, 32.15s/it]2025-04-24 15:43:58,118 - INFO - Layer: model.layers.2.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:43:58,120 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_mlp_gate_proj.safetensors
2025-04-24 15:43:58,121 - INFO - exists: True
2025-04-24 15:43:58,181 - INFO - factorize_layer_kron_svd
2025-04-24 15:44:00,173 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:44:01,230 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:44:02,277 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:44:03,343 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:44:04,411 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:44:05,590 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 15:44:07,187 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:44:08,979 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:44:10,753 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:44:12,574 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:44:15,003 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:44:17,976 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_2_mlp_gate_proj.safetensors True
Layer: model.layers.2.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [1.0618421e-05 7.9699194e-06 7.3974884e-06 7.0551118e-06 6.9922344e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,4096), (11008,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)
2025-04-24 15:45:09,437 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)')
2025-04-24 15:45:09,437 - INFO - Replacing 'model.layers.2.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:   8%|████▊                                                    | 19/225 [12:00<2:28:03, 43.13s/it]2025-04-24 15:45:09,438 - INFO - Skipping layer model.layers.2.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,438 - INFO - Skipping layer model.layers.2.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,438 - INFO - Layer: model.layers.3.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:45:09,439 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_q_proj.safetensors
2025-04-24 15:45:09,439 - INFO - exists: False
2025-04-24 15:45:09,439 - WARNING - Skipping layer model.layers.3.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_q_proj.safetensors
2025-04-24 15:45:09,439 - INFO - Layer: model.layers.3.self_attn.k_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
2025-04-24 15:45:09,439 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_k_proj.safetensors
2025-04-24 15:45:09,439 - INFO - exists: False
2025-04-24 15:45:09,439 - WARNING - Skipping layer model.layers.3.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_k_proj.safetensors
2025-04-24 15:45:09,439 - INFO - Skipping layer model.layers.3.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,440 - INFO - Layer: model.layers.3.self_attn.o_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,440 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_o_proj.safetensors
2025-04-24 15:45:09,440 - INFO - exists: False
2025-04-24 15:45:09,440 - WARNING - Skipping layer model.layers.3.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_o_proj.safetensors
2025-04-24 15:45:09,440 - INFO - Layer: model.layers.3.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:45:09,441 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors
2025-04-24 15:45:09,441 - INFO - exists: False
2025-04-24 15:45:09,441 - WARNING - Skipping layer model.layers.3.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors
2025-04-24 15:45:09,441 - INFO - Skipping layer model.layers.3.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,441 - INFO - Layer: model.layers.3.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:45:09,442 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_down_proj.safetensors
2025-04-24 15:45:09,442 - INFO - exists: False
2025-04-24 15:45:09,442 - WARNING - Skipping layer model.layers.3.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_down_proj.safetensors
2025-04-24 15:45:09,442 - INFO - Layer: model.layers.4.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:45:09,442 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_q_proj.safetensors
2025-04-24 15:45:09,442 - INFO - exists: False
2025-04-24 15:45:09,442 - WARNING - Skipping layer model.layers.4.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_q_proj.safetensors
2025-04-24 15:45:09,442 - INFO - Layer: model.layers.4.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:45:09,442 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_k_proj.safetensors
2025-04-24 15:45:09,443 - INFO - exists: False
2025-04-24 15:45:09,443 - WARNING - Skipping layer model.layers.4.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_k_proj.safetensors
2025-04-24 15:45:09,443 - INFO - Skipping layer model.layers.4.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,443 - INFO - Layer: model.layers.4.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:45:09,443 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_o_proj.safetensors
2025-04-24 15:45:09,443 - INFO - exists: False
2025-04-24 15:45:09,443 - WARNING - Skipping layer model.layers.4.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_o_proj.safetensors
2025-04-24 15:45:09,443 - INFO - Layer: model.layers.4.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:45:09,443 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors
2025-04-24 15:45:09,443 - INFO - exists: False
2025-04-24 15:45:09,444 - WARNING - Skipping layer model.layers.4.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors
2025-04-24 15:45:09,444 - INFO - Skipping layer model.layers.4.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,444 - INFO - Layer: model.layers.4.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:45:09,444 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors
2025-04-24 15:45:09,444 - INFO - exists: False
2025-04-24 15:45:09,444 - WARNING - Skipping layer model.layers.4.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors
2025-04-24 15:45:09,444 - INFO - Layer: model.layers.5.self_attn.q_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
2025-04-24 15:45:09,444 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_q_proj.safetensors
2025-04-24 15:45:09,444 - INFO - exists: False
2025-04-24 15:45:09,444 - WARNING - Skipping layer model.layers.5.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_q_proj.safetensors
2025-04-24 15:45:09,444 - INFO - Layer: model.layers.5.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:45:09,445 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_k_proj.safetensors
2025-04-24 15:45:09,445 - INFO - exists: False
2025-04-24 15:45:09,445 - WARNING - Skipping layer model.layers.5.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_k_proj.safetensors
2025-04-24 15:45:09,445 - INFO - Skipping layer model.layers.5.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,445 - INFO - Layer: model.layers.5.self_attn.o_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,445 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_o_proj.safetensors
2025-04-24 15:45:09,445 - INFO - exists: False
2025-04-24 15:45:09,445 - WARNING - Skipping layer model.layers.5.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_o_proj.safetensors
2025-04-24 15:45:09,445 - INFO - Skipping layer model.layers.5.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,445 - INFO - Skipping layer model.layers.5.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,445 - INFO - Skipping layer model.layers.5.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,445 - INFO - Layer: model.layers.6.self_attn.q_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:45:09,446 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_q_proj.safetensors
2025-04-24 15:45:09,446 - INFO - exists: False
2025-04-24 15:45:09,446 - WARNING - Skipping layer model.layers.6.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_q_proj.safetensors
2025-04-24 15:45:09,446 - INFO - Layer: model.layers.6.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:45:09,447 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_k_proj.safetensors
2025-04-24 15:45:09,447 - INFO - exists: False
2025-04-24 15:45:09,447 - WARNING - Skipping layer model.layers.6.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_k_proj.safetensors
2025-04-24 15:45:09,447 - INFO - Skipping layer model.layers.6.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,447 - INFO - Layer: model.layers.6.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 15:45:09,447 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_o_proj.safetensors
2025-04-24 15:45:09,447 - INFO - exists: False
2025-04-24 15:45:09,447 - WARNING - Skipping layer model.layers.6.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_o_proj.safetensors
2025-04-24 15:45:09,447 - INFO - Skipping layer model.layers.6.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,447 - INFO - Skipping layer model.layers.6.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,447 - INFO - Skipping layer model.layers.6.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,447 - INFO - Layer: model.layers.7.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,447 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_q_proj.safetensors
2025-04-24 15:45:09,447 - INFO - exists: False
2025-04-24 15:45:09,448 - WARNING - Skipping layer model.layers.7.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_q_proj.safetensors
2025-04-24 15:45:09,448 - INFO - Layer: model.layers.7.self_attn.k_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:45:09,448 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_k_proj.safetensors
2025-04-24 15:45:09,448 - INFO - exists: False
2025-04-24 15:45:09,448 - WARNING - Skipping layer model.layers.7.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_k_proj.safetensors
2025-04-24 15:45:09,448 - INFO - Skipping layer model.layers.7.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,448 - INFO - Layer: model.layers.7.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:45:09,448 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_o_proj.safetensors
2025-04-24 15:45:09,448 - INFO - exists: False
2025-04-24 15:45:09,448 - WARNING - Skipping layer model.layers.7.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_o_proj.safetensors
2025-04-24 15:45:09,448 - INFO - Layer: model.layers.7.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:45:09,449 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_mlp_gate_proj.safetensors
2025-04-24 15:45:09,449 - INFO - exists: False
2025-04-24 15:45:09,449 - WARNING - Skipping layer model.layers.7.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_mlp_gate_proj.safetensors
2025-04-24 15:45:09,449 - INFO - Skipping layer model.layers.7.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,449 - INFO - Skipping layer model.layers.7.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,449 - INFO - Layer: model.layers.8.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,450 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_q_proj.safetensors
2025-04-24 15:45:09,450 - INFO - exists: False
2025-04-24 15:45:09,450 - WARNING - Skipping layer model.layers.8.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_q_proj.safetensors
2025-04-24 15:45:09,450 - INFO - Layer: model.layers.8.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,450 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_k_proj.safetensors
2025-04-24 15:45:09,450 - INFO - exists: False
2025-04-24 15:45:09,450 - WARNING - Skipping layer model.layers.8.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_k_proj.safetensors
2025-04-24 15:45:09,450 - INFO - Skipping layer model.layers.8.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,450 - INFO - Layer: model.layers.8.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:45:09,451 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_o_proj.safetensors
2025-04-24 15:45:09,451 - INFO - exists: False
2025-04-24 15:45:09,451 - WARNING - Skipping layer model.layers.8.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_o_proj.safetensors
2025-04-24 15:45:09,451 - INFO - Skipping layer model.layers.8.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,451 - INFO - Skipping layer model.layers.8.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,451 - INFO - Skipping layer model.layers.8.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,451 - INFO - Layer: model.layers.9.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,451 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_q_proj.safetensors
2025-04-24 15:45:09,451 - INFO - exists: False
2025-04-24 15:45:09,451 - WARNING - Skipping layer model.layers.9.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_q_proj.safetensors
2025-04-24 15:45:09,451 - INFO - Layer: model.layers.9.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,451 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_k_proj.safetensors
2025-04-24 15:45:09,451 - INFO - exists: False
2025-04-24 15:45:09,452 - WARNING - Skipping layer model.layers.9.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_k_proj.safetensors
2025-04-24 15:45:09,452 - INFO - Skipping layer model.layers.9.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,452 - INFO - Layer: model.layers.9.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 15:45:09,452 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_o_proj.safetensors
2025-04-24 15:45:09,452 - INFO - exists: False
2025-04-24 15:45:09,452 - WARNING - Skipping layer model.layers.9.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_o_proj.safetensors
2025-04-24 15:45:09,452 - INFO - Skipping layer model.layers.9.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,452 - INFO - Skipping layer model.layers.9.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,452 - INFO - Skipping layer model.layers.9.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:45:09,452 - INFO - Layer: model.layers.10.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:45:09,452 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_10_self_attn_q_proj.safetensors
2025-04-24 15:45:09,452 - INFO - exists: True
2025-04-24 15:45:09,484 - INFO - factorize_layer_kron_svd
2025-04-24 15:45:13,953 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:45:15,234 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:45:16,422 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:45:17,699 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_3_mlp_down_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_5_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_6_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_7_mlp_gate_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_8_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_9_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_10_self_attn_q_proj.safetensors True
Layer: model.layers.10.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.1147475e-04 1.1751837e-04 8.8331944e-05 4.9924896e-05 3.9312708e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:45:42,610 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:45:42,610 - INFO - Replacing 'model.layers.10.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  32%|██████████████████▌                                        | 71/225 [12:33<06:38,  2.59s/it]2025-04-24 15:45:42,611 - INFO - Layer: model.layers.10.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 15:45:42,612 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_10_self_attn_k_proj.safetensors
2025-04-24 15:45:42,612 - INFO - exists: True
2025-04-24 15:45:42,645 - INFO - factorize_layer_kron_svd
2025-04-24 15:45:44,089 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:45:45,317 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:45:46,449 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:45:47,685 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_10_self_attn_k_proj.safetensors True
Layer: model.layers.10.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.4601988e-04 9.0922345e-05 6.7010224e-05 5.4932527e-05 5.0821891e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 15:46:10,427 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 15:46:10,427 - INFO - Replacing 'model.layers.10.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  32%|██████████████████▉                                        | 72/225 [13:01<08:14,  3.23s/it]2025-04-24 15:46:10,428 - INFO - Skipping layer model.layers.10.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:46:10,428 - INFO - Skipping layer model.layers.10.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:46:10,428 - INFO - Skipping layer model.layers.10.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:46:10,428 - INFO - Skipping layer model.layers.10.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:46:10,428 - INFO - Skipping layer model.layers.10.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:46:10,428 - INFO - Layer: model.layers.11.self_attn.q_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
2025-04-24 15:46:10,430 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_q_proj.safetensors
2025-04-24 15:46:10,430 - INFO - exists: True
2025-04-24 15:46:10,454 - INFO - factorize_layer_kron_svd
2025-04-24 15:46:11,957 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:46:13,227 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:46:14,428 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:46:15,690 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_q_proj.safetensors True
Layer: model.layers.11.self_attn.q_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.7986700e-04 9.9609977e-05 7.5574397e-05 5.1822190e-05 4.9105878e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (416,4096), (4096,416)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)
2025-04-24 15:46:37,359 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)')
2025-04-24 15:46:37,359 - INFO - Replacing 'model.layers.11.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  35%|████████████████████▍                                      | 78/225 [13:28<08:28,  3.46s/it]2025-04-24 15:46:37,359 - INFO - Layer: model.layers.11.self_attn.k_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
2025-04-24 15:46:37,360 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_k_proj.safetensors
2025-04-24 15:46:37,360 - INFO - exists: True
2025-04-24 15:46:37,387 - INFO - factorize_layer_kron_svd
2025-04-24 15:46:38,864 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:46:40,154 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:46:41,338 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:46:42,597 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_k_proj.safetensors True
Layer: model.layers.11.self_attn.k_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.4792934e-04 1.2157520e-04 1.0247317e-04 7.1057482e-05 5.7551941e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (416,4096), (4096,416)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)
2025-04-24 15:47:10,052 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)')
2025-04-24 15:47:10,052 - INFO - Replacing 'model.layers.11.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  35%|████████████████████▋                                      | 79/225 [14:01<11:19,  4.65s/it]2025-04-24 15:47:10,053 - INFO - Skipping layer model.layers.11.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:47:10,053 - INFO - Layer: model.layers.11.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 15:47:10,054 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_o_proj.safetensors
2025-04-24 15:47:10,054 - INFO - exists: True
2025-04-24 15:47:10,084 - INFO - factorize_layer_kron_svd
2025-04-24 15:47:11,565 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 15:47:12,780 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_11_self_attn_o_proj.safetensors True
Layer: model.layers.11.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [2.2733117e-04 2.0363974e-05 1.6356025e-05 1.3161105e-05 1.1948326e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 15:47:40,674 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 15:47:40,675 - INFO - Replacing 'model.layers.11.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  36%|█████████████████████▏                                     | 81/225 [14:31<13:51,  5.77s/it]2025-04-24 15:47:40,675 - INFO - Skipping layer model.layers.11.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:47:40,675 - INFO - Skipping layer model.layers.11.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:47:40,675 - INFO - Skipping layer model.layers.11.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:47:40,675 - INFO - Layer: model.layers.12.self_attn.q_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:47:40,677 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_q_proj.safetensors
2025-04-24 15:47:40,677 - INFO - exists: True
2025-04-24 15:47:40,708 - INFO - factorize_layer_kron_svd
2025-04-24 15:47:42,046 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:47:43,319 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:47:44,521 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:47:45,805 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_q_proj.safetensors True
Layer: model.layers.12.self_attn.q_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.7795611e-04 7.3599527e-05 5.4209992e-05 4.3944550e-05 4.0591403e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (616,4096), (4096,616)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)
2025-04-24 15:48:07,735 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)')
2025-04-24 15:48:07,736 - INFO - Replacing 'model.layers.12.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  38%|██████████████████████▎                                    | 85/225 [14:58<14:00,  6.00s/it]2025-04-24 15:48:07,736 - INFO - Layer: model.layers.12.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:48:07,737 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_k_proj.safetensors
2025-04-24 15:48:07,737 - INFO - exists: True
2025-04-24 15:48:07,756 - INFO - factorize_layer_kron_svd
2025-04-24 15:48:09,248 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:48:10,490 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:48:11,658 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:48:12,902 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_k_proj.safetensors True
Layer: model.layers.12.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.07608642e-03 1.05497034e-04 8.38672131e-05 7.40240066e-05
 4.44736033e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:48:35,184 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:48:35,185 - INFO - Replacing 'model.layers.12.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  38%|██████████████████████▌                                    | 86/225 [15:26<17:41,  7.63s/it]2025-04-24 15:48:35,185 - INFO - Skipping layer model.layers.12.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:48:35,185 - INFO - Layer: model.layers.12.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:48:35,186 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_o_proj.safetensors
2025-04-24 15:48:35,186 - INFO - exists: True
2025-04-24 15:48:35,211 - INFO - factorize_layer_kron_svd
2025-04-24 15:48:36,665 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 15:48:37,879 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_self_attn_o_proj.safetensors True
Layer: model.layers.12.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.06922475e-04 2.49136410e-05 1.08429231e-05 1.04350329e-05
 9.57184784e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 15:49:05,059 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 15:49:05,060 - INFO - Replacing 'model.layers.12.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  39%|███████████████████████                                    | 88/225 [15:56<20:24,  8.94s/it]2025-04-24 15:49:05,061 - INFO - Layer: model.layers.12.mlp.gate_proj | Ratio: 0.500 -> Target Rank: 1496 (Align: 8)
2025-04-24 15:49:05,062 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_gate_proj.safetensors
2025-04-24 15:49:05,062 - INFO - exists: True
2025-04-24 15:49:05,145 - INFO - factorize_layer_kron_svd
2025-04-24 15:49:07,300 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:49:08,563 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:49:16,905 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_gate_proj.safetensors True
Layer: model.layers.12.mlp.gate_proj | Ratio: 0.500 -> Target Rank: 1496 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [3.4531584e-04 4.3154534e-05 2.8466011e-05 2.0477493e-05 1.5518726e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1496,4096), (11008,1496)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1496, bias=False)
  (1): Linear(in_features=1496, out_features=11008, bias=False)
)
2025-04-24 15:50:17,982 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1496, bias=False)
  (1): Linear(in_features=1496, out_features=11008, bias=False)
)')
2025-04-24 15:50:17,983 - INFO - Replacing 'model.layers.12.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:  40%|███████████████████████▎                                   | 89/225 [17:09<36:39, 16.18s/it]2025-04-24 15:50:17,983 - INFO - Layer: model.layers.12.mlp.up_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
2025-04-24 15:50:17,984 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_up_proj.safetensors
2025-04-24 15:50:17,984 - INFO - exists: True
2025-04-24 15:50:18,048 - INFO - factorize_layer_kron_svd
2025-04-24 15:50:20,231 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:50:21,517 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:50:28,037 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_up_proj.safetensors True
Layer: model.layers.12.mlp.up_proj | Ratio: 0.600 -> Target Rank: 1792 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [3.1828787e-04 4.3379245e-05 2.2649983e-05 1.7851607e-05 1.5423566e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1792,4096), (11008,1792)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=11008, bias=False)
)
2025-04-24 15:51:49,950 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1792, bias=False)
  (1): Linear(in_features=1792, out_features=11008, bias=False)
)')
2025-04-24 15:51:49,951 - INFO - Replacing 'model.layers.12.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:  40%|██████████████████████▊                                  | 90/225 [18:41<1:00:07, 26.72s/it]2025-04-24 15:51:49,951 - INFO - Layer: model.layers.12.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 15:51:49,956 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_down_proj.safetensors
2025-04-24 15:51:49,956 - INFO - exists: True
2025-04-24 15:51:50,076 - INFO - factorize_layer_kron_svd
2025-04-24 15:51:56,697 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:52:03,058 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:52:04,336 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_12_mlp_down_proj.safetensors True
Layer: model.layers.12.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x11008)...
  SVD complete. Singular values (top 5): [1.1694148e-03 2.0377325e-04 1.2311406e-04 1.0693405e-04 8.5032843e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,11008), (4096,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=11008, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=4096, bias=False)
)
2025-04-24 15:53:34,004 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=11008, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=4096, bias=False)
)')
2025-04-24 15:53:34,004 - INFO - Replacing 'model.layers.12.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)
Compressing Layers:  40%|███████████████████████                                  | 91/225 [20:25<1:28:18, 39.54s/it]2025-04-24 15:53:34,005 - INFO - Layer: model.layers.13.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 15:53:34,006 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_q_proj.safetensors
2025-04-24 15:53:34,006 - INFO - exists: True
2025-04-24 15:53:34,080 - INFO - factorize_layer_kron_svd
2025-04-24 15:53:35,691 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:53:37,395 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:53:38,739 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:53:40,200 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_q_proj.safetensors True
Layer: model.layers.13.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.09047582e-03 1.13891496e-04 6.78460201e-05 4.42121782e-05
 3.75433629e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 15:54:05,849 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 15:54:05,849 - INFO - Replacing 'model.layers.13.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  41%|███████████████████████▎                                 | 92/225 [20:57<1:24:22, 38.07s/it]2025-04-24 15:54:05,850 - INFO - Layer: model.layers.13.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:54:05,850 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_k_proj.safetensors
2025-04-24 15:54:05,850 - INFO - exists: True
2025-04-24 15:54:05,874 - INFO - factorize_layer_kron_svd
2025-04-24 15:54:07,533 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:54:09,042 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:54:10,441 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:54:11,966 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_k_proj.safetensors True
Layer: model.layers.13.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.1110766e-03 9.8493336e-05 7.3882249e-05 5.9176251e-05 4.1877520e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 15:54:52,587 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 15:54:52,587 - INFO - Replacing 'model.layers.13.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  41%|███████████████████████▌                                 | 93/225 [21:43<1:27:50, 39.93s/it]2025-04-24 15:54:52,587 - INFO - Skipping layer model.layers.13.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:54:52,587 - INFO - Layer: model.layers.13.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 15:54:52,590 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_o_proj.safetensors
2025-04-24 15:54:52,590 - INFO - exists: True
2025-04-24 15:54:52,609 - INFO - factorize_layer_kron_svd
2025-04-24 15:54:54,346 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 15:54:55,704 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_13_self_attn_o_proj.safetensors True
Layer: model.layers.13.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.67980761e-04 3.03513152e-05 1.29702248e-05 1.20683135e-05
 1.04485744e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 15:55:20,425 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 15:55:20,425 - INFO - Replacing 'model.layers.13.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  42%|████████████████████████                                 | 95/225 [22:11<1:05:04, 30.04s/it]2025-04-24 15:55:20,425 - INFO - Skipping layer model.layers.13.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:55:20,426 - INFO - Skipping layer model.layers.13.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:55:20,426 - INFO - Skipping layer model.layers.13.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:55:20,426 - INFO - Layer: model.layers.14.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:55:20,426 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_14_self_attn_q_proj.safetensors
2025-04-24 15:55:20,426 - INFO - exists: True
2025-04-24 15:55:20,445 - INFO - factorize_layer_kron_svd
2025-04-24 15:55:21,969 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:55:23,384 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:55:24,764 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:55:26,168 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_14_self_attn_q_proj.safetensors True
Layer: model.layers.14.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.67754861e-04 1.08093715e-04 5.89062947e-05 5.34788778e-05
 4.27111954e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:55:59,931 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:55:59,931 - INFO - Replacing 'model.layers.14.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  44%|█████████████████████████▉                                 | 99/225 [22:51<41:01, 19.54s/it]2025-04-24 15:55:59,932 - INFO - Layer: model.layers.14.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 15:55:59,934 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_14_self_attn_k_proj.safetensors
2025-04-24 15:55:59,934 - INFO - exists: True
2025-04-24 15:55:59,952 - INFO - factorize_layer_kron_svd
2025-04-24 15:56:01,565 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:56:02,978 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:56:04,183 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:56:05,399 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_14_self_attn_k_proj.safetensors True
Layer: model.layers.14.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.7232516e-04 1.0987472e-04 7.0545255e-05 5.8294750e-05 4.7337810e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 15:56:30,987 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 15:56:30,987 - INFO - Replacing 'model.layers.14.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  44%|█████████████████████████▊                                | 100/225 [23:22<44:28, 21.34s/it]2025-04-24 15:56:30,987 - INFO - Skipping layer model.layers.14.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:56:30,987 - INFO - Skipping layer model.layers.14.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:56:30,987 - INFO - Skipping layer model.layers.14.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:56:30,987 - INFO - Skipping layer model.layers.14.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:56:30,988 - INFO - Skipping layer model.layers.14.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:56:30,988 - INFO - Layer: model.layers.15.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 15:56:30,988 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_15_self_attn_q_proj.safetensors
2025-04-24 15:56:30,988 - INFO - exists: True
2025-04-24 15:56:31,029 - INFO - factorize_layer_kron_svd
2025-04-24 15:56:32,784 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:56:34,254 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:56:35,445 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:56:36,898 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_15_self_attn_q_proj.safetensors True
Layer: model.layers.15.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.6131087e-04 8.2904990e-05 6.6847955e-05 5.3464220e-05 4.0176823e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 15:57:07,139 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 15:57:07,139 - INFO - Replacing 'model.layers.15.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  47%|███████████████████████████▎                              | 106/225 [23:58<24:54, 12.56s/it]2025-04-24 15:57:07,139 - INFO - Layer: model.layers.15.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 15:57:07,141 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_15_self_attn_k_proj.safetensors
2025-04-24 15:57:07,141 - INFO - exists: True
2025-04-24 15:57:07,159 - INFO - factorize_layer_kron_svd
2025-04-24 15:57:08,641 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:57:10,029 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:57:11,183 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:57:12,794 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_15_self_attn_k_proj.safetensors True
Layer: model.layers.15.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.8808837e-04 1.1092378e-04 6.3344865e-05 3.6479836e-05 3.4227403e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 15:57:42,657 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 15:57:42,657 - INFO - Replacing 'model.layers.15.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  48%|███████████████████████████▌                              | 107/225 [24:33<30:07, 15.32s/it]2025-04-24 15:57:42,657 - INFO - Skipping layer model.layers.15.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:57:42,657 - INFO - Skipping layer model.layers.15.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:57:42,657 - INFO - Skipping layer model.layers.15.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:57:42,657 - INFO - Skipping layer model.layers.15.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:57:42,657 - INFO - Skipping layer model.layers.15.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:57:42,657 - INFO - Layer: model.layers.16.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 15:57:42,658 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_q_proj.safetensors
2025-04-24 15:57:42,658 - INFO - exists: True
2025-04-24 15:57:42,678 - INFO - factorize_layer_kron_svd
2025-04-24 15:57:45,595 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 15:57:46,785 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_q_proj.safetensors True
Layer: model.layers.16.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.8457525e-04 7.0841801e-05 5.7777223e-05 5.5076001e-05 4.2950800e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 15:58:07,344 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 15:58:07,344 - INFO - Replacing 'model.layers.16.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  50%|█████████████████████████████▏                            | 113/225 [24:58<17:59,  9.63s/it]2025-04-24 15:58:07,344 - INFO - Layer: model.layers.16.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 15:58:07,346 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_k_proj.safetensors
2025-04-24 15:58:07,346 - INFO - exists: True
2025-04-24 15:58:07,364 - INFO - factorize_layer_kron_svd
2025-04-24 15:58:08,985 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:58:10,428 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:58:11,803 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_k_proj.safetensors True
Layer: model.layers.16.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.0770942e-03 8.0462807e-05 6.1351449e-05 4.7102651e-05 3.8980666e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (616,4096), (4096,616)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)
2025-04-24 15:58:40,629 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)')
2025-04-24 15:58:40,629 - INFO - Replacing 'model.layers.16.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  51%|█████████████████████████████▍                            | 114/225 [25:31<22:32, 12.18s/it]2025-04-24 15:58:40,629 - INFO - Skipping layer model.layers.16.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:58:40,629 - INFO - Layer: model.layers.16.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 15:58:40,630 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_o_proj.safetensors
2025-04-24 15:58:40,630 - INFO - exists: True
2025-04-24 15:58:40,649 - INFO - factorize_layer_kron_svd
2025-04-24 15:58:42,045 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:58:43,181 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:58:44,330 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:58:45,510 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:58:46,593 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:58:48,140 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 15:58:49,239 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:58:50,363 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 15:58:51,493 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 15:58:52,616 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 15:58:53,862 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 15:58:55,533 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_16_self_attn_o_proj.safetensors True
Layer: model.layers.16.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.0113722e-06 2.6841703e-06 2.6340790e-06 2.5708566e-06 2.5678978e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1848,4096), (4096,1848)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)
2025-04-24 15:59:34,470 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)')
2025-04-24 15:59:34,471 - INFO - Replacing 'model.layers.16.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  52%|█████████████████████████████▉                            | 116/225 [26:25<28:26, 15.65s/it]2025-04-24 15:59:34,471 - INFO - Skipping layer model.layers.16.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:59:34,471 - INFO - Skipping layer model.layers.16.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:59:34,471 - INFO - Skipping layer model.layers.16.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 15:59:34,471 - INFO - Layer: model.layers.17.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 15:59:34,473 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_17_self_attn_q_proj.safetensors
2025-04-24 15:59:34,474 - INFO - exists: True
2025-04-24 15:59:34,493 - INFO - factorize_layer_kron_svd
2025-04-24 15:59:36,098 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 15:59:37,355 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 15:59:38,540 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_17_self_attn_q_proj.safetensors True
Layer: model.layers.17.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.689794e-04 7.188844e-05 6.298116e-05 4.230161e-05 4.018409e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:00:01,258 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:00:01,258 - INFO - Replacing 'model.layers.17.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  53%|██████████████████████████████▉                           | 120/225 [26:52<21:05, 12.05s/it]2025-04-24 16:00:01,258 - INFO - Layer: model.layers.17.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:00:01,259 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_17_self_attn_k_proj.safetensors
2025-04-24 16:00:01,259 - INFO - exists: True
2025-04-24 16:00:01,278 - INFO - factorize_layer_kron_svd
2025-04-24 16:00:02,984 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:00:04,290 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:00:05,472 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:00:07,031 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_17_self_attn_k_proj.safetensors True
Layer: model.layers.17.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.0933678e-04 7.7465673e-05 6.2697633e-05 4.3592729e-05 3.4580888e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:00:46,383 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:00:46,383 - INFO - Replacing 'model.layers.17.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  54%|███████████████████████████████▏                          | 121/225 [27:37<28:05, 16.20s/it]2025-04-24 16:00:46,383 - INFO - Skipping layer model.layers.17.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:00:46,383 - INFO - Skipping layer model.layers.17.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:00:46,383 - INFO - Skipping layer model.layers.17.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:00:46,383 - INFO - Skipping layer model.layers.17.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:00:46,383 - INFO - Skipping layer model.layers.17.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:00:46,383 - INFO - Layer: model.layers.18.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:00:46,385 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_q_proj.safetensors
2025-04-24 16:00:46,385 - INFO - exists: True
2025-04-24 16:00:46,433 - INFO - factorize_layer_kron_svd
2025-04-24 16:00:48,142 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:00:49,739 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:00:51,338 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_q_proj.safetensors True
Layer: model.layers.18.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.4509847e-04 6.3694992e-05 5.3031312e-05 3.3028406e-05 3.0152803e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:01:20,378 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:01:20,378 - INFO - Replacing 'model.layers.18.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  56%|████████████████████████████████▋                         | 127/225 [28:11<17:32, 10.74s/it]2025-04-24 16:01:20,379 - INFO - Layer: model.layers.18.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:01:20,379 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_k_proj.safetensors
2025-04-24 16:01:20,379 - INFO - exists: True
2025-04-24 16:01:20,398 - INFO - factorize_layer_kron_svd
2025-04-24 16:01:21,983 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:01:23,409 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:01:24,645 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:01:25,986 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_k_proj.safetensors True
Layer: model.layers.18.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.9182804e-04 7.6477787e-05 3.8036465e-05 3.0466859e-05 2.4186118e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:01:57,536 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:01:57,537 - INFO - Replacing 'model.layers.18.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  57%|████████████████████████████████▉                         | 128/225 [28:48<22:03, 13.64s/it]2025-04-24 16:01:57,537 - INFO - Skipping layer model.layers.18.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:01:57,537 - INFO - Layer: model.layers.18.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:01:57,539 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_o_proj.safetensors
2025-04-24 16:01:57,539 - INFO - exists: True
2025-04-24 16:01:57,556 - INFO - factorize_layer_kron_svd
2025-04-24 16:01:58,882 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:01:59,972 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:02:01,093 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:02:02,185 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:02:03,307 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:02:04,532 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:02:05,615 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:02:06,694 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:02:07,791 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:02:08,860 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:02:09,953 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:02:11,609 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_18_self_attn_o_proj.safetensors True
Layer: model.layers.18.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.4370907e-06 2.7923429e-06 2.7048741e-06 2.5941874e-06 2.5748666e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:02:48,461 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:02:48,461 - INFO - Replacing 'model.layers.18.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  58%|█████████████████████████████████▌                        | 130/225 [29:39<26:04, 16.47s/it]2025-04-24 16:02:48,462 - INFO - Skipping layer model.layers.18.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:02:48,462 - INFO - Skipping layer model.layers.18.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:02:48,462 - INFO - Skipping layer model.layers.18.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:02:48,462 - INFO - Layer: model.layers.19.self_attn.q_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:02:48,462 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_q_proj.safetensors
2025-04-24 16:02:48,462 - INFO - exists: True
2025-04-24 16:02:48,480 - INFO - factorize_layer_kron_svd
2025-04-24 16:02:49,841 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:02:51,079 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:02:52,319 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_q_proj.safetensors True
Layer: model.layers.19.self_attn.q_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.1692264e-04 5.3431831e-05 4.5319226e-05 3.9285813e-05 3.2373766e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:03:26,862 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:03:26,862 - INFO - Replacing 'model.layers.19.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  60%|██████████████████████████████████▌                       | 134/225 [30:18<20:45, 13.68s/it]2025-04-24 16:03:26,862 - INFO - Layer: model.layers.19.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:03:26,863 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_k_proj.safetensors
2025-04-24 16:03:26,863 - INFO - exists: True
2025-04-24 16:03:26,881 - INFO - factorize_layer_kron_svd
2025-04-24 16:03:28,371 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:03:29,655 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:03:30,903 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_k_proj.safetensors True
Layer: model.layers.19.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.4402843e-04 5.6601450e-05 4.7169488e-05 3.6125271e-05 3.3897668e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:04:05,748 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:04:05,748 - INFO - Replacing 'model.layers.19.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  60%|██████████████████████████████████▊                       | 135/225 [30:56<25:18, 16.87s/it]2025-04-24 16:04:05,748 - INFO - Skipping layer model.layers.19.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:04:05,748 - INFO - Layer: model.layers.19.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 16:04:05,749 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_o_proj.safetensors
2025-04-24 16:04:05,749 - INFO - exists: True
2025-04-24 16:04:05,766 - INFO - factorize_layer_kron_svd
2025-04-24 16:04:07,117 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:04:08,227 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:04:09,316 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:04:10,438 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:04:11,548 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:04:13,238 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:04:14,334 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:04:15,462 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:04:16,593 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:04:17,719 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:04:18,856 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:04:20,422 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_19_self_attn_o_proj.safetensors True
Layer: model.layers.19.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.3624221e-06 2.7126407e-06 2.6424659e-06 2.5899076e-06 2.4992921e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1848,4096), (4096,1848)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)
2025-04-24 16:04:53,746 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)')
2025-04-24 16:04:53,746 - INFO - Replacing 'model.layers.19.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  61%|███████████████████████████████████▎                      | 137/225 [31:44<27:31, 18.76s/it]2025-04-24 16:04:53,746 - INFO - Skipping layer model.layers.19.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:04:53,746 - INFO - Skipping layer model.layers.19.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:04:53,746 - INFO - Skipping layer model.layers.19.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:04:53,746 - INFO - Layer: model.layers.20.self_attn.q_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
2025-04-24 16:04:53,747 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_q_proj.safetensors
2025-04-24 16:04:53,747 - INFO - exists: True
2025-04-24 16:04:53,764 - INFO - factorize_layer_kron_svd
2025-04-24 16:04:55,452 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:04:56,936 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:04:58,202 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_q_proj.safetensors True
Layer: model.layers.20.self_attn.q_proj | Ratio: 0.200 -> Target Rank: 416 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.0140831e-04 6.1302264e-05 5.0301820e-05 3.8353595e-05 2.8814045e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (416,4096), (4096,416)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)
2025-04-24 16:05:25,640 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=416, bias=False)
  (1): Linear(in_features=416, out_features=4096, bias=False)
)')
2025-04-24 16:05:25,640 - INFO - Replacing 'model.layers.20.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  63%|████████████████████████████████████▎                     | 141/225 [32:16<19:45, 14.11s/it]2025-04-24 16:05:25,640 - INFO - Layer: model.layers.20.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 16:05:25,641 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_k_proj.safetensors
2025-04-24 16:05:25,641 - INFO - exists: True
2025-04-24 16:05:25,661 - INFO - factorize_layer_kron_svd
2025-04-24 16:05:27,200 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:05:28,714 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_k_proj.safetensors True
Layer: model.layers.20.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.0406852e-03 5.4494500e-05 4.0110652e-05 2.9760553e-05 2.5743462e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 16:05:57,740 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 16:05:57,740 - INFO - Replacing 'model.layers.20.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  63%|████████████████████████████████████▌                     | 142/225 [32:48<22:50, 16.51s/it]2025-04-24 16:05:57,740 - INFO - Layer: model.layers.20.self_attn.v_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:05:57,741 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_v_proj.safetensors
2025-04-24 16:05:57,741 - INFO - exists: True
2025-04-24 16:05:57,766 - INFO - factorize_layer_kron_svd
2025-04-24 16:05:59,733 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:06:00,992 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:06:02,165 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:06:03,716 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_v_proj.safetensors True
Layer: model.layers.20.self_attn.v_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [9.2318274e-05 2.0415315e-05 1.2823558e-05 8.6249993e-06 6.7299879e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:06:31,906 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:06:31,906 - INFO - Replacing 'model.layers.20.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:  64%|████████████████████████████████████▊                     | 143/225 [33:23<26:25, 19.34s/it]2025-04-24 16:06:31,906 - INFO - Layer: model.layers.20.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:06:31,907 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_o_proj.safetensors
2025-04-24 16:06:31,907 - INFO - exists: True
2025-04-24 16:06:31,925 - INFO - factorize_layer_kron_svd
2025-04-24 16:06:33,375 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:06:34,501 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:06:35,638 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:06:36,782 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:06:37,914 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:06:39,525 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:06:40,650 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:06:41,783 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:06:42,912 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:06:44,009 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:06:45,182 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:06:46,828 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_20_self_attn_o_proj.safetensors True
Layer: model.layers.20.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.5827680e-06 2.8515849e-06 2.6935977e-06 2.5656159e-06 2.4738813e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:07:30,289 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:07:30,290 - INFO - Replacing 'model.layers.20.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  64%|█████████████████████████████████████                     | 144/225 [34:21<35:55, 26.61s/it]2025-04-24 16:07:30,290 - INFO - Skipping layer model.layers.20.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:07:30,290 - INFO - Skipping layer model.layers.20.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:07:30,290 - INFO - Skipping layer model.layers.20.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:07:30,290 - INFO - Layer: model.layers.21.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:07:30,291 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_q_proj.safetensors
2025-04-24 16:07:30,291 - INFO - exists: True
2025-04-24 16:07:30,307 - INFO - factorize_layer_kron_svd
2025-04-24 16:07:32,684 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:07:33,922 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:07:35,091 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_q_proj.safetensors True
Layer: model.layers.21.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.1362458e-04 7.4350537e-05 3.7766848e-05 2.4498802e-05 2.1550906e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:08:06,131 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:08:06,132 - INFO - Replacing 'model.layers.21.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  66%|██████████████████████████████████████▏                   | 148/225 [34:57<22:28, 17.51s/it]2025-04-24 16:08:06,132 - INFO - Layer: model.layers.21.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:08:06,133 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_k_proj.safetensors
2025-04-24 16:08:06,133 - INFO - exists: True
2025-04-24 16:08:06,151 - INFO - factorize_layer_kron_svd
2025-04-24 16:08:07,544 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:08:09,166 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:08:10,656 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:08:12,072 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_k_proj.safetensors True
Layer: model.layers.21.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [2.5919633e-04 9.5758223e-05 7.8373805e-06 6.2292274e-06 5.4841680e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:08:51,329 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:08:51,329 - INFO - Replacing 'model.layers.21.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  66%|██████████████████████████████████████▍                   | 149/225 [35:42<27:38, 21.82s/it]2025-04-24 16:08:51,330 - INFO - Layer: model.layers.21.self_attn.v_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:08:51,332 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_v_proj.safetensors
2025-04-24 16:08:51,332 - INFO - exists: True
2025-04-24 16:08:51,352 - INFO - factorize_layer_kron_svd
2025-04-24 16:08:52,753 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:08:53,985 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:08:55,260 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:08:56,829 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_v_proj.safetensors True
Layer: model.layers.21.self_attn.v_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.3663064e-04 1.4290518e-05 9.3747267e-06 6.9539688e-06 4.9605360e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:09:37,694 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:09:37,694 - INFO - Replacing 'model.layers.21.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:  67%|██████████████████████████████████████▋                   | 150/225 [36:28<32:50, 26.28s/it]2025-04-24 16:09:37,695 - INFO - Layer: model.layers.21.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 16:09:37,695 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_o_proj.safetensors
2025-04-24 16:09:37,695 - INFO - exists: True
2025-04-24 16:09:37,713 - INFO - factorize_layer_kron_svd
2025-04-24 16:09:39,009 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:09:40,113 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:09:41,240 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:09:42,365 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:09:43,472 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:09:44,978 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:09:46,081 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:09:47,177 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:09:48,282 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:09:49,461 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:09:50,751 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:09:52,559 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_21_self_attn_o_proj.safetensors True
Layer: model.layers.21.self_attn.o_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.6280055e-06 2.9603489e-06 2.6979048e-06 2.4875860e-06 2.4380076e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1848,4096), (4096,1848)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)
2025-04-24 16:10:22,562 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)')
2025-04-24 16:10:22,563 - INFO - Replacing 'model.layers.21.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  67%|██████████████████████████████████████▉                   | 151/225 [37:13<37:08, 30.11s/it]2025-04-24 16:10:22,563 - INFO - Skipping layer model.layers.21.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:10:22,563 - INFO - Skipping layer model.layers.21.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:10:22,563 - INFO - Skipping layer model.layers.21.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:10:22,563 - INFO - Layer: model.layers.22.self_attn.q_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:10:22,567 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_q_proj.safetensors
2025-04-24 16:10:22,567 - INFO - exists: True
2025-04-24 16:10:22,591 - INFO - factorize_layer_kron_svd
2025-04-24 16:10:25,640 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:10:27,000 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:10:28,354 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_q_proj.safetensors True
Layer: model.layers.22.self_attn.q_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.1551203e-04 5.6577930e-05 3.6369638e-05 2.8548533e-05 2.6242335e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:10:50,680 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:10:50,681 - INFO - Replacing 'model.layers.22.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  69%|███████████████████████████████████████▉                  | 155/225 [37:41<20:33, 17.63s/it]2025-04-24 16:10:50,681 - INFO - Layer: model.layers.22.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:10:50,682 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_k_proj.safetensors
2025-04-24 16:10:50,682 - INFO - exists: True
2025-04-24 16:10:50,707 - INFO - factorize_layer_kron_svd
2025-04-24 16:10:52,403 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:10:54,055 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_k_proj.safetensors True
Layer: model.layers.22.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.8471733e-04 3.7389949e-05 3.0549065e-05 2.7955735e-05 2.3029401e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:11:23,182 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:11:23,182 - INFO - Replacing 'model.layers.22.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  69%|████████████████████████████████████████▏                 | 156/225 [38:14<23:02, 20.04s/it]2025-04-24 16:11:23,183 - INFO - Skipping layer model.layers.22.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:11:23,183 - INFO - Layer: model.layers.22.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:11:23,183 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_o_proj.safetensors
2025-04-24 16:11:23,183 - INFO - exists: True
2025-04-24 16:11:23,202 - INFO - factorize_layer_kron_svd
2025-04-24 16:11:24,606 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:11:26,127 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:11:27,675 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:11:29,144 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:11:30,599 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_22_self_attn_o_proj.safetensors True
Layer: model.layers.22.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.4139143e-05 4.4393823e-06 1.9341273e-06 8.7018583e-07 8.0446426e-07]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:11:57,958 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:11:57,959 - INFO - Replacing 'model.layers.22.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  70%|████████████████████████████████████████▋                 | 158/225 [38:49<21:26, 19.20s/it]2025-04-24 16:11:57,959 - INFO - Skipping layer model.layers.22.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:11:57,959 - INFO - Skipping layer model.layers.22.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:11:57,959 - INFO - Skipping layer model.layers.22.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:11:57,959 - INFO - Layer: model.layers.23.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:11:57,959 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_q_proj.safetensors
2025-04-24 16:11:57,959 - INFO - exists: True
2025-04-24 16:11:58,010 - INFO - factorize_layer_kron_svd
2025-04-24 16:12:00,036 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:12:01,483 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_q_proj.safetensors True
Layer: model.layers.23.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.4219279e-04 3.7877617e-05 2.6261388e-05 2.2600490e-05 2.1597491e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:12:32,338 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:12:32,338 - INFO - Replacing 'model.layers.23.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  72%|█████████████████████████████████████████▊                | 162/225 [39:23<14:52, 14.16s/it]2025-04-24 16:12:32,339 - INFO - Layer: model.layers.23.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:12:32,339 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_k_proj.safetensors
2025-04-24 16:12:32,340 - INFO - exists: True
2025-04-24 16:12:32,370 - INFO - factorize_layer_kron_svd
2025-04-24 16:12:34,020 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:12:35,630 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:12:37,380 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_k_proj.safetensors True
Layer: model.layers.23.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.7510236e-04 3.6314970e-05 2.5059404e-05 2.1486116e-05 2.0177757e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:13:17,485 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:13:17,486 - INFO - Replacing 'model.layers.23.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  72%|██████████████████████████████████████████                | 163/225 [40:08<19:16, 18.66s/it]2025-04-24 16:13:17,486 - INFO - Layer: model.layers.23.self_attn.v_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:13:17,487 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_v_proj.safetensors
2025-04-24 16:13:17,487 - INFO - exists: True
2025-04-24 16:13:17,509 - INFO - factorize_layer_kron_svd
2025-04-24 16:13:19,066 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:13:20,307 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:13:21,497 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:13:22,990 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_v_proj.safetensors True
Layer: model.layers.23.self_attn.v_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.7369165e-05 1.2404687e-05 8.0052805e-06 5.7160964e-06 4.7268454e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:13:48,861 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:13:48,861 - INFO - Replacing 'model.layers.23.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:  73%|██████████████████████████████████████████▎               | 164/225 [40:40<21:11, 20.84s/it]2025-04-24 16:13:48,862 - INFO - Layer: model.layers.23.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:13:48,862 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_o_proj.safetensors
2025-04-24 16:13:48,862 - INFO - exists: True
2025-04-24 16:13:48,880 - INFO - factorize_layer_kron_svd
2025-04-24 16:13:50,313 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:13:51,495 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:13:52,928 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:13:54,184 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:13:55,581 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_self_attn_o_proj.safetensors True
Layer: model.layers.23.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [2.7224842e-05 1.7550238e-06 1.0574929e-06 7.5971263e-07 6.0233413e-07]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:14:25,895 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:14:25,895 - INFO - Replacing 'model.layers.23.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  73%|██████████████████████████████████████████▌               | 165/225 [41:17<24:01, 24.03s/it]2025-04-24 16:14:25,896 - INFO - Skipping layer model.layers.23.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:14:25,896 - INFO - Layer: model.layers.23.mlp.up_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 16:14:25,896 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_mlp_up_proj.safetensors
2025-04-24 16:14:25,896 - INFO - exists: True
2025-04-24 16:14:25,957 - INFO - factorize_layer_kron_svd
2025-04-24 16:14:28,276 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:14:29,655 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:14:30,999 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:14:33,081 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:14:36,721 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_23_mlp_up_proj.safetensors True
Layer: model.layers.23.mlp.up_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [3.0700947e-05 1.0850134e-05 3.0478623e-06 2.7577912e-06 1.0493320e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,4096), (11008,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)
2025-04-24 16:15:32,454 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)')
2025-04-24 16:15:32,454 - INFO - Replacing 'model.layers.23.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:  74%|███████████████████████████████████████████               | 167/225 [42:23<26:26, 27.36s/it]2025-04-24 16:15:32,455 - INFO - Skipping layer model.layers.23.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:15:32,455 - INFO - Layer: model.layers.24.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 16:15:32,457 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_q_proj.safetensors
2025-04-24 16:15:32,457 - INFO - exists: True
2025-04-24 16:15:32,484 - INFO - factorize_layer_kron_svd
2025-04-24 16:15:34,108 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:15:35,522 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_q_proj.safetensors True
Layer: model.layers.24.self_attn.q_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [4.7672872e-04 6.1251303e-05 3.5211855e-05 2.2390554e-05 2.0775149e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 16:16:05,449 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 16:16:05,449 - INFO - Replacing 'model.layers.24.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  75%|███████████████████████████████████████████▌              | 169/225 [42:56<22:05, 23.67s/it]2025-04-24 16:16:05,449 - INFO - Layer: model.layers.24.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
2025-04-24 16:16:05,450 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_k_proj.safetensors
2025-04-24 16:16:05,450 - INFO - exists: True
2025-04-24 16:16:05,469 - INFO - factorize_layer_kron_svd
2025-04-24 16:16:07,045 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:16:08,279 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:16:09,651 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_k_proj.safetensors True
Layer: model.layers.24.self_attn.k_proj | Ratio: 0.100 -> Target Rank: 208 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.5969006e-04 4.6440331e-05 2.8826469e-05 1.8546911e-05 1.6199194e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (208,4096), (4096,208)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)
2025-04-24 16:16:35,277 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=208, bias=False)
  (1): Linear(in_features=208, out_features=4096, bias=False)
)')
2025-04-24 16:16:35,277 - INFO - Replacing 'model.layers.24.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  76%|███████████████████████████████████████████▊              | 170/225 [43:26<22:47, 24.87s/it]2025-04-24 16:16:35,277 - INFO - Layer: model.layers.24.self_attn.v_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:16:35,279 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_v_proj.safetensors
2025-04-24 16:16:35,279 - INFO - exists: True
2025-04-24 16:16:35,335 - INFO - factorize_layer_kron_svd
2025-04-24 16:16:36,805 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:16:38,170 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:16:39,367 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:16:40,760 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_v_proj.safetensors True
Layer: model.layers.24.self_attn.v_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.32314041e-05 1.17357795e-05 8.59317061e-06 5.70959173e-06
 4.66277879e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:17:09,551 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:17:09,551 - INFO - Replacing 'model.layers.24.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:  76%|████████████████████████████████████████████              | 171/225 [44:00<24:13, 26.92s/it]2025-04-24 16:17:09,552 - INFO - Layer: model.layers.24.self_attn.o_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 16:17:09,552 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_o_proj.safetensors
2025-04-24 16:17:09,552 - INFO - exists: True
2025-04-24 16:17:09,569 - INFO - factorize_layer_kron_svd
2025-04-24 16:17:10,984 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:17:12,156 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:17:13,297 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:17:14,477 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_self_attn_o_proj.safetensors True
Layer: model.layers.24.self_attn.o_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [3.2492968e-05 1.0363568e-05 1.5397670e-06 1.1765046e-06 8.8089394e-07]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 16:17:38,828 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 16:17:38,828 - INFO - Replacing 'model.layers.24.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  76%|████████████████████████████████████████████▎             | 172/225 [44:30<24:16, 27.48s/it]2025-04-24 16:17:38,828 - INFO - Layer: model.layers.24.mlp.gate_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
2025-04-24 16:17:38,830 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_gate_proj.safetensors
2025-04-24 16:17:38,830 - INFO - exists: True
2025-04-24 16:17:38,869 - INFO - factorize_layer_kron_svd
2025-04-24 16:17:41,022 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:17:42,445 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:17:43,690 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:17:50,065 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:18:00,683 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_gate_proj.safetensors True
Layer: model.layers.24.mlp.gate_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [4.4121687e-05 1.3112584e-05 3.2457190e-06 2.4400804e-06 1.0232656e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)
2025-04-24 16:19:14,325 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)')
2025-04-24 16:19:14,326 - INFO - Replacing 'model.layers.24.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:  77%|████████████████████████████████████████████▌             | 173/225 [46:05<38:45, 44.71s/it]2025-04-24 16:19:14,326 - INFO - Layer: model.layers.24.mlp.up_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
2025-04-24 16:19:14,328 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_up_proj.safetensors
2025-04-24 16:19:14,328 - INFO - exists: True
2025-04-24 16:19:14,378 - INFO - factorize_layer_kron_svd
2025-04-24 16:19:16,722 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:19:18,841 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:19:21,319 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:19:25,167 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:19:29,387 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_up_proj.safetensors True
Layer: model.layers.24.mlp.up_proj | Ratio: 0.700 -> Target Rank: 2096 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [3.5628200e-05 5.7007760e-06 3.7646712e-06 2.6412317e-06 1.1728241e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)
2025-04-24 16:20:43,894 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2096, bias=False)
  (1): Linear(in_features=2096, out_features=11008, bias=False)
)')
2025-04-24 16:20:43,894 - INFO - Replacing 'model.layers.24.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:  77%|████████████████████████████████████████████▊             | 174/225 [47:35<48:08, 56.63s/it]2025-04-24 16:20:43,894 - INFO - Layer: model.layers.24.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 16:20:43,896 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_down_proj.safetensors
2025-04-24 16:20:43,896 - INFO - exists: True
2025-04-24 16:20:43,949 - INFO - factorize_layer_kron_svd
2025-04-24 16:20:48,302 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:20:49,487 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_24_mlp_down_proj.safetensors True
Layer: model.layers.24.mlp.down_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x11008)...
  SVD complete. Singular values (top 5): [7.60391820e-04 1.16251285e-04 8.95536141e-05 6.90299203e-05
 6.11170253e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,11008), (4096,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=11008, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=4096, bias=False)
)
2025-04-24 16:22:31,483 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=11008, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=4096, bias=False)
)')
2025-04-24 16:22:31,483 - INFO - Replacing 'model.layers.24.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)
Compressing Layers:  78%|█████████████████████████████████████████████             | 175/225 [49:22<58:52, 70.66s/it]2025-04-24 16:22:31,483 - INFO - Layer: model.layers.25.self_attn.q_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:22:31,484 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_self_attn_q_proj.safetensors
2025-04-24 16:22:31,484 - INFO - exists: True
2025-04-24 16:22:31,511 - INFO - factorize_layer_kron_svd
2025-04-24 16:22:33,192 - INFO -   Factor is positive definite (alpha=1.00e-05)
2025-04-24 16:22:34,490 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_self_attn_q_proj.safetensors True
Layer: model.layers.25.self_attn.q_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Factor is positive definite (alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [7.3310739e-04 4.5168257e-05 2.6283642e-05 2.2007003e-05 1.9362484e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:23:01,282 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:23:01,282 - INFO - Replacing 'model.layers.25.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  78%|█████████████████████████████████████████████▎            | 176/225 [49:52<48:17, 59.13s/it]2025-04-24 16:23:01,283 - INFO - Skipping layer model.layers.25.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:23:01,283 - INFO - Skipping layer model.layers.25.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:23:01,283 - INFO - Layer: model.layers.25.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:23:01,283 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_self_attn_o_proj.safetensors
2025-04-24 16:23:01,284 - INFO - exists: True
2025-04-24 16:23:01,301 - INFO - factorize_layer_kron_svd
2025-04-24 16:23:03,201 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:23:04,543 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:23:05,779 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:23:07,044 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:23:08,516 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_self_attn_o_proj.safetensors True
Layer: model.layers.25.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.5150558e-05 2.7744670e-06 7.5447014e-07 4.9762866e-07 4.8306060e-07]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:23:36,199 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:23:36,199 - INFO - Replacing 'model.layers.25.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  80%|██████████████████████████████████████████████▏           | 179/225 [50:27<25:24, 33.13s/it]2025-04-24 16:23:36,200 - INFO - Layer: model.layers.25.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 16:23:36,200 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_mlp_gate_proj.safetensors
2025-04-24 16:23:36,200 - INFO - exists: True
2025-04-24 16:23:36,245 - INFO - factorize_layer_kron_svd
2025-04-24 16:23:38,271 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:23:39,620 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:23:41,029 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:23:48,154 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:24:01,939 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_mlp_gate_proj.safetensors True
Layer: model.layers.25.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [5.2119361e-05 1.5998472e-05 4.2029083e-06 1.9503864e-06 1.1962488e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,4096), (11008,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)
2025-04-24 16:25:06,669 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)')
2025-04-24 16:25:06,669 - INFO - Replacing 'model.layers.25.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:  80%|██████████████████████████████████████████████▍           | 180/225 [51:57<33:44, 44.99s/it]2025-04-24 16:25:06,669 - INFO - Layer: model.layers.25.mlp.up_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 16:25:06,670 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_mlp_up_proj.safetensors
2025-04-24 16:25:06,670 - INFO - exists: True
2025-04-24 16:25:06,721 - INFO - factorize_layer_kron_svd
2025-04-24 16:25:08,751 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:25:09,978 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:25:11,229 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:25:19,227 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:25:23,566 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_25_mlp_up_proj.safetensors True
Layer: model.layers.25.mlp.up_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [3.1324053e-05 1.3509146e-05 3.6688521e-06 2.5376346e-06 1.6996315e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,4096), (11008,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)
2025-04-24 16:26:23,510 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)')
2025-04-24 16:26:23,510 - INFO - Replacing 'model.layers.25.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)
Compressing Layers:  80%|██████████████████████████████████████████████▋           | 181/225 [53:14<38:19, 52.25s/it]2025-04-24 16:26:23,511 - INFO - Skipping layer model.layers.25.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:26:23,511 - INFO - Layer: model.layers.26.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:26:23,512 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_q_proj.safetensors
2025-04-24 16:26:23,512 - INFO - exists: True
2025-04-24 16:26:23,543 - INFO - factorize_layer_kron_svd
2025-04-24 16:26:24,889 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:26:26,076 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:26:27,246 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_q_proj.safetensors True
Layer: model.layers.26.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.1266200e-04 5.1251598e-05 3.0445932e-05 2.3706018e-05 2.2058506e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1024,4096), (4096,1024)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)
2025-04-24 16:26:58,445 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1024, bias=False)
  (1): Linear(in_features=1024, out_features=4096, bias=False)
)')
2025-04-24 16:26:58,445 - INFO - Replacing 'model.layers.26.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  81%|███████████████████████████████████████████████▏          | 183/225 [53:49<26:58, 38.53s/it]2025-04-24 16:26:58,446 - INFO - Layer: model.layers.26.self_attn.k_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 16:26:58,446 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_k_proj.safetensors
2025-04-24 16:26:58,446 - INFO - exists: True
2025-04-24 16:26:58,463 - INFO - factorize_layer_kron_svd
2025-04-24 16:26:59,906 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:27:01,191 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:27:02,404 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:27:03,628 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_k_proj.safetensors True
Layer: model.layers.26.self_attn.k_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.2989095e-04 3.5860310e-05 2.9987032e-05 1.9561858e-05 1.6020722e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 16:27:37,378 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 16:27:37,378 - INFO - Replacing 'model.layers.26.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  82%|███████████████████████████████████████████████▍          | 184/225 [54:28<26:23, 38.62s/it]2025-04-24 16:27:37,379 - INFO - Skipping layer model.layers.26.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:27:37,379 - INFO - Layer: model.layers.26.self_attn.o_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:27:37,380 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_o_proj.safetensors
2025-04-24 16:27:37,380 - INFO - exists: True
2025-04-24 16:27:37,395 - INFO - factorize_layer_kron_svd
2025-04-24 16:27:38,803 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:27:40,143 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:27:41,371 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:27:42,571 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_26_self_attn_o_proj.safetensors True
Layer: model.layers.26.self_attn.o_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [2.3415269e-04 1.1255141e-05 1.0018451e-05 7.2952666e-06 5.6233293e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:28:16,427 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:28:16,427 - INFO - Replacing 'model.layers.26.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  83%|███████████████████████████████████████████████▉          | 186/225 [55:07<20:18, 31.25s/it]2025-04-24 16:28:16,427 - INFO - Skipping layer model.layers.26.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:28:16,427 - INFO - Skipping layer model.layers.26.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:28:16,427 - INFO - Skipping layer model.layers.26.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:28:16,427 - INFO - Layer: model.layers.27.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 16:28:16,428 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_q_proj.safetensors
2025-04-24 16:28:16,428 - INFO - exists: True
2025-04-24 16:28:16,443 - INFO - factorize_layer_kron_svd
2025-04-24 16:28:17,882 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:28:19,145 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:28:20,374 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:28:21,527 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:28:22,825 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_q_proj.safetensors True
Layer: model.layers.27.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.2065467e-04 3.6923717e-05 1.8709072e-05 1.2459362e-05 1.2122801e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (824,4096), (4096,824)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)
2025-04-24 16:28:45,466 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=824, bias=False)
  (1): Linear(in_features=824, out_features=4096, bias=False)
)')
2025-04-24 16:28:45,466 - INFO - Replacing 'model.layers.27.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  84%|████████████████████████████████████████████████▉         | 190/225 [55:36<10:53, 18.67s/it]2025-04-24 16:28:45,466 - INFO - Layer: model.layers.27.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
2025-04-24 16:28:45,468 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_k_proj.safetensors
2025-04-24 16:28:45,468 - INFO - exists: True
2025-04-24 16:28:45,484 - INFO - factorize_layer_kron_svd
2025-04-24 16:28:46,973 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:28:48,401 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:28:49,609 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:28:50,743 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:28:52,414 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_k_proj.safetensors True
Layer: model.layers.27.self_attn.k_proj | Ratio: 0.300 -> Target Rank: 616 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [8.5674645e-04 2.3621626e-05 1.5614280e-05 1.0000707e-05 9.1756147e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (616,4096), (4096,616)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)
2025-04-24 16:29:29,514 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=616, bias=False)
  (1): Linear(in_features=616, out_features=4096, bias=False)
)')
2025-04-24 16:29:29,514 - INFO - Replacing 'model.layers.27.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  85%|█████████████████████████████████████████████████▏        | 191/225 [56:20<12:50, 22.67s/it]2025-04-24 16:29:29,515 - INFO - Layer: model.layers.27.self_attn.v_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
2025-04-24 16:29:29,515 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_v_proj.safetensors
2025-04-24 16:29:29,515 - INFO - exists: True
2025-04-24 16:29:29,533 - INFO - factorize_layer_kron_svd
2025-04-24 16:29:30,870 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:29:32,298 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:29:33,460 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:29:35,030 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_v_proj.safetensors True
Layer: model.layers.27.self_attn.v_proj | Ratio: 0.900 -> Target Rank: 1848 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.2262762e-04 1.2386496e-05 8.2811475e-06 5.6460581e-06 5.2539558e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1848,4096), (4096,1848)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)
2025-04-24 16:29:58,180 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1848, bias=False)
  (1): Linear(in_features=1848, out_features=4096, bias=False)
)')
2025-04-24 16:29:58,180 - INFO - Replacing 'model.layers.27.self_attn.v_proj' (attribute 'v_proj' within parent LlamaAttention)
Compressing Layers:  85%|█████████████████████████████████████████████████▍        | 192/225 [56:49<13:04, 23.78s/it]2025-04-24 16:29:58,180 - INFO - Layer: model.layers.27.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:29:58,181 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_o_proj.safetensors
2025-04-24 16:29:58,181 - INFO - exists: True
2025-04-24 16:29:58,200 - INFO - factorize_layer_kron_svd
2025-04-24 16:29:59,571 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:30:00,634 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:30:01,731 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:30:02,856 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:30:03,988 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:30:05,404 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:30:06,510 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:30:07,645 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:30:08,769 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:30:09,992 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:30:11,265 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:30:12,848 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_27_self_attn_o_proj.safetensors True
Layer: model.layers.27.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.6467215e-06 3.7391610e-06 3.0175340e-06 2.9309579e-06 2.8120503e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1640,4096), (4096,1640)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)
2025-04-24 16:30:45,771 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1640, bias=False)
  (1): Linear(in_features=1640, out_features=4096, bias=False)
)')
2025-04-24 16:30:45,771 - INFO - Replacing 'model.layers.27.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  86%|█████████████████████████████████████████████████▊        | 193/225 [57:36<15:19, 28.73s/it]2025-04-24 16:30:45,772 - INFO - Skipping layer model.layers.27.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:30:45,772 - INFO - Skipping layer model.layers.27.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:30:45,772 - INFO - Skipping layer model.layers.27.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:30:45,772 - INFO - Layer: model.layers.28.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:30:45,772 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_q_proj.safetensors
2025-04-24 16:30:45,772 - INFO - exists: True
2025-04-24 16:30:45,787 - INFO - factorize_layer_kron_svd
2025-04-24 16:30:47,209 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:30:48,629 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:30:49,824 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:30:51,219 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_q_proj.safetensors True
Layer: model.layers.28.self_attn.q_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.3855560e-03 3.4289329e-05 2.7094886e-05 1.8852646e-05 1.6840988e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:31:29,418 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:31:29,418 - INFO - Replacing 'model.layers.28.self_attn.q_proj' (attribute 'q_proj' within parent LlamaAttention)
Compressing Layers:  88%|██████████████████████████████████████████████████▊       | 197/225 [58:20<08:53, 19.05s/it]2025-04-24 16:31:29,418 - INFO - Layer: model.layers.28.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:31:29,420 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_k_proj.safetensors
2025-04-24 16:31:29,420 - INFO - exists: True
2025-04-24 16:31:29,436 - INFO - factorize_layer_kron_svd
2025-04-24 16:31:30,847 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:31:32,060 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:31:33,171 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:31:34,387 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_k_proj.safetensors True
Layer: model.layers.28.self_attn.k_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [1.9324456e-03 3.1512136e-05 2.3065544e-05 1.8104505e-05 1.3718930e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:32:11,813 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:32:11,813 - INFO - Replacing 'model.layers.28.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  88%|███████████████████████████████████████████████████       | 198/225 [59:03<10:16, 22.84s/it]2025-04-24 16:32:11,813 - INFO - Skipping layer model.layers.28.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:32:11,814 - INFO - Layer: model.layers.28.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:32:11,814 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_o_proj.safetensors
2025-04-24 16:32:11,814 - INFO - exists: True
2025-04-24 16:32:11,830 - INFO - factorize_layer_kron_svd
2025-04-24 16:32:13,124 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:32:14,258 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:32:15,365 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:32:16,481 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:32:17,587 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:32:18,845 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:32:19,970 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:32:21,051 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:32:22,184 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:32:23,418 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:32:24,883 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:32:26,685 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_self_attn_o_proj.safetensors True
Layer: model.layers.28.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [6.0813322e-06 3.6334923e-06 3.2903934e-06 3.1669369e-06 3.0863382e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:33:01,250 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:33:01,250 - INFO - Replacing 'model.layers.28.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  89%|███████████████████████████████████████████████████▌      | 200/225 [59:52<09:45, 23.44s/it]2025-04-24 16:33:01,251 - INFO - Layer: model.layers.28.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
2025-04-24 16:33:01,251 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_mlp_gate_proj.safetensors
2025-04-24 16:33:01,251 - INFO - exists: True
2025-04-24 16:33:01,291 - INFO - factorize_layer_kron_svd
2025-04-24 16:33:03,356 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:33:04,487 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:33:05,595 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:33:06,730 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:33:07,862 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:33:09,393 - INFO -   Factor is positive definite (alpha=1.00e+00)
2025-04-24 16:33:17,827 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:33:28,160 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:33:37,107 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)
2025-04-24 16:33:45,383 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)
2025-04-24 16:33:54,401 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)
2025-04-24 16:34:02,115 - INFO -   Factor is positive definite (alpha=1.00e+00)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_28_mlp_gate_proj.safetensors True
Layer: model.layers.28.mlp.gate_proj | Ratio: 0.900 -> Target Rank: 2688 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Regularizing factor (try 3, alpha=1.00e-03)
  Regularizing factor (try 4, alpha=1.00e-02)
  Regularizing factor (try 5, alpha=1.00e-01)
  Factor is positive definite (alpha=1.00e+00)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (11008x4096)...
  SVD complete. Singular values (top 5): [1.1478479e-05 8.4232897e-06 6.2309559e-06 5.6626295e-06 5.4233547e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (2688,4096), (11008,2688)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)
2025-04-24 16:35:20,888 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=2688, bias=False)
  (1): Linear(in_features=2688, out_features=11008, bias=False)
)')
2025-04-24 16:35:20,888 - INFO - Replacing 'model.layers.28.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)
Compressing Layers:  89%|██████████████████████████████████████████████████      | 201/225 [1:02:12<17:57, 44.89s/it]2025-04-24 16:35:20,889 - INFO - Skipping layer model.layers.28.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:35:20,889 - INFO - Skipping layer model.layers.28.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:35:20,889 - INFO - Layer: model.layers.29.self_attn.q_proj | Ratio: 0.400 -> Target Rank: 824 (Align: 8)
2025-04-24 16:35:20,891 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_q_proj.safetensors
2025-04-24 16:35:20,891 - INFO - exists: False
2025-04-24 16:35:20,891 - WARNING - Skipping layer model.layers.29.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_q_proj.safetensors
2025-04-24 16:35:20,891 - INFO - Layer: model.layers.29.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:35:20,891 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_k_proj.safetensors
2025-04-24 16:35:20,891 - INFO - exists: True
2025-04-24 16:35:20,923 - INFO - factorize_layer_kron_svd
2025-04-24 16:35:22,563 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:35:23,995 - INFO -   Factor is positive definite (alpha=1.00e-04)
2025-04-24 16:35:25,191 - INFO -   Factor is positive definite (alpha=1.00e-05)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_k_proj.safetensors True
Layer: model.layers.29.self_attn.k_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-05)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [3.3663202e-04 4.4211527e-05 2.5250516e-05 1.9198609e-05 1.3092749e-05]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1232,4096), (4096,1232)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)
2025-04-24 16:35:55,354 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1232, bias=False)
  (1): Linear(in_features=1232, out_features=4096, bias=False)
)')
2025-04-24 16:35:55,355 - INFO - Replacing 'model.layers.29.self_attn.k_proj' (attribute 'k_proj' within parent LlamaAttention)
Compressing Layers:  91%|███████████████████████████████████████████████████     | 205/225 [1:02:46<08:45, 26.27s/it]2025-04-24 16:35:55,355 - INFO - Skipping layer model.layers.29.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:35:55,355 - INFO - Layer: model.layers.29.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:35:55,356 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_o_proj.safetensors
2025-04-24 16:35:55,356 - INFO - exists: True
2025-04-24 16:35:55,377 - INFO - factorize_layer_kron_svd
2025-04-24 16:35:57,052 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:35:58,466 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)
2025-04-24 16:35:59,664 - INFO -   Factor is positive definite (alpha=1.00e-03)
2025-04-24 16:36:00,832 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)
2025-04-24 16:36:02,146 - INFO -   Factor is positive definite (alpha=1.00e-04)
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_29_self_attn_o_proj.safetensors True
Layer: model.layers.29.self_attn.o_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
factorize_layer_kron_svd
Regularizing factors for layer (initial alpha=1.00e-05)...
  Regularizing factor (try 1, alpha=1.00e-05)
  Regularizing factor (try 2, alpha=1.00e-04)
  Factor is positive definite (alpha=1.00e-03)
  Regularizing factor (try 1, alpha=1.00e-05)
  Factor is positive definite (alpha=1.00e-04)
  Cholesky decomposition successful.
  Performing SVD on transformed matrix (4096x4096)...
  SVD complete. Singular values (top 5): [5.9945382e-05 8.5975926e-06 2.6044404e-06 1.4789388e-06 1.0568257e-06]
  Cholesky factor inverses computed.
  Factorization complete for layer. New shapes: (1440,4096), (4096,1440)
factorized_sequential Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)
2025-04-24 16:36:22,670 - INFO - factorized_sequential 'Sequential(
  (0): Linear(in_features=4096, out_features=1440, bias=False)
  (1): Linear(in_features=1440, out_features=4096, bias=False)
)')
2025-04-24 16:36:22,670 - INFO - Replacing 'model.layers.29.self_attn.o_proj' (attribute 'o_proj' within parent LlamaAttention)
Compressing Layers:  92%|███████████████████████████████████████████████████▌    | 207/225 [1:03:13<06:51, 22.89s/it]2025-04-24 16:36:22,670 - INFO - Skipping layer model.layers.29.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,670 - INFO - Skipping layer model.layers.29.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,670 - INFO - Skipping layer model.layers.29.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,670 - INFO - Layer: model.layers.30.self_attn.q_proj | Ratio: 0.700 -> Target Rank: 1440 (Align: 8)
2025-04-24 16:36:22,672 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_q_proj.safetensors
2025-04-24 16:36:22,672 - INFO - exists: False
2025-04-24 16:36:22,672 - WARNING - Skipping layer model.layers.30.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_q_proj.safetensors
2025-04-24 16:36:22,672 - INFO - Layer: model.layers.30.self_attn.k_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:36:22,673 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_k_proj.safetensors
2025-04-24 16:36:22,673 - INFO - exists: False
2025-04-24 16:36:22,673 - WARNING - Skipping layer model.layers.30.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_k_proj.safetensors
2025-04-24 16:36:22,673 - INFO - Skipping layer model.layers.30.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,673 - INFO - Layer: model.layers.30.self_attn.o_proj | Ratio: 0.800 -> Target Rank: 1640 (Align: 8)
2025-04-24 16:36:22,673 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_o_proj.safetensors
2025-04-24 16:36:22,673 - INFO - exists: False
2025-04-24 16:36:22,673 - WARNING - Skipping layer model.layers.30.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_o_proj.safetensors
2025-04-24 16:36:22,673 - INFO - Skipping layer model.layers.30.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,673 - INFO - Skipping layer model.layers.30.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,673 - INFO - Skipping layer model.layers.30.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,673 - INFO - Layer: model.layers.31.self_attn.q_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:36:22,674 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_q_proj.safetensors
2025-04-24 16:36:22,674 - INFO - exists: False
2025-04-24 16:36:22,674 - WARNING - Skipping layer model.layers.31.self_attn.q_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_q_proj.safetensors
2025-04-24 16:36:22,674 - INFO - Layer: model.layers.31.self_attn.k_proj | Ratio: 0.500 -> Target Rank: 1024 (Align: 8)
2025-04-24 16:36:22,674 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_k_proj.safetensors
2025-04-24 16:36:22,674 - INFO - exists: False
2025-04-24 16:36:22,674 - WARNING - Skipping layer model.layers.31.self_attn.k_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_k_proj.safetensors
2025-04-24 16:36:22,674 - INFO - Skipping layer model.layers.31.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,674 - INFO - Layer: model.layers.31.self_attn.o_proj | Ratio: 0.600 -> Target Rank: 1232 (Align: 8)
2025-04-24 16:36:22,675 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_o_proj.safetensors
2025-04-24 16:36:22,675 - INFO - exists: False
2025-04-24 16:36:22,675 - WARNING - Skipping layer model.layers.31.self_attn.o_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_o_proj.safetensors
2025-04-24 16:36:22,675 - INFO - Skipping layer model.layers.31.mlp.gate_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,675 - INFO - Skipping layer model.layers.31.mlp.up_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,675 - INFO - Skipping layer model.layers.31.mlp.down_proj: Sensitivity ratio >= 1.0 (1.00). No compression.
2025-04-24 16:36:22,675 - INFO - Skipping layer lm_head: Sensitivity ratio >= 1.0 (1.00). No compression.
Compressing Layers: 100%|████████████████████████████████████████████████████████| 225/225 [1:03:13<00:00, 16.86s/it]
2025-04-24 16:36:22,675 - INFO - Compression finished. Processed: 87, Skipped (Ratio>=1 or No Sensitivity/Factors): 138, Failed: 0
2025-04-24 16:36:22,682 - INFO - Model compression statistics:
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_30_self_attn_o_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_q_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_k_proj.safetensors False
factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b/fisher_factors_output_1404/model_layers_31_self_attn_o_proj.safetensors False
Traceback (most recent call last):
  File "/home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/llama/compress_llama_with_kronsvd_llama2.py", line 553, in <module>
    logging.info(f"  Processed layers: {compression_stats['layers_processed']}")
                                        ^^^^^^^^^^^^^^^^^
NameError: name 'compression_stats' is not defined
