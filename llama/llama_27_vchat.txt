{'lm_head': 1, 'model.layers.31.mlp.gate_proj': 0.8, 'model.layers.31.mlp.up_proj': 0.8, 'model.layers.31.mlp.down_proj': 0.8, 'model.layers.31.self_attn.q_proj': 1, 'model.layers.31.self_attn.k_proj': 1, 'model.layers.31.self_attn.v_proj': 1, 'model.layers.31.self_attn.o_proj': 1, 'model.layers.30.mlp.gate_proj': 0.8, 'model.layers.30.mlp.up_proj': 0.8, 'model.layers.30.mlp.down_proj': 0.8, 'model.layers.30.self_attn.q_proj': 1, 'model.layers.30.self_attn.k_proj': 1, 'model.layers.30.self_attn.v_proj': 1, 'model.layers.30.self_attn.o_proj': 1, 'model.layers.29.mlp.gate_proj': 0.8, 'model.layers.29.mlp.up_proj': 0.8, 'model.layers.29.mlp.down_proj': 0.8, 'model.layers.29.self_attn.q_proj': 1, 'model.layers.29.self_attn.k_proj': 1, 'model.layers.29.self_attn.v_proj': 1, 'model.layers.29.self_attn.o_proj': 1, 'model.layers.28.mlp.gate_proj': 0.8, 'model.layers.28.mlp.up_proj': 0.8, 'model.layers.28.mlp.down_proj': 0.8, 'model.layers.28.self_attn.q_proj': 1, 'model.layers.28.self_attn.k_proj': 1, 'model.layers.28.self_attn.v_proj': 1, 'model.layers.28.self_attn.o_proj': 1, 'model.layers.27.mlp.gate_proj': 0.8, 'model.layers.27.mlp.up_proj': 0.8, 'model.layers.27.mlp.down_proj': 0.8, 'model.layers.27.self_attn.q_proj': 1, 'model.layers.27.self_attn.k_proj': 1, 'model.layers.27.self_attn.v_proj': 1, 'model.layers.27.self_attn.o_proj': 1, 'model.layers.26.mlp.gate_proj': 0.8, 'model.layers.26.mlp.up_proj': 0.8, 'model.layers.26.mlp.down_proj': 0.8, 'model.layers.26.self_attn.q_proj': 1, 'model.layers.26.self_attn.k_proj': 1, 'model.layers.26.self_attn.v_proj': 1, 'model.layers.26.self_attn.o_proj': 1, 'model.layers.25.mlp.gate_proj': 0.8, 'model.layers.25.mlp.up_proj': 0.8, 'model.layers.25.mlp.down_proj': 0.8, 'model.layers.25.self_attn.q_proj': 1, 'model.layers.25.self_attn.k_proj': 1, 'model.layers.25.self_attn.v_proj': 1, 'model.layers.25.self_attn.o_proj': 1, 'model.layers.24.mlp.gate_proj': 0.8, 'model.layers.24.mlp.up_proj': 0.8, 'model.layers.24.mlp.down_proj': 0.8, 'model.layers.24.self_attn.q_proj': 1, 'model.layers.24.self_attn.k_proj': 1, 'model.layers.24.self_attn.v_proj': 1, 'model.layers.24.self_attn.o_proj': 1, 'model.layers.23.mlp.gate_proj': 0.8, 'model.layers.23.mlp.up_proj': 0.8, 'model.layers.23.mlp.down_proj': 0.8, 'model.layers.23.self_attn.q_proj': 1, 'model.layers.23.self_attn.k_proj': 1, 'model.layers.23.self_attn.v_proj': 1, 'model.layers.23.self_attn.o_proj': 1, 'model.layers.22.mlp.gate_proj': 0.8, 'model.layers.22.mlp.up_proj': 0.8, 'model.layers.22.mlp.down_proj': 0.8, 'model.layers.22.self_attn.q_proj': 1, 'model.layers.22.self_attn.k_proj': 1, 'model.layers.22.self_attn.v_proj': 1, 'model.layers.22.self_attn.o_proj': 1, 'model.layers.21.mlp.gate_proj': 0.8, 'model.layers.21.mlp.up_proj': 0.8, 'model.layers.21.mlp.down_proj': 0.8, 'model.layers.21.self_attn.q_proj': 1, 'model.layers.21.self_attn.k_proj': 1, 'model.layers.21.self_attn.v_proj': 1, 'model.layers.21.self_attn.o_proj': 1, 'model.layers.20.mlp.gate_proj': 0.8, 'model.layers.20.mlp.up_proj': 0.8, 'model.layers.20.mlp.down_proj': 0.8, 'model.layers.20.self_attn.q_proj': 1, 'model.layers.20.self_attn.k_proj': 1, 'model.layers.20.self_attn.v_proj': 1, 'model.layers.20.self_attn.o_proj': 1, 'model.layers.19.mlp.gate_proj': 0.8, 'model.layers.19.mlp.up_proj': 0.8, 'model.layers.19.mlp.down_proj': 0.8, 'model.layers.19.self_attn.q_proj': 1, 'model.layers.19.self_attn.k_proj': 1, 'model.layers.19.self_attn.v_proj': 1, 'model.layers.19.self_attn.o_proj': 1, 'model.layers.18.mlp.gate_proj': 0.8, 'model.layers.18.mlp.up_proj': 0.8, 'model.layers.18.mlp.down_proj': 0.8, 'model.layers.18.self_attn.q_proj': 1, 'model.layers.18.self_attn.k_proj': 1, 'model.layers.18.self_attn.v_proj': 1, 'model.layers.18.self_attn.o_proj': 1, 'model.layers.17.mlp.gate_proj': 0.8, 'model.layers.17.mlp.up_proj': 0.8, 'model.layers.17.mlp.down_proj': 0.8, 'model.layers.17.self_attn.q_proj': 1, 'model.layers.17.self_attn.k_proj': 1, 'model.layers.17.self_attn.v_proj': 1, 'model.layers.17.self_attn.o_proj': 1, 'model.layers.16.mlp.gate_proj': 0.8, 'model.layers.16.mlp.up_proj': 0.8, 'model.layers.16.mlp.down_proj': 0.8, 'model.layers.16.self_attn.q_proj': 1, 'model.layers.16.self_attn.k_proj': 1, 'model.layers.16.self_attn.v_proj': 1, 'model.layers.16.self_attn.o_proj': 1, 'model.layers.15.mlp.gate_proj': 0.8, 'model.layers.15.mlp.up_proj': 0.8, 'model.layers.15.mlp.down_proj': 0.8, 'model.layers.15.self_attn.q_proj': 1, 'model.layers.15.self_attn.k_proj': 1, 'model.layers.15.self_attn.v_proj': 1, 'model.layers.15.self_attn.o_proj': 1, 'model.layers.14.mlp.gate_proj': 0.8, 'model.layers.14.mlp.up_proj': 0.8, 'model.layers.14.mlp.down_proj': 0.8, 'model.layers.14.self_attn.q_proj': 1, 'model.layers.14.self_attn.k_proj': 1, 'model.layers.14.self_attn.v_proj': 1, 'model.layers.14.self_attn.o_proj': 1, 'model.layers.13.mlp.gate_proj': 0.8, 'model.layers.13.mlp.up_proj': 0.8, 'model.layers.13.mlp.down_proj': 0.8, 'model.layers.13.self_attn.q_proj': 1, 'model.layers.13.self_attn.k_proj': 1, 'model.layers.13.self_attn.v_proj': 1, 'model.layers.13.self_attn.o_proj': 1, 'model.layers.12.mlp.gate_proj': 0.8, 'model.layers.12.mlp.up_proj': 0.8, 'model.layers.12.mlp.down_proj': 0.8, 'model.layers.12.self_attn.q_proj': 1, 'model.layers.12.self_attn.k_proj': 1, 'model.layers.12.self_attn.v_proj': 1, 'model.layers.12.self_attn.o_proj': 1, 'model.layers.11.mlp.gate_proj': 0.8, 'model.layers.11.mlp.up_proj': 0.8, 'model.layers.11.mlp.down_proj': 0.8, 'model.layers.11.self_attn.q_proj': 1, 'model.layers.11.self_attn.k_proj': 1, 'model.layers.11.self_attn.v_proj': 1, 'model.layers.11.self_attn.o_proj': 1, 'model.layers.10.mlp.gate_proj': 0.8, 'model.layers.10.mlp.up_proj': 0.8, 'model.layers.10.mlp.down_proj': 0.8, 'model.layers.10.self_attn.q_proj': 1, 'model.layers.10.self_attn.k_proj': 1, 'model.layers.10.self_attn.v_proj': 1, 'model.layers.10.self_attn.o_proj': 1, 'model.layers.9.mlp.gate_proj': 0.8, 'model.layers.9.mlp.up_proj': 0.8, 'model.layers.9.mlp.down_proj': 0.8, 'model.layers.9.self_attn.q_proj': 1, 'model.layers.9.self_attn.k_proj': 1, 'model.layers.9.self_attn.v_proj': 1, 'model.layers.9.self_attn.o_proj': 1, 'model.layers.8.mlp.gate_proj': 0.8, 'model.layers.8.mlp.up_proj': 0.8, 'model.layers.8.mlp.down_proj': 0.8, 'model.layers.8.self_attn.q_proj': 1, 'model.layers.8.self_attn.k_proj': 1, 'model.layers.8.self_attn.v_proj': 1, 'model.layers.8.self_attn.o_proj': 1, 'model.layers.7.mlp.gate_proj': 0.8, 'model.layers.7.mlp.up_proj': 0.8, 'model.layers.7.mlp.down_proj': 0.8, 'model.layers.7.self_attn.q_proj': 1, 'model.layers.7.self_attn.k_proj': 1, 'model.layers.7.self_attn.v_proj': 1, 'model.layers.7.self_attn.o_proj': 1, 'model.layers.6.mlp.gate_proj': 0.8, 'model.layers.6.mlp.up_proj': 0.8, 'model.layers.6.mlp.down_proj': 0.8, 'model.layers.6.self_attn.q_proj': 1, 'model.layers.6.self_attn.k_proj': 1, 'model.layers.6.self_attn.v_proj': 1, 'model.layers.6.self_attn.o_proj': 1, 'model.layers.5.mlp.gate_proj': 0.8, 'model.layers.5.mlp.up_proj': 0.8, 'model.layers.5.mlp.down_proj': 0.8, 'model.layers.5.self_attn.q_proj': 1, 'model.layers.5.self_attn.k_proj': 1, 'model.layers.5.self_attn.v_proj': 1, 'model.layers.5.self_attn.o_proj': 1, 'model.layers.4.mlp.gate_proj': 0.8, 'model.layers.4.mlp.up_proj': 0.8, 'model.layers.4.mlp.down_proj': 0.8, 'model.layers.4.self_attn.q_proj': 1, 'model.layers.4.self_attn.k_proj': 1, 'model.layers.4.self_attn.v_proj': 1, 'model.layers.4.self_attn.o_proj': 1, 'model.layers.3.mlp.gate_proj': 0.8, 'model.layers.3.mlp.up_proj': 0.8, 'model.layers.3.mlp.down_proj': 0.8, 'model.layers.3.self_attn.q_proj': 1, 'model.layers.3.self_attn.k_proj': 1, 'model.layers.3.self_attn.v_proj': 1, 'model.layers.3.self_attn.o_proj': 1, 'model.layers.2.mlp.gate_proj': 0.8, 'model.layers.2.mlp.up_proj': 0.8, 'model.layers.2.mlp.down_proj': 0.8, 'model.layers.2.self_attn.q_proj': 1, 'model.layers.2.self_attn.k_proj': 1, 'model.layers.2.self_attn.v_proj': 1, 'model.layers.2.self_attn.o_proj': 1, 'model.layers.1.mlp.gate_proj': 0.8, 'model.layers.1.mlp.up_proj': 0.8, 'model.layers.1.mlp.down_proj': 0.8, 'model.layers.1.self_attn.q_proj': 1, 'model.layers.1.self_attn.k_proj': 1, 'model.layers.1.self_attn.v_proj': 1, 'model.layers.1.self_attn.o_proj': 1, 'model.layers.0.mlp.gate_proj': 0.8, 'model.layers.0.mlp.up_proj': 0.8, 'model.layers.0.mlp.down_proj': 0.8, 'model.layers.0.self_attn.q_proj': 1, 'model.layers.0.self_attn.k_proj': 1, 'model.layers.0.self_attn.v_proj': 1, 'model.layers.0.self_attn.o_proj': 1}2025-04-25 09:48:51,215 - INFO - Loading model: unsloth/llama-2-7b-chat[2025-04-25 09:48:56,158] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)Warning: The cache directory for DeepSpeed Triton autotune, /home/jovyan/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.Loading checkpoint shards:   0%|                                       | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|██████████▎                    | 1/3 [00:10<00:21, 10.59s/it]Loading checkpoint shards:  67%|████████████████████▋          | 2/3 [00:18<00:09,  9.20s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:22<00:00,  6.60s/it]Loading checkpoint shards: 100%|███████████████████████████████| 3/3 [00:22<00:00,  7.44s/it]2025-04-25 09:49:20,521 - INFO - Model loaded with dtype torch.bfloat162025-04-25 09:50:03,444 - INFO - Model moved to cuda:02025-04-25 09:50:03,445 - INFO - Found 225 linear layers to potentially compress.Compressing Layers:   0%|                                            | 0/225 [00:00<?, ?it/s]2025-04-25 09:50:03,446 - INFO - Skipping layer model.layers.0.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:50:03,446 - INFO - Skipping layer model.layers.0.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:50:03,446 - INFO - Skipping layer model.layers.0.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:50:03,446 - INFO - Skipping layer model.layers.0.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:50:03,446 - INFO - Layer: model.layers.0.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:50:03,446 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_gate_proj.safetensors2025-04-25 09:50:03,446 - INFO - exists: True2025-04-25 09:50:03,450 - INFO - factorize_layer_kron_svd2025-04-25 09:50:10,558 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:50:13,345 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:50:19,370 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 09:50:26,674 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:50:40,750 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_gate_proj.safetensors TrueLayer: model.layers.0.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [8.1718399e-04 2.9179015e-05 1.2629871e-05 1.1120813e-05 5.3344133e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 09:51:42,612 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 09:51:42,612 - INFO - Replacing 'model.layers.0.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:   2%|▊                                 | 5/225 [01:39<1:12:43, 19.83s/it]2025-04-25 09:51:42,613 - INFO - Layer: model.layers.0.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:51:42,614 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_up_proj.safetensors2025-04-25 09:51:42,614 - INFO - exists: True2025-04-25 09:51:42,642 - INFO - factorize_layer_kron_svd2025-04-25 09:51:47,434 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:51:48,661 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:51:49,914 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 09:51:51,662 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:51:55,333 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_up_proj.safetensors TrueLayer: model.layers.0.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [4.4869381e-04 9.4277355e-05 2.2874417e-05 1.9138701e-05 1.4721376e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 09:52:46,546 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 09:52:46,547 - INFO - Replacing 'model.layers.0.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:   3%|▉                                 | 6/225 [02:43<1:48:09, 29.63s/it]2025-04-25 09:52:46,547 - INFO - Layer: model.layers.0.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:52:46,550 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_down_proj.safetensors2025-04-25 09:52:46,550 - INFO - exists: True2025-04-25 09:52:46,571 - INFO - factorize_layer_kron_svd2025-04-25 09:52:48,910 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:52:50,698 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:52:52,459 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:52:54,244 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:52:56,026 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:53:01,259 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 09:53:02,291 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:53:03,353 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:53:04,396 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:53:05,457 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:53:06,505 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:53:07,703 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_0_mlp_down_proj.safetensors TrueLayer: model.layers.0.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [8.8298384e-06 6.1057090e-06 5.6111639e-06 5.3944013e-06 5.1141064e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 09:54:16,526 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 09:54:16,526 - INFO - Replacing 'model.layers.0.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:   3%|█                                 | 7/225 [04:13<2:40:30, 44.17s/it]2025-04-25 09:54:16,527 - INFO - Skipping layer model.layers.1.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:54:16,527 - INFO - Skipping layer model.layers.1.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:54:16,527 - INFO - Skipping layer model.layers.1.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:54:16,527 - INFO - Skipping layer model.layers.1.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:54:16,527 - INFO - Layer: model.layers.1.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:54:16,530 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_gate_proj.safetensors2025-04-25 09:54:16,530 - INFO - exists: True2025-04-25 09:54:16,547 - INFO - factorize_layer_kron_svd2025-04-25 09:54:18,385 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:54:19,472 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:54:20,545 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:54:21,583 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:54:22,625 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:54:23,878 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 09:54:25,457 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:54:27,280 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:54:29,071 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:54:30,865 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:54:32,750 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:54:36,499 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_gate_proj.safetensors TrueLayer: model.layers.1.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.4005915e-05 9.7339671e-06 8.9150799e-06 8.8396546e-06 8.2917913e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 09:55:42,841 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 09:55:42,842 - INFO - Replacing 'model.layers.1.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:   5%|█▊                               | 12/225 [05:39<1:36:23, 27.15s/it]2025-04-25 09:55:42,842 - INFO - Layer: model.layers.1.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:55:42,844 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_up_proj.safetensors2025-04-25 09:55:42,844 - INFO - exists: True2025-04-25 09:55:42,861 - INFO - factorize_layer_kron_svd2025-04-25 09:55:44,660 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:55:45,844 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:55:47,072 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 09:55:48,701 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:55:52,341 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_up_proj.safetensors TrueLayer: model.layers.1.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [8.3380165e-03 1.2735171e-05 4.8180482e-06 1.3797395e-06 1.0792503e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 09:56:59,675 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 09:56:59,675 - INFO - Replacing 'model.layers.1.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:   6%|█▉                               | 13/225 [06:56<2:02:48, 34.76s/it]2025-04-25 09:56:59,675 - INFO - Layer: model.layers.1.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:56:59,678 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_down_proj.safetensors2025-04-25 09:56:59,678 - INFO - exists: False2025-04-25 09:56:59,678 - WARNING - Skipping layer model.layers.1.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_down_proj.safetensors2025-04-25 09:56:59,678 - INFO - Skipping layer model.layers.2.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:56:59,678 - INFO - Skipping layer model.layers.2.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:56:59,678 - INFO - Skipping layer model.layers.2.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:56:59,678 - INFO - Skipping layer model.layers.2.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:56:59,678 - INFO - Layer: model.layers.2.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:56:59,679 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_gate_proj.safetensors2025-04-25 09:56:59,679 - INFO - exists: True2025-04-25 09:56:59,695 - INFO - factorize_layer_kron_svd2025-04-25 09:57:01,504 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:57:02,563 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:57:03,644 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:57:04,702 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:57:05,751 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:57:06,994 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 09:57:08,574 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:57:10,395 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:57:12,175 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 09:57:13,984 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 09:57:15,794 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 09:57:19,226 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_1_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_gate_proj.safetensors TrueLayer: model.layers.2.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.0536157e-05 7.8889116e-06 7.3416263e-06 6.9958951e-06 6.9346693e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 09:58:19,496 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 09:58:19,496 - INFO - Replacing 'model.layers.2.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:   8%|██▊                              | 19/225 [08:16<1:17:32, 22.58s/it]2025-04-25 09:58:19,497 - INFO - Layer: model.layers.2.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:58:19,499 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_up_proj.safetensors2025-04-25 09:58:19,499 - INFO - exists: False2025-04-25 09:58:19,499 - WARNING - Skipping layer model.layers.2.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_up_proj.safetensors2025-04-25 09:58:19,499 - INFO - Layer: model.layers.2.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:58:19,500 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_down_proj.safetensors2025-04-25 09:58:19,500 - INFO - exists: True2025-04-25 09:58:19,516 - INFO - factorize_layer_kron_svd2025-04-25 09:58:22,549 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:58:26,228 - INFO -   Factor is positive definite (alpha=1.00e-04)2025-04-25 09:58:27,268 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:58:28,413 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:58:29,669 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_2_mlp_down_proj.safetensors TrueLayer: model.layers.2.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [9.0164710e-03 9.7567434e-05 5.4176409e-05 2.1932610e-05 1.9526537e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 09:59:38,848 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 09:59:38,849 - INFO - Replacing 'model.layers.2.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:   9%|███                              | 21/225 [09:35<1:29:08, 26.22s/it]2025-04-25 09:59:38,849 - INFO - Skipping layer model.layers.3.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:59:38,849 - INFO - Skipping layer model.layers.3.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:59:38,849 - INFO - Skipping layer model.layers.3.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:59:38,849 - INFO - Skipping layer model.layers.3.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 09:59:38,849 - INFO - Layer: model.layers.3.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:59:38,852 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors2025-04-25 09:59:38,852 - INFO - exists: False2025-04-25 09:59:38,852 - WARNING - Skipping layer model.layers.3.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors2025-04-25 09:59:38,852 - INFO - Layer: model.layers.3.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:59:38,852 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_up_proj.safetensors2025-04-25 09:59:38,852 - INFO - exists: False2025-04-25 09:59:38,852 - WARNING - Skipping layer model.layers.3.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_up_proj.safetensors2025-04-25 09:59:38,852 - INFO - Layer: model.layers.3.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 09:59:38,853 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_down_proj.safetensors2025-04-25 09:59:38,853 - INFO - exists: True2025-04-25 09:59:38,870 - INFO - factorize_layer_kron_svd2025-04-25 09:59:41,695 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:59:45,056 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 09:59:48,693 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 09:59:49,771 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 09:59:51,036 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_3_mlp_down_proj.safetensors TrueLayer: model.layers.3.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [2.5388924e-03 3.4759837e-04 1.6566851e-04 1.1550266e-04 6.5852117e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:01:07,145 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:01:07,145 - INFO - Replacing 'model.layers.3.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  12%|████                             | 28/225 [11:03<1:03:03, 19.21s/it]2025-04-25 10:01:07,145 - INFO - Skipping layer model.layers.4.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:01:07,145 - INFO - Skipping layer model.layers.4.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:01:07,146 - INFO - Skipping layer model.layers.4.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:01:07,146 - INFO - Skipping layer model.layers.4.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:01:07,146 - INFO - Layer: model.layers.4.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:01:07,158 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors2025-04-25 10:01:07,158 - INFO - exists: False2025-04-25 10:01:07,158 - WARNING - Skipping layer model.layers.4.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors2025-04-25 10:01:07,158 - INFO - Layer: model.layers.4.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:01:07,159 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_up_proj.safetensors2025-04-25 10:01:07,159 - INFO - exists: True2025-04-25 10:01:07,175 - INFO - factorize_layer_kron_svd2025-04-25 10:01:08,917 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:01:09,975 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:01:11,009 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:01:12,049 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:01:13,104 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:01:14,350 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:01:15,892 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:01:17,681 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:01:19,465 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:01:21,238 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:01:23,017 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:01:26,650 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_up_proj.safetensors TrueLayer: model.layers.4.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [4.2674606e-06 3.9633169e-06 3.8188300e-06 3.7764739e-06 3.7316508e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:02:34,576 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:02:34,577 - INFO - Replacing 'model.layers.4.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  15%|█████▎                             | 34/225 [12:31<55:25, 17.41s/it]2025-04-25 10:02:34,577 - INFO - Layer: model.layers.4.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:02:34,579 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors2025-04-25 10:02:34,579 - INFO - exists: False2025-04-25 10:02:34,579 - WARNING - Skipping layer model.layers.4.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors2025-04-25 10:02:34,579 - INFO - Skipping layer model.layers.5.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:02:34,580 - INFO - Skipping layer model.layers.5.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:02:34,580 - INFO - Skipping layer model.layers.5.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:02:34,580 - INFO - Skipping layer model.layers.5.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:02:34,580 - INFO - Layer: model.layers.5.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:02:34,580 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_gate_proj.safetensors2025-04-25 10:02:34,580 - INFO - exists: False2025-04-25 10:02:34,580 - WARNING - Skipping layer model.layers.5.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_gate_proj.safetensors2025-04-25 10:02:34,580 - INFO - Layer: model.layers.5.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:02:34,581 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_up_proj.safetensors2025-04-25 10:02:34,581 - INFO - exists: False2025-04-25 10:02:34,581 - WARNING - Skipping layer model.layers.5.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_up_proj.safetensors2025-04-25 10:02:34,581 - INFO - Layer: model.layers.5.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:02:34,581 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_down_proj.safetensors2025-04-25 10:02:34,581 - INFO - exists: True2025-04-25 10:02:34,600 - INFO - factorize_layer_kron_svd2025-04-25 10:02:37,182 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:02:40,452 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:02:43,994 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:02:45,047 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:02:46,247 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:02:47,501 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_4_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_5_mlp_down_proj.safetensors TrueLayer: model.layers.5.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [4.2569707e-03 5.2021828e-04 9.3271483e-05 6.7189409e-05 5.4636472e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:04:02,449 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:04:02,450 - INFO - Replacing 'model.layers.5.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  19%|██████▌                            | 42/225 [13:59<44:47, 14.69s/it]2025-04-25 10:04:02,450 - INFO - Skipping layer model.layers.6.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:04:02,450 - INFO - Skipping layer model.layers.6.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:04:02,450 - INFO - Skipping layer model.layers.6.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:04:02,450 - INFO - Skipping layer model.layers.6.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:04:02,450 - INFO - Layer: model.layers.6.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:04:02,452 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_gate_proj.safetensors2025-04-25 10:04:02,452 - INFO - exists: True2025-04-25 10:04:02,468 - INFO - factorize_layer_kron_svd2025-04-25 10:04:04,272 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:04:05,301 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:04:06,332 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:04:07,359 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:04:08,381 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:04:09,629 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:04:11,188 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:04:13,019 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:04:14,826 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:04:16,627 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:04:18,420 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:04:22,056 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_gate_proj.safetensors TrueLayer: model.layers.6.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.3830311e-05 7.5414341e-06 7.1951326e-06 7.1753102e-06 6.8685222e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:05:29,457 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:05:29,457 - INFO - Replacing 'model.layers.6.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  21%|███████▎                           | 47/225 [15:26<45:46, 15.43s/it]2025-04-25 10:05:29,457 - INFO - Layer: model.layers.6.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:05:29,460 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_up_proj.safetensors2025-04-25 10:05:29,460 - INFO - exists: False2025-04-25 10:05:29,460 - WARNING - Skipping layer model.layers.6.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_up_proj.safetensors2025-04-25 10:05:29,460 - INFO - Layer: model.layers.6.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:05:29,461 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_down_proj.safetensors2025-04-25 10:05:29,461 - INFO - exists: True2025-04-25 10:05:29,478 - INFO - factorize_layer_kron_svd2025-04-25 10:05:33,271 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:05:36,935 - INFO -   Factor is positive definite (alpha=1.00e-04)2025-04-25 10:05:37,988 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:05:39,153 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:05:40,391 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_6_mlp_down_proj.safetensors TrueLayer: model.layers.6.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [1.1730455e-02 7.5274904e-05 5.8971975e-05 3.9316310e-05 2.7261001e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:06:36,324 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:06:36,325 - INFO - Replacing 'model.layers.6.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  22%|███████▌                           | 49/225 [16:32<52:25, 17.87s/it]2025-04-25 10:06:36,325 - INFO - Skipping layer model.layers.7.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:06:36,325 - INFO - Skipping layer model.layers.7.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:06:36,325 - INFO - Skipping layer model.layers.7.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:06:36,325 - INFO - Skipping layer model.layers.7.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:06:36,325 - INFO - Layer: model.layers.7.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:06:36,327 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_gate_proj.safetensors2025-04-25 10:06:36,328 - INFO - exists: True2025-04-25 10:06:36,348 - INFO - factorize_layer_kron_svd2025-04-25 10:06:38,222 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:06:39,433 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:06:40,682 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:06:42,447 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:06:45,576 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_gate_proj.safetensors TrueLayer: model.layers.7.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [6.1598225e-03 4.3083266e-05 2.9594266e-05 2.0862246e-05 1.8714514e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:07:32,295 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:07:32,296 - INFO - Replacing 'model.layers.7.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  24%|████████▍                          | 54/225 [17:28<44:43, 15.69s/it]2025-04-25 10:07:32,297 - INFO - Layer: model.layers.7.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:07:32,298 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_up_proj.safetensors2025-04-25 10:07:32,298 - INFO - exists: True2025-04-25 10:07:32,318 - INFO - factorize_layer_kron_svd2025-04-25 10:07:34,275 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:07:35,462 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:07:36,699 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:07:38,401 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:07:41,521 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_up_proj.safetensors TrueLayer: model.layers.7.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [2.8216012e-03 3.8601193e-05 2.6869149e-05 2.3445984e-05 1.8939305e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:08:28,754 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:08:28,754 - INFO - Replacing 'model.layers.7.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  24%|████████▌                          | 55/225 [18:25<54:19, 19.17s/it]2025-04-25 10:08:28,754 - INFO - Layer: model.layers.7.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:08:28,757 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_down_proj.safetensors2025-04-25 10:08:28,757 - INFO - exists: False2025-04-25 10:08:28,757 - WARNING - Skipping layer model.layers.7.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_down_proj.safetensors2025-04-25 10:08:28,757 - INFO - Skipping layer model.layers.8.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:08:28,757 - INFO - Skipping layer model.layers.8.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:08:28,757 - INFO - Skipping layer model.layers.8.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:08:28,757 - INFO - Skipping layer model.layers.8.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:08:28,757 - INFO - Layer: model.layers.8.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:08:28,758 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_gate_proj.safetensors2025-04-25 10:08:28,758 - INFO - exists: False2025-04-25 10:08:28,758 - WARNING - Skipping layer model.layers.8.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_gate_proj.safetensors2025-04-25 10:08:28,758 - INFO - Layer: model.layers.8.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:08:28,758 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_up_proj.safetensors2025-04-25 10:08:28,758 - INFO - exists: True2025-04-25 10:08:28,775 - INFO - factorize_layer_kron_svd2025-04-25 10:08:30,566 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:08:31,640 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:08:32,688 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:08:33,763 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:08:34,817 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:08:36,083 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:08:37,659 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:08:39,455 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:08:41,215 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:08:42,978 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:08:44,822 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:08:48,434 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_7_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_up_proj.safetensors TrueLayer: model.layers.8.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.3510244e-06 4.6259770e-06 4.5105817e-06 4.3957298e-06 4.3850546e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:09:57,122 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:09:57,122 - INFO - Replacing 'model.layers.8.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  28%|█████████▋                         | 62/225 [19:53<43:53, 16.16s/it]2025-04-25 10:09:57,123 - INFO - Layer: model.layers.8.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:09:57,126 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_down_proj.safetensors2025-04-25 10:09:57,126 - INFO - exists: False2025-04-25 10:09:57,126 - WARNING - Skipping layer model.layers.8.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_down_proj.safetensors2025-04-25 10:09:57,126 - INFO - Skipping layer model.layers.9.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:09:57,126 - INFO - Skipping layer model.layers.9.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:09:57,126 - INFO - Skipping layer model.layers.9.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:09:57,126 - INFO - Skipping layer model.layers.9.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:09:57,126 - INFO - Layer: model.layers.9.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:09:57,126 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_gate_proj.safetensors2025-04-25 10:09:57,126 - INFO - exists: False2025-04-25 10:09:57,126 - WARNING - Skipping layer model.layers.9.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_gate_proj.safetensors2025-04-25 10:09:57,126 - INFO - Layer: model.layers.9.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:09:57,127 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_up_proj.safetensors2025-04-25 10:09:57,127 - INFO - exists: False2025-04-25 10:09:57,127 - WARNING - Skipping layer model.layers.9.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_up_proj.safetensors2025-04-25 10:09:57,127 - INFO - Layer: model.layers.9.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:09:57,127 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_down_proj.safetensors2025-04-25 10:09:57,127 - INFO - exists: True2025-04-25 10:09:57,146 - INFO - factorize_layer_kron_svd2025-04-25 10:10:01,139 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:10:04,015 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:10:07,640 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:10:08,698 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:10:09,915 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:10:11,172 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_8_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_9_mlp_down_proj.safetensors TrueLayer: model.layers.9.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [2.8424084e-02 1.8538581e-04 1.7036285e-04 1.0448481e-04 9.5918804e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:11:22,528 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:11:22,528 - INFO - Replacing 'model.layers.9.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  31%|██████████▉                        | 70/225 [21:19<35:39, 13.81s/it]2025-04-25 10:11:22,529 - INFO - Skipping layer model.layers.10.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:11:22,529 - INFO - Skipping layer model.layers.10.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:11:22,529 - INFO - Skipping layer model.layers.10.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:11:22,529 - INFO - Skipping layer model.layers.10.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:11:22,529 - INFO - Layer: model.layers.10.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:11:22,554 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_gate_proj.safetensors2025-04-25 10:11:22,554 - INFO - exists: False2025-04-25 10:11:22,554 - WARNING - Skipping layer model.layers.10.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_gate_proj.safetensors2025-04-25 10:11:22,554 - INFO - Layer: model.layers.10.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:11:22,565 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_up_proj.safetensors2025-04-25 10:11:22,565 - INFO - exists: True2025-04-25 10:11:22,639 - INFO - factorize_layer_kron_svd2025-04-25 10:11:27,724 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:11:28,920 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:11:30,162 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:11:31,764 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:11:35,215 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_up_proj.safetensors TrueLayer: model.layers.10.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [2.4830976e-03 1.3603101e-04 2.3816692e-05 2.0194741e-05 1.6129978e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:12:29,207 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:12:29,208 - INFO - Replacing 'model.layers.10.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  34%|███████████▊                       | 76/225 [22:25<32:10, 12.96s/it]2025-04-25 10:12:29,208 - INFO - Layer: model.layers.10.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:12:29,219 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_down_proj.safetensors2025-04-25 10:12:29,219 - INFO - exists: False2025-04-25 10:12:29,219 - WARNING - Skipping layer model.layers.10.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_down_proj.safetensors2025-04-25 10:12:29,219 - INFO - Skipping layer model.layers.11.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:12:29,219 - INFO - Skipping layer model.layers.11.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:12:29,219 - INFO - Skipping layer model.layers.11.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:12:29,219 - INFO - Skipping layer model.layers.11.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:12:29,219 - INFO - Layer: model.layers.11.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:12:29,220 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_gate_proj.safetensors2025-04-25 10:12:29,220 - INFO - exists: False2025-04-25 10:12:29,220 - WARNING - Skipping layer model.layers.11.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_gate_proj.safetensors2025-04-25 10:12:29,220 - INFO - Layer: model.layers.11.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:12:29,221 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_up_proj.safetensors2025-04-25 10:12:29,221 - INFO - exists: False2025-04-25 10:12:29,221 - WARNING - Skipping layer model.layers.11.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_up_proj.safetensors2025-04-25 10:12:29,221 - INFO - Layer: model.layers.11.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:12:29,225 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_down_proj.safetensors2025-04-25 10:12:29,225 - INFO - exists: True2025-04-25 10:12:29,267 - INFO - factorize_layer_kron_svd2025-04-25 10:12:31,805 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:12:33,632 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:12:35,408 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:12:37,173 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:12:38,936 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:12:41,912 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:12:42,940 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:12:43,984 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:12:45,042 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:12:46,090 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:12:47,146 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:12:48,366 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_10_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_11_mlp_down_proj.safetensors TrueLayer: model.layers.11.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [7.3898063e-06 5.6267804e-06 5.3947410e-06 5.2994505e-06 5.2197383e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:13:47,728 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:13:47,728 - INFO - Replacing 'model.layers.11.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  37%|█████████████                      | 84/225 [23:44<27:40, 11.78s/it]2025-04-25 10:13:47,729 - INFO - Skipping layer model.layers.12.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:13:47,729 - INFO - Skipping layer model.layers.12.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:13:47,729 - INFO - Skipping layer model.layers.12.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:13:47,729 - INFO - Skipping layer model.layers.12.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:13:47,729 - INFO - Layer: model.layers.12.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:13:47,739 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_gate_proj.safetensors2025-04-25 10:13:47,740 - INFO - exists: True2025-04-25 10:13:47,759 - INFO - factorize_layer_kron_svd2025-04-25 10:13:49,671 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:13:50,716 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:13:51,753 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:13:52,789 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:13:53,845 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:13:55,065 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:13:56,650 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:13:58,419 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:14:00,169 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:14:01,935 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:14:03,709 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:14:07,257 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_gate_proj.safetensors TrueLayer: model.layers.12.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.2988171e-05 7.1681275e-06 6.5595987e-06 6.5212694e-06 6.4388596e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:15:11,493 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:15:11,494 - INFO - Replacing 'model.layers.12.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  40%|█████████████▊                     | 89/225 [25:08<29:31, 13.03s/it]2025-04-25 10:15:11,494 - INFO - Layer: model.layers.12.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:15:11,497 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_up_proj.safetensors2025-04-25 10:15:11,497 - INFO - exists: False2025-04-25 10:15:11,497 - WARNING - Skipping layer model.layers.12.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_up_proj.safetensors2025-04-25 10:15:11,497 - INFO - Layer: model.layers.12.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:15:11,497 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_down_proj.safetensors2025-04-25 10:15:11,497 - INFO - exists: True2025-04-25 10:15:11,514 - INFO - factorize_layer_kron_svd2025-04-25 10:15:13,967 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:15:15,765 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:15:17,515 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:15:19,294 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:15:21,075 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:15:24,588 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:15:25,609 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:15:26,629 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:15:27,652 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:15:28,673 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:15:29,697 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:15:30,883 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_12_mlp_down_proj.safetensors TrueLayer: model.layers.12.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [6.7547603e-06 5.6931804e-06 5.4988618e-06 5.3369122e-06 5.2610458e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:16:44,167 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:16:44,168 - INFO - Replacing 'model.layers.12.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  40%|██████████████▏                    | 91/225 [26:40<38:25, 17.20s/it]2025-04-25 10:16:44,168 - INFO - Skipping layer model.layers.13.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:16:44,168 - INFO - Skipping layer model.layers.13.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:16:44,168 - INFO - Skipping layer model.layers.13.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:16:44,168 - INFO - Skipping layer model.layers.13.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:16:44,168 - INFO - Layer: model.layers.13.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:16:44,170 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_gate_proj.safetensors2025-04-25 10:16:44,170 - INFO - exists: True2025-04-25 10:16:44,185 - INFO - factorize_layer_kron_svd2025-04-25 10:16:46,604 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:16:47,830 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:16:49,119 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:16:50,776 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:16:54,452 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_gate_proj.safetensors TrueLayer: model.layers.13.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [6.0720551e-03 4.1635503e-05 2.5478646e-05 2.1152418e-05 1.8824872e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:17:53,430 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:17:53,430 - INFO - Replacing 'model.layers.13.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  43%|██████████████▉                    | 96/225 [27:49<34:45, 16.17s/it]2025-04-25 10:17:53,431 - INFO - Layer: model.layers.13.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:17:53,433 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_up_proj.safetensors2025-04-25 10:17:53,433 - INFO - exists: True2025-04-25 10:17:53,457 - INFO - factorize_layer_kron_svd2025-04-25 10:17:57,845 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:17:58,996 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:18:00,243 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:18:01,851 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:18:04,890 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:18:08,539 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_up_proj.safetensors TrueLayer: model.layers.13.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [6.4682798e-03 6.1749437e-05 2.4349400e-05 2.1919277e-05 2.0116417e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:19:08,873 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:19:08,874 - INFO - Replacing 'model.layers.13.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  43%|███████████████                    | 97/225 [29:05<44:45, 20.98s/it]2025-04-25 10:19:08,874 - INFO - Layer: model.layers.13.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:19:08,877 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_down_proj.safetensors2025-04-25 10:19:08,877 - INFO - exists: False2025-04-25 10:19:08,877 - WARNING - Skipping layer model.layers.13.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_down_proj.safetensors2025-04-25 10:19:08,877 - INFO - Skipping layer model.layers.14.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:19:08,877 - INFO - Skipping layer model.layers.14.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:19:08,877 - INFO - Skipping layer model.layers.14.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:19:08,877 - INFO - Skipping layer model.layers.14.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:19:08,877 - INFO - Layer: model.layers.14.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:19:08,877 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_gate_proj.safetensors2025-04-25 10:19:08,877 - INFO - exists: False2025-04-25 10:19:08,877 - WARNING - Skipping layer model.layers.14.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_gate_proj.safetensors2025-04-25 10:19:08,877 - INFO - Layer: model.layers.14.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:19:08,878 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_up_proj.safetensors2025-04-25 10:19:08,878 - INFO - exists: True2025-04-25 10:19:08,892 - INFO - factorize_layer_kron_svd2025-04-25 10:19:12,850 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:19:14,048 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:19:15,302 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:19:16,974 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:19:20,053 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:19:23,522 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_13_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_up_proj.safetensors TrueLayer: model.layers.14.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [9.7202640e-03 2.5967920e-05 2.1275189e-05 1.6423986e-05 1.5875536e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:20:26,326 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:20:26,326 - INFO - Replacing 'model.layers.14.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  46%|███████████████▋                  | 104/225 [30:22<33:20, 16.54s/it]2025-04-25 10:20:26,326 - INFO - Layer: model.layers.14.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:20:26,329 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_down_proj.safetensors2025-04-25 10:20:26,329 - INFO - exists: False2025-04-25 10:20:26,330 - WARNING - Skipping layer model.layers.14.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_down_proj.safetensors2025-04-25 10:20:26,330 - INFO - Skipping layer model.layers.15.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:20:26,330 - INFO - Skipping layer model.layers.15.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:20:26,330 - INFO - Skipping layer model.layers.15.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:20:26,330 - INFO - Skipping layer model.layers.15.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:20:26,330 - INFO - Layer: model.layers.15.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:20:26,330 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_gate_proj.safetensors2025-04-25 10:20:26,330 - INFO - exists: False2025-04-25 10:20:26,330 - WARNING - Skipping layer model.layers.15.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_gate_proj.safetensors2025-04-25 10:20:26,330 - INFO - Layer: model.layers.15.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:20:26,331 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_up_proj.safetensors2025-04-25 10:20:26,331 - INFO - exists: False2025-04-25 10:20:26,331 - WARNING - Skipping layer model.layers.15.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_up_proj.safetensors2025-04-25 10:20:26,331 - INFO - Layer: model.layers.15.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:20:26,331 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_down_proj.safetensors2025-04-25 10:20:26,331 - INFO - exists: True2025-04-25 10:20:26,346 - INFO - factorize_layer_kron_svd2025-04-25 10:20:31,066 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:20:32,921 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:20:34,711 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:20:36,478 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:20:38,253 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:20:41,821 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:20:42,860 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:20:43,924 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:20:44,965 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:20:46,000 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:20:47,030 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:20:48,234 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_14_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_15_mlp_down_proj.safetensors TrueLayer: model.layers.15.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [5.7206826e-06 5.4490124e-06 5.3648482e-06 5.2898772e-06 5.0597928e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:21:55,839 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:21:55,839 - INFO - Replacing 'model.layers.15.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  50%|████████████████▉                 | 112/225 [31:52<26:53, 14.28s/it]2025-04-25 10:21:55,840 - INFO - Skipping layer model.layers.16.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:21:55,840 - INFO - Skipping layer model.layers.16.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:21:55,840 - INFO - Skipping layer model.layers.16.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:21:55,840 - INFO - Skipping layer model.layers.16.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:21:55,840 - INFO - Layer: model.layers.16.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:21:55,842 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_gate_proj.safetensors2025-04-25 10:21:55,842 - INFO - exists: True2025-04-25 10:21:55,856 - INFO - factorize_layer_kron_svd2025-04-25 10:21:57,601 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:21:58,804 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:22:00,073 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:22:01,713 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:22:05,344 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_gate_proj.safetensors TrueLayer: model.layers.16.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [3.0645484e-03 2.1843742e-05 8.2429324e-06 3.9983265e-06 3.0144206e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:23:10,796 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:23:10,796 - INFO - Replacing 'model.layers.16.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  52%|█████████████████▋                | 117/225 [33:07<26:03, 14.47s/it]2025-04-25 10:23:10,797 - INFO - Layer: model.layers.16.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:23:10,799 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_up_proj.safetensors2025-04-25 10:23:10,799 - INFO - exists: False2025-04-25 10:23:10,799 - WARNING - Skipping layer model.layers.16.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_up_proj.safetensors2025-04-25 10:23:10,799 - INFO - Layer: model.layers.16.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:23:10,800 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_down_proj.safetensors2025-04-25 10:23:10,800 - INFO - exists: True2025-04-25 10:23:10,815 - INFO - factorize_layer_kron_svd2025-04-25 10:23:14,907 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:23:18,013 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:23:21,652 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:23:22,706 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:23:23,899 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:23:25,163 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_16_mlp_down_proj.safetensors TrueLayer: model.layers.16.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [5.7327412e-02 1.1083911e-04 5.4754466e-05 5.0081719e-05 4.2930162e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:24:36,258 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:24:36,258 - INFO - Replacing 'model.layers.16.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  53%|█████████████████▉                | 119/225 [34:32<32:19, 18.30s/it]2025-04-25 10:24:36,258 - INFO - Skipping layer model.layers.17.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:24:36,258 - INFO - Skipping layer model.layers.17.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:24:36,258 - INFO - Skipping layer model.layers.17.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:24:36,258 - INFO - Skipping layer model.layers.17.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:24:36,258 - INFO - Layer: model.layers.17.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:24:36,261 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_gate_proj.safetensors2025-04-25 10:24:36,261 - INFO - exists: True2025-04-25 10:24:36,277 - INFO - factorize_layer_kron_svd2025-04-25 10:24:38,108 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:24:39,325 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:24:40,571 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:24:42,414 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:24:45,970 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_gate_proj.safetensors TrueLayer: model.layers.17.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.2734500e-02 1.9533880e-05 1.8360362e-05 1.5285072e-05 1.4013754e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:25:50,580 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:25:50,581 - INFO - Replacing 'model.layers.17.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  55%|██████████████████▋               | 124/225 [35:47<28:55, 17.18s/it]2025-04-25 10:25:50,581 - INFO - Layer: model.layers.17.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:25:50,588 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_up_proj.safetensors2025-04-25 10:25:50,588 - INFO - exists: True2025-04-25 10:25:50,604 - INFO - factorize_layer_kron_svd2025-04-25 10:25:52,396 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:25:53,564 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:25:54,826 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:25:56,555 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:26:00,136 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_up_proj.safetensors TrueLayer: model.layers.17.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.35030011e-03 2.14593056e-05 1.69268369e-05 1.56144724e-05 1.40765405e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:27:04,233 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:27:04,234 - INFO - Replacing 'model.layers.17.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  56%|██████████████████▉               | 125/225 [37:00<36:38, 21.99s/it]2025-04-25 10:27:04,234 - INFO - Layer: model.layers.17.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:27:04,237 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_down_proj.safetensors2025-04-25 10:27:04,237 - INFO - exists: False2025-04-25 10:27:04,237 - WARNING - Skipping layer model.layers.17.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_down_proj.safetensors2025-04-25 10:27:04,237 - INFO - Skipping layer model.layers.18.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:27:04,237 - INFO - Skipping layer model.layers.18.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:27:04,237 - INFO - Skipping layer model.layers.18.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:27:04,237 - INFO - Skipping layer model.layers.18.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:27:04,237 - INFO - Layer: model.layers.18.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:27:04,237 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_gate_proj.safetensors2025-04-25 10:27:04,237 - INFO - exists: False2025-04-25 10:27:04,238 - WARNING - Skipping layer model.layers.18.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_gate_proj.safetensors2025-04-25 10:27:04,238 - INFO - Layer: model.layers.18.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:27:04,238 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_up_proj.safetensors2025-04-25 10:27:04,238 - INFO - exists: True2025-04-25 10:27:04,254 - INFO - factorize_layer_kron_svd2025-04-25 10:27:06,261 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:27:07,434 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:27:08,723 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:27:10,454 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:27:14,184 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_17_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_up_proj.safetensors TrueLayer: model.layers.18.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.7937209e-03 2.0253658e-05 1.6411330e-05 1.4584949e-05 1.2499403e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:28:19,745 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:28:19,746 - INFO - Replacing 'model.layers.18.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  59%|███████████████████▉              | 132/225 [38:16<26:05, 16.84s/it]2025-04-25 10:28:19,746 - INFO - Layer: model.layers.18.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:28:19,749 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_down_proj.safetensors2025-04-25 10:28:19,749 - INFO - exists: False2025-04-25 10:28:19,749 - WARNING - Skipping layer model.layers.18.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_down_proj.safetensors2025-04-25 10:28:19,749 - INFO - Skipping layer model.layers.19.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:28:19,749 - INFO - Skipping layer model.layers.19.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:28:19,749 - INFO - Skipping layer model.layers.19.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:28:19,749 - INFO - Skipping layer model.layers.19.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:28:19,749 - INFO - Layer: model.layers.19.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:28:19,750 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_gate_proj.safetensors2025-04-25 10:28:19,750 - INFO - exists: False2025-04-25 10:28:19,750 - WARNING - Skipping layer model.layers.19.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_gate_proj.safetensors2025-04-25 10:28:19,750 - INFO - Layer: model.layers.19.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:28:19,750 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_up_proj.safetensors2025-04-25 10:28:19,750 - INFO - exists: False2025-04-25 10:28:19,750 - WARNING - Skipping layer model.layers.19.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_up_proj.safetensors2025-04-25 10:28:19,750 - INFO - Layer: model.layers.19.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:28:19,751 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_down_proj.safetensors2025-04-25 10:28:19,751 - INFO - exists: True2025-04-25 10:28:19,767 - INFO - factorize_layer_kron_svd2025-04-25 10:28:22,153 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:28:25,082 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:28:28,612 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:28:29,626 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:28:30,750 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:28:31,981 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_18_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_19_mlp_down_proj.safetensors TrueLayer: model.layers.19.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [3.5986744e-02 9.2276161e-05 4.2714488e-05 3.8102378e-05 3.5181394e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:29:44,770 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:29:44,770 - INFO - Replacing 'model.layers.19.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  62%|█████████████████████▏            | 140/225 [39:41<20:04, 14.17s/it]2025-04-25 10:29:44,770 - INFO - Skipping layer model.layers.20.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:29:44,770 - INFO - Skipping layer model.layers.20.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:29:44,770 - INFO - Skipping layer model.layers.20.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:29:44,771 - INFO - Skipping layer model.layers.20.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:29:44,771 - INFO - Layer: model.layers.20.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:29:44,773 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_gate_proj.safetensors2025-04-25 10:29:44,773 - INFO - exists: True2025-04-25 10:29:44,792 - INFO - factorize_layer_kron_svd2025-04-25 10:29:47,830 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:29:49,039 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:29:50,303 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:29:52,128 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:29:55,828 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_gate_proj.safetensors TrueLayer: model.layers.20.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.6294589e-03 2.1218650e-05 1.5237835e-05 1.4524096e-05 1.3646030e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:30:55,137 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:30:55,137 - INFO - Replacing 'model.layers.20.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  64%|█████████████████████▉            | 145/225 [40:51<18:51, 14.15s/it]2025-04-25 10:30:55,138 - INFO - Layer: model.layers.20.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:30:55,141 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_up_proj.safetensors2025-04-25 10:30:55,141 - INFO - exists: True2025-04-25 10:30:55,157 - INFO - factorize_layer_kron_svd2025-04-25 10:30:56,941 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:30:57,974 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:30:59,009 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:31:00,051 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:31:01,087 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:31:02,293 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:31:03,894 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:31:05,692 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:31:07,444 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:31:09,190 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:31:10,929 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:31:14,418 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_up_proj.safetensors TrueLayer: model.layers.20.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [6.0963253e-06 5.4725215e-06 4.6369269e-06 4.5791958e-06 4.4192011e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:32:15,840 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:32:15,840 - INFO - Replacing 'model.layers.20.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  65%|██████████████████████            | 146/225 [42:12<25:03, 19.03s/it]2025-04-25 10:32:15,841 - INFO - Layer: model.layers.20.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:32:15,843 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_down_proj.safetensors2025-04-25 10:32:15,843 - INFO - exists: False2025-04-25 10:32:15,843 - WARNING - Skipping layer model.layers.20.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_down_proj.safetensors2025-04-25 10:32:15,843 - INFO - Skipping layer model.layers.21.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:32:15,843 - INFO - Skipping layer model.layers.21.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:32:15,843 - INFO - Skipping layer model.layers.21.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:32:15,843 - INFO - Skipping layer model.layers.21.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:32:15,843 - INFO - Layer: model.layers.21.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:32:15,844 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_gate_proj.safetensors2025-04-25 10:32:15,844 - INFO - exists: False2025-04-25 10:32:15,844 - WARNING - Skipping layer model.layers.21.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_gate_proj.safetensors2025-04-25 10:32:15,844 - INFO - Layer: model.layers.21.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:32:15,844 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_up_proj.safetensors2025-04-25 10:32:15,844 - INFO - exists: True2025-04-25 10:32:15,861 - INFO - factorize_layer_kron_svd2025-04-25 10:32:18,946 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:32:20,218 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:32:21,445 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:32:23,222 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:32:26,394 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_20_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_up_proj.safetensors TrueLayer: model.layers.21.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.8695735e-03 5.5963137e-05 1.4356574e-05 1.3274203e-05 1.2030486e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:33:31,640 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:33:31,641 - INFO - Replacing 'model.layers.21.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  68%|███████████████████████           | 153/225 [43:28<18:40, 15.56s/it]2025-04-25 10:33:31,641 - INFO - Layer: model.layers.21.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:33:31,645 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_down_proj.safetensors2025-04-25 10:33:31,645 - INFO - exists: False2025-04-25 10:33:31,645 - WARNING - Skipping layer model.layers.21.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_down_proj.safetensors2025-04-25 10:33:31,645 - INFO - Skipping layer model.layers.22.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:33:31,646 - INFO - Skipping layer model.layers.22.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:33:31,646 - INFO - Skipping layer model.layers.22.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:33:31,646 - INFO - Skipping layer model.layers.22.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:33:31,646 - INFO - Layer: model.layers.22.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:33:31,646 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_gate_proj.safetensors2025-04-25 10:33:31,646 - INFO - exists: False2025-04-25 10:33:31,646 - WARNING - Skipping layer model.layers.22.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_gate_proj.safetensors2025-04-25 10:33:31,646 - INFO - Layer: model.layers.22.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:33:31,646 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_up_proj.safetensors2025-04-25 10:33:31,646 - INFO - exists: False2025-04-25 10:33:31,647 - WARNING - Skipping layer model.layers.22.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_up_proj.safetensors2025-04-25 10:33:31,647 - INFO - Layer: model.layers.22.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:33:31,647 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_down_proj.safetensors2025-04-25 10:33:31,647 - INFO - exists: True2025-04-25 10:33:31,664 - INFO - factorize_layer_kron_svd2025-04-25 10:33:34,127 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:33:36,269 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:33:39,233 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:33:40,254 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:33:41,370 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:33:42,600 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_21_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_22_mlp_down_proj.safetensors TrueLayer: model.layers.22.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [2.3855805e-02 8.0862206e-05 5.0205126e-05 4.2752916e-05 3.9248724e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:34:32,703 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:34:32,703 - INFO - Replacing 'model.layers.22.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  72%|████████████████████████▎         | 161/225 [44:29<13:08, 12.32s/it]2025-04-25 10:34:32,703 - INFO - Skipping layer model.layers.23.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:34:32,703 - INFO - Skipping layer model.layers.23.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:34:32,703 - INFO - Skipping layer model.layers.23.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:34:32,703 - INFO - Skipping layer model.layers.23.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:34:32,703 - INFO - Layer: model.layers.23.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:34:32,706 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_gate_proj.safetensors2025-04-25 10:34:32,706 - INFO - exists: True2025-04-25 10:34:32,722 - INFO - factorize_layer_kron_svd2025-04-25 10:34:34,625 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:34:35,786 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:34:37,026 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:34:38,791 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:34:41,939 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_gate_proj.safetensors TrueLayer: model.layers.23.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.6312244e-03 1.5538668e-05 4.1256385e-06 2.1622898e-06 2.0991954e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:35:25,330 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:35:25,331 - INFO - Replacing 'model.layers.23.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  74%|█████████████████████████         | 166/225 [45:21<11:38, 11.84s/it]2025-04-25 10:35:25,331 - INFO - Layer: model.layers.23.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:35:25,332 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_up_proj.safetensors2025-04-25 10:35:25,332 - INFO - exists: False2025-04-25 10:35:25,332 - WARNING - Skipping layer model.layers.23.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_up_proj.safetensors2025-04-25 10:35:25,332 - INFO - Layer: model.layers.23.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:35:25,333 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_down_proj.safetensors2025-04-25 10:35:25,333 - INFO - exists: True2025-04-25 10:35:25,350 - INFO - factorize_layer_kron_svd2025-04-25 10:35:27,942 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:35:30,251 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:35:33,353 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:35:34,410 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:35:35,548 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:35:36,766 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_23_mlp_down_proj.safetensors TrueLayer: model.layers.23.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [6.6739982e-03 2.3223182e-04 4.9300255e-05 3.7862912e-05 3.5104458e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:36:31,767 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:36:31,767 - INFO - Replacing 'model.layers.23.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  75%|█████████████████████████▍        | 168/225 [46:28<13:56, 14.67s/it]2025-04-25 10:36:31,768 - INFO - Skipping layer model.layers.24.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:36:31,768 - INFO - Skipping layer model.layers.24.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:36:31,768 - INFO - Skipping layer model.layers.24.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:36:31,768 - INFO - Skipping layer model.layers.24.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:36:31,768 - INFO - Layer: model.layers.24.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:36:31,772 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_gate_proj.safetensors2025-04-25 10:36:31,773 - INFO - exists: True2025-04-25 10:36:31,792 - INFO - factorize_layer_kron_svd2025-04-25 10:36:33,674 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:36:34,737 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:36:35,812 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:36:36,855 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:36:37,885 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:36:39,108 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:36:40,672 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:36:42,468 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:36:44,261 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:36:46,091 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:36:47,854 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:36:50,854 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_gate_proj.safetensors TrueLayer: model.layers.24.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.0848038e-05 5.9405497e-06 5.6468962e-06 5.4398588e-06 5.3999447e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:37:38,284 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:37:38,285 - INFO - Replacing 'model.layers.24.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  77%|██████████████████████████▏       | 173/225 [47:34<12:20, 14.23s/it]2025-04-25 10:37:38,285 - INFO - Layer: model.layers.24.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:37:38,288 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_up_proj.safetensors2025-04-25 10:37:38,288 - INFO - exists: True2025-04-25 10:37:38,305 - INFO - factorize_layer_kron_svd2025-04-25 10:37:40,122 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:37:41,171 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:37:42,212 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:37:43,265 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:37:44,317 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:37:45,512 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:37:47,104 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:37:48,907 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:37:50,685 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:37:52,446 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:37:54,242 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:37:57,314 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_up_proj.safetensors TrueLayer: model.layers.24.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [4.6520490e-06 4.4155945e-06 4.3086152e-06 4.1636677e-06 4.0883192e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:38:45,625 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:38:45,625 - INFO - Replacing 'model.layers.24.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  77%|██████████████████████████▎       | 174/225 [48:42<15:53, 18.70s/it]2025-04-25 10:38:45,626 - INFO - Layer: model.layers.24.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:38:45,628 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_down_proj.safetensors2025-04-25 10:38:45,628 - INFO - exists: False2025-04-25 10:38:45,629 - WARNING - Skipping layer model.layers.24.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_down_proj.safetensors2025-04-25 10:38:45,629 - INFO - Skipping layer model.layers.25.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:38:45,629 - INFO - Skipping layer model.layers.25.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:38:45,629 - INFO - Skipping layer model.layers.25.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:38:45,629 - INFO - Skipping layer model.layers.25.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:38:45,629 - INFO - Layer: model.layers.25.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:38:45,629 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_gate_proj.safetensors2025-04-25 10:38:45,629 - INFO - exists: False2025-04-25 10:38:45,629 - WARNING - Skipping layer model.layers.25.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_gate_proj.safetensors2025-04-25 10:38:45,629 - INFO - Layer: model.layers.25.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:38:45,630 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_up_proj.safetensors2025-04-25 10:38:45,630 - INFO - exists: True2025-04-25 10:38:45,647 - INFO - factorize_layer_kron_svd2025-04-25 10:38:47,394 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:38:48,580 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:38:49,812 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:38:51,579 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:38:54,739 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_24_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_up_proj.safetensors TrueLayer: model.layers.25.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.2369884e-03 1.2808485e-05 1.0910483e-05 1.0035876e-05 9.8339870e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:39:41,573 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:39:41,573 - INFO - Replacing 'model.layers.25.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  80%|███████████████████████████▎      | 181/225 [49:38<10:07, 13.81s/it]2025-04-25 10:39:41,573 - INFO - Layer: model.layers.25.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:39:41,574 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_down_proj.safetensors2025-04-25 10:39:41,574 - INFO - exists: False2025-04-25 10:39:41,574 - WARNING - Skipping layer model.layers.25.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_down_proj.safetensors2025-04-25 10:39:41,574 - INFO - Skipping layer model.layers.26.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:39:41,574 - INFO - Skipping layer model.layers.26.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:39:41,574 - INFO - Skipping layer model.layers.26.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:39:41,574 - INFO - Skipping layer model.layers.26.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:39:41,575 - INFO - Layer: model.layers.26.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:39:41,575 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_gate_proj.safetensors2025-04-25 10:39:41,575 - INFO - exists: False2025-04-25 10:39:41,575 - WARNING - Skipping layer model.layers.26.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_gate_proj.safetensors2025-04-25 10:39:41,575 - INFO - Layer: model.layers.26.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:39:41,576 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_up_proj.safetensors2025-04-25 10:39:41,576 - INFO - exists: False2025-04-25 10:39:41,576 - WARNING - Skipping layer model.layers.26.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_up_proj.safetensors2025-04-25 10:39:41,576 - INFO - Layer: model.layers.26.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:39:41,576 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_down_proj.safetensors2025-04-25 10:39:41,576 - INFO - exists: True2025-04-25 10:39:41,593 - INFO - factorize_layer_kron_svd2025-04-25 10:39:44,012 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:39:46,192 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:39:49,373 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:39:50,428 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:39:51,590 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:39:52,833 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_25_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_26_mlp_down_proj.safetensors TrueLayer: model.layers.26.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [4.1444181e-03 7.6422427e-04 4.0036848e-05 3.7765723e-05 3.1555592e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:40:45,997 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:40:45,997 - INFO - Replacing 'model.layers.26.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  84%|████████████████████████████▌     | 189/225 [50:42<06:48, 11.35s/it]2025-04-25 10:40:45,998 - INFO - Skipping layer model.layers.27.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:40:45,998 - INFO - Skipping layer model.layers.27.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:40:45,998 - INFO - Skipping layer model.layers.27.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:40:45,998 - INFO - Skipping layer model.layers.27.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:40:45,998 - INFO - Layer: model.layers.27.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:40:46,000 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_gate_proj.safetensors2025-04-25 10:40:46,000 - INFO - exists: True2025-04-25 10:40:46,017 - INFO - factorize_layer_kron_svd2025-04-25 10:40:48,108 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:40:49,310 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:40:50,567 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:40:52,351 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:40:55,514 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_gate_proj.safetensors TrueLayer: model.layers.27.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [8.5178309e-04 1.7080700e-04 1.5016245e-05 1.2949634e-05 1.1322722e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:41:42,370 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:41:42,370 - INFO - Replacing 'model.layers.27.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  86%|█████████████████████████████▎    | 194/225 [51:38<05:51, 11.33s/it]2025-04-25 10:41:42,371 - INFO - Layer: model.layers.27.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:41:42,371 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_up_proj.safetensors2025-04-25 10:41:42,372 - INFO - exists: False2025-04-25 10:41:42,372 - WARNING - Skipping layer model.layers.27.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_up_proj.safetensors2025-04-25 10:41:42,372 - INFO - Layer: model.layers.27.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:41:42,372 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_down_proj.safetensors2025-04-25 10:41:42,372 - INFO - exists: True2025-04-25 10:41:42,389 - INFO - factorize_layer_kron_svd2025-04-25 10:41:44,798 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:41:46,913 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:41:50,055 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:41:51,108 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:41:52,264 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:41:53,530 - INFO -   Factor is positive definite (alpha=1.00e-03)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_27_mlp_down_proj.safetensors TrueLayer: model.layers.27.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [4.3249605e-03 9.9447533e-04 4.9234852e-05 3.5841313e-05 3.4881272e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:42:58,830 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:42:58,831 - INFO - Replacing 'model.layers.27.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  87%|█████████████████████████████▌    | 196/225 [52:55<07:14, 14.99s/it]2025-04-25 10:42:58,831 - INFO - Skipping layer model.layers.28.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:42:58,831 - INFO - Skipping layer model.layers.28.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:42:58,831 - INFO - Skipping layer model.layers.28.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:42:58,831 - INFO - Skipping layer model.layers.28.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:42:58,831 - INFO - Layer: model.layers.28.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:42:58,834 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_gate_proj.safetensors2025-04-25 10:42:58,834 - INFO - exists: True2025-04-25 10:42:58,853 - INFO - factorize_layer_kron_svd2025-04-25 10:43:00,647 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:43:01,894 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:43:03,199 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:43:05,091 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:43:08,697 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_gate_proj.safetensors TrueLayer: model.layers.28.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [2.48785485e-02 2.44410057e-05 1.47788587e-05 1.22457295e-05 1.07915093e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:44:02,773 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:44:02,774 - INFO - Replacing 'model.layers.28.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  89%|██████████████████████████████▎   | 201/225 [53:59<05:42, 14.27s/it]2025-04-25 10:44:02,774 - INFO - Layer: model.layers.28.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:44:02,776 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_up_proj.safetensors2025-04-25 10:44:02,776 - INFO - exists: True2025-04-25 10:44:02,805 - INFO - factorize_layer_kron_svd2025-04-25 10:44:04,730 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:44:05,782 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:44:06,824 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:44:07,867 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:44:08,906 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:44:10,116 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:44:11,707 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:44:13,557 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:44:15,346 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:44:17,113 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:44:18,884 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:44:22,434 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_up_proj.safetensors TrueLayer: model.layers.28.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [8.9290443e-06 4.8989136e-06 4.5310157e-06 4.3148771e-06 4.1740809e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:45:22,686 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:45:22,686 - INFO - Replacing 'model.layers.28.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  90%|██████████████████████████████▌   | 202/225 [55:19<07:37, 19.89s/it]2025-04-25 10:45:22,687 - INFO - Layer: model.layers.28.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:45:22,714 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_down_proj.safetensors2025-04-25 10:45:22,714 - INFO - exists: False2025-04-25 10:45:22,714 - WARNING - Skipping layer model.layers.28.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_down_proj.safetensors2025-04-25 10:45:22,714 - INFO - Skipping layer model.layers.29.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:45:22,714 - INFO - Skipping layer model.layers.29.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:45:22,714 - INFO - Skipping layer model.layers.29.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:45:22,714 - INFO - Skipping layer model.layers.29.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:45:22,714 - INFO - Layer: model.layers.29.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:45:22,714 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_gate_proj.safetensors2025-04-25 10:45:22,715 - INFO - exists: False2025-04-25 10:45:22,715 - WARNING - Skipping layer model.layers.29.mlp.gate_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_gate_proj.safetensors2025-04-25 10:45:22,715 - INFO - Layer: model.layers.29.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:45:22,715 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_up_proj.safetensors2025-04-25 10:45:22,715 - INFO - exists: True2025-04-25 10:45:22,731 - INFO - factorize_layer_kron_svd2025-04-25 10:45:24,519 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:45:25,684 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:45:26,947 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:45:28,681 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:45:32,293 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_28_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_gate_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_up_proj.safetensors TrueLayer: model.layers.29.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [2.5008040e-02 2.4909425e-05 1.7541013e-05 1.1958569e-05 1.1578863e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:46:35,604 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:46:35,604 - INFO - Replacing 'model.layers.29.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  93%|███████████████████████████████▌  | 209/225 [56:32<04:08, 15.52s/it]2025-04-25 10:46:35,605 - INFO - Layer: model.layers.29.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:46:35,607 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_down_proj.safetensors2025-04-25 10:46:35,607 - INFO - exists: False2025-04-25 10:46:35,607 - WARNING - Skipping layer model.layers.29.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_down_proj.safetensors2025-04-25 10:46:35,607 - INFO - Skipping layer model.layers.30.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:46:35,607 - INFO - Skipping layer model.layers.30.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:46:35,607 - INFO - Skipping layer model.layers.30.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:46:35,607 - INFO - Skipping layer model.layers.30.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:46:35,607 - INFO - Layer: model.layers.30.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:46:35,608 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_gate_proj.safetensors2025-04-25 10:46:35,608 - INFO - exists: True2025-04-25 10:46:35,623 - INFO - factorize_layer_kron_svd2025-04-25 10:46:37,442 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:46:38,544 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:46:39,646 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:46:40,746 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:46:41,832 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:46:43,092 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:46:44,733 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:46:46,595 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:46:48,368 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:46:50,198 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:46:51,947 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:46:55,445 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_29_mlp_down_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_gate_proj.safetensors TrueLayer: model.layers.30.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.9579800e-05 1.1570799e-05 1.0300217e-05 7.9101983e-06 6.5702579e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:48:01,147 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:48:01,147 - INFO - Replacing 'model.layers.30.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  96%|████████████████████████████████▍ | 215/225 [57:57<02:30, 15.07s/it]2025-04-25 10:48:01,147 - INFO - Layer: model.layers.30.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:48:01,150 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_up_proj.safetensors2025-04-25 10:48:01,150 - INFO - exists: False2025-04-25 10:48:01,150 - WARNING - Skipping layer model.layers.30.mlp.up_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_up_proj.safetensors2025-04-25 10:48:01,150 - INFO - Layer: model.layers.30.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:48:01,150 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_down_proj.safetensors2025-04-25 10:48:01,150 - INFO - exists: True2025-04-25 10:48:01,169 - INFO - factorize_layer_kron_svd2025-04-25 10:48:03,639 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:48:06,863 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:48:10,143 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:48:13,851 - INFO -   Factor is positive definite (alpha=1.00e-02)2025-04-25 10:48:14,897 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:48:15,956 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:48:17,108 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:48:18,351 - INFO -   Factor is positive definite (alpha=1.00e-02)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_up_proj.safetensors Falsefactor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_30_mlp_down_proj.safetensors TrueLayer: model.layers.30.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Factor is positive definite (alpha=1.00e-02)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Factor is positive definite (alpha=1.00e-02)  Cholesky decomposition successful.  Performing SVD on transformed matrix (4096x11008)...  SVD complete. Singular values (top 5): [0.01037151 0.00216841 0.00034812 0.00017528 0.00016458]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,11008), (4096,2096)factorized_sequential Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))2025-04-25 10:49:26,082 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=11008, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=4096, bias=False))')2025-04-25 10:49:26,082 - INFO - Replacing 'model.layers.30.mlp.down_proj' (attribute 'down_proj' within parent LlamaMLP)Compressing Layers:  96%|████████████████████████████████▊ | 217/225 [59:22<02:32, 19.08s/it]2025-04-25 10:49:26,082 - INFO - Skipping layer model.layers.31.self_attn.q_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:49:26,082 - INFO - Skipping layer model.layers.31.self_attn.k_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:49:26,082 - INFO - Skipping layer model.layers.31.self_attn.v_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:49:26,082 - INFO - Skipping layer model.layers.31.self_attn.o_proj: Sensitivity ratio >= 1.0 (1.00). No compression.2025-04-25 10:49:26,082 - INFO - Layer: model.layers.31.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:49:26,087 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_gate_proj.safetensors2025-04-25 10:49:26,087 - INFO - exists: True2025-04-25 10:49:26,104 - INFO - factorize_layer_kron_svd2025-04-25 10:49:29,783 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:49:30,922 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:49:32,178 - INFO -   Factor is positive definite (alpha=1.00e-03)2025-04-25 10:49:33,863 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:49:37,537 - INFO -   Factor is positive definite (alpha=1.00e-04)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_gate_proj.safetensors TrueLayer: model.layers.31.mlp.gate_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Factor is positive definite (alpha=1.00e-03)  Regularizing factor (try 1, alpha=1.00e-05)  Factor is positive definite (alpha=1.00e-04)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [5.3034523e-03 6.2283059e-04 3.3307722e-05 2.5902780e-05 2.1905900e-05]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:50:41,840 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:50:41,841 - INFO - Replacing 'model.layers.31.mlp.gate_proj' (attribute 'gate_proj' within parent LlamaMLP)Compressing Layers:  99%|███████████████████████████████▌| 222/225 [1:00:38<00:53, 17.73s/it]2025-04-25 10:50:41,841 - INFO - Layer: model.layers.31.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:50:41,843 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_up_proj.safetensors2025-04-25 10:50:41,843 - INFO - exists: True2025-04-25 10:50:41,858 - INFO - factorize_layer_kron_svd2025-04-25 10:50:45,143 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:50:46,166 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:50:47,180 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:50:48,196 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:50:49,214 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:50:50,408 - INFO -   Factor is positive definite (alpha=1.00e+00)2025-04-25 10:50:51,993 - INFO -   Regularizing factor (try 1, alpha=1.00e-05)2025-04-25 10:50:53,797 - INFO -   Regularizing factor (try 2, alpha=1.00e-04)2025-04-25 10:50:55,559 - INFO -   Regularizing factor (try 3, alpha=1.00e-03)2025-04-25 10:50:57,301 - INFO -   Regularizing factor (try 4, alpha=1.00e-02)2025-04-25 10:50:59,046 - INFO -   Regularizing factor (try 5, alpha=1.00e-01)2025-04-25 10:51:02,559 - INFO -   Factor is positive definite (alpha=1.00e+00)factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_up_proj.safetensors TrueLayer: model.layers.31.mlp.up_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)factorize_layer_kron_svdRegularizing factors for layer (initial alpha=1.00e-05)...  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Regularizing factor (try 1, alpha=1.00e-05)  Regularizing factor (try 2, alpha=1.00e-04)  Regularizing factor (try 3, alpha=1.00e-03)  Regularizing factor (try 4, alpha=1.00e-02)  Regularizing factor (try 5, alpha=1.00e-01)  Factor is positive definite (alpha=1.00e+00)  Cholesky decomposition successful.  Performing SVD on transformed matrix (11008x4096)...  SVD complete. Singular values (top 5): [1.9596220e-05 1.2680045e-05 1.0252364e-05 8.5133843e-06 7.9795263e-06]  Cholesky factor inverses computed.  Factorization complete for layer. New shapes: (2096,4096), (11008,2096)factorized_sequential Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))2025-04-25 10:52:02,844 - INFO - factorized_sequential 'Sequential(  (0): Linear(in_features=4096, out_features=2096, bias=False)  (1): Linear(in_features=2096, out_features=11008, bias=False))')2025-04-25 10:52:02,845 - INFO - Replacing 'model.layers.31.mlp.up_proj' (attribute 'up_proj' within parent LlamaMLP)Compressing Layers:  99%|███████████████████████████████▋| 223/225 [1:01:59<00:46, 23.39s/it]2025-04-25 10:52:02,845 - INFO - Layer: model.layers.31.mlp.down_proj | Ratio: 0.800 -> Target Rank: 2096 (Align: 8)2025-04-25 10:52:02,847 - INFO - factor_filename: /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_down_proj.safetensors2025-04-25 10:52:02,847 - INFO - exists: False2025-04-25 10:52:02,847 - WARNING - Skipping layer model.layers.31.mlp.down_proj: Factor file not found at /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_down_proj.safetensors2025-04-25 10:52:02,847 - INFO - Skipping layer lm_head: Sensitivity ratio >= 1.0 (1.00). No compression.Compressing Layers: 100%|████████████████████████████████| 225/225 [1:01:59<00:00, 16.53s/it]2025-04-25 10:52:02,847 - INFO - Compression finished. Processed: 49, Skipped (Ratio>=1 or No Sensitivity/Factors): 176, Failed: 02025-04-25 10:52:02,848 - INFO - Saving compressed model to ./llama102025-04-25 10:52:31,394 - INFO - Compressed model and tokenizer saved.2025-04-25 10:52:31,409 - INFO - Evaluating on wikitext2factor_filename /home/jovyan/shares/SR004.nfs2/chekalina/FisherKronecker/grads_output/llama-2-7b-chat/fisher_factors_output_1404/model_layers_31_mlp_down_proj.safetensors FalseEvaluating:   0%|                                                     | 0/21 [00:00<?, ?it/s]Evaluating:   5%|██▏                                          | 1/21 [00:04<01:20,  4.02s/it]Evaluating:  10%|████▎                                        | 2/21 [00:05<00:44,  2.33s/it]Evaluating:  14%|██████▍                                      | 3/21 [00:06<00:32,  1.79s/it]Evaluating:  19%|████████▌                                    | 4/21 [00:07<00:26,  1.54s/it]Evaluating:  24%|██████████▋                                  | 5/21 [00:08<00:22,  1.40s/it]Evaluating:  29%|████████████▊                                | 6/21 [00:09<00:19,  1.31s/it]Evaluating:  33%|███████████████                              | 7/21 [00:10<00:17,  1.26s/it]Evaluating:  38%|█████████████████▏                           | 8/21 [00:12<00:15,  1.22s/it]Evaluating:  43%|███████████████████▎                         | 9/21 [00:13<00:14,  1.20s/it]Evaluating:  48%|████████████████████▉                       | 10/21 [00:14<00:13,  1.19s/it]Evaluating:  52%|███████████████████████                     | 11/21 [00:15<00:11,  1.17s/it]Evaluating:  57%|█████████████████████████▏                  | 12/21 [00:16<00:10,  1.17s/it]Evaluating:  62%|███████████████████████████▏                | 13/21 [00:17<00:09,  1.16s/it]Evaluating:  67%|█████████████████████████████▎              | 14/21 [00:18<00:08,  1.16s/it]Evaluating:  71%|███████████████████████████████▍            | 15/21 [00:20<00:06,  1.16s/it]Evaluating:  76%|█████████████████████████████████▌          | 16/21 [00:21<00:05,  1.15s/it]Evaluating:  81%|███████████████████████████████████▌        | 17/21 [00:22<00:04,  1.15s/it]Evaluating:  86%|█████████████████████████████████████▋      | 18/21 [00:23<00:03,  1.15s/it]Evaluating:  90%|███████████████████████████████████████▊    | 19/21 [00:24<00:02,  1.20s/it]Evaluating:  95%|█████████████████████████████████████████▉  | 20/21 [00:26<00:01,  1.19s/it]Evaluating: 100%|████████████████████████████████████████████| 21/21 [00:26<00:00,  1.09s/it]Evaluating: 100%|████████████████████████████████████████████| 21/21 [00:26<00:00,  1.28s/it]2025-04-25 10:53:05,392 - INFO - wikitext2 perplexity: 11.25002025-04-25 10:53:05,393 - INFO - Evaluating on ptbnlls.shape torch.Size([16376])Mean NLL: 2.421875Evaluating:   0%|                                                      | 0/7 [00:00<?, ?it/s]Evaluating:  14%|██████▌                                       | 1/7 [00:01<00:06,  1.15s/it]Evaluating:  29%|█████████████▏                                | 2/7 [00:02<00:05,  1.15s/it]Evaluating:  43%|███████████████████▋                          | 3/7 [00:03<00:04,  1.15s/it]Evaluating:  57%|██████████████████████████▎                   | 4/7 [00:04<00:03,  1.15s/it]Evaluating:  71%|████████████████████████████████▊             | 5/7 [00:05<00:02,  1.15s/it]Evaluating:  86%|███████████████████████████████████████▍      | 6/7 [00:06<00:01,  1.15s/it]Evaluating: 100%|██████████████████████████████████████████████| 7/7 [00:07<00:00,  1.11s/it]Evaluating: 100%|██████████████████████████████████████████████| 7/7 [00:07<00:00,  1.13s/it]2025-04-25 10:53:16,628 - INFO - ptb perplexity: 56.25002025-04-25 10:53:16,628 - INFO - Evaluation results:2025-04-25 10:53:16,628 - INFO -   wikitext2: 11.25002025-04-25 10:53:16,628 - INFO -   ptb: 56.2500nlls.shape torch.Size([16376])Mean NLL: 4.03125