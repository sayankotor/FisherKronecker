{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g5Nk-MI4-nLz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.linalg import kron\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check decomposition of torch row-wise permuted matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape_and_permute(A, m, n):\n",
    "    # Reshape to (m, n, m, n) in row-major order (default in PyTorch)\n",
    "    A_reshaped = A.reshape(m, n, m, n)\n",
    "    \n",
    "    # Permute the axes (0, 2, 1, 3) to interleave dimensions\n",
    "    A_permuted = A_reshaped.permute(0, 2, 1, 3)\n",
    "    \n",
    "    # Reshape to (m*m, n*n) in column-major order\n",
    "    RA = A_permuted.reshape(m * m, n * n)  # Transpose for column-major layout\n",
    "    \n",
    "    return RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to create operator\n",
      "operator created\n",
      "svds...\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "n = 10\n",
    "\n",
    "B = torch.rand(m, m)\n",
    "B = B + B.T\n",
    "C = torch.rand(n, n)\n",
    "C = C + C.T\n",
    "\n",
    "A = torch.kron(B, C)\n",
    "\n",
    "noise1=torch.randn(A.size())*0.01\n",
    "A1 = reshape_and_permute(A, m, n)\n",
    "\n",
    "\n",
    "def getitem_fmatrix_permuted(matrix, p, q):\n",
    "    return matrix[p][q]\n",
    "\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "\n",
    "#@jit\n",
    "def matvec_item_custom(x): #m**2\\times n**2, m**2 -> n**2 \n",
    "    #print (\"matvec_item_custom\")\n",
    "    res =np.zeros((m**2))\n",
    "    for ind in range(m**2):\n",
    "        sum_ = 0.0\n",
    "        for jnd, elem in enumerate(x):\n",
    "            sum_+= getitem_fmatrix_permuted(A1, ind, jnd)*elem\n",
    "        res[ind] = sum_\n",
    "    return res\n",
    "\n",
    "#@jit\n",
    "def rmatvec_item_custom(x): # A.T*y\n",
    "    res = np.zeros((n**2))\n",
    "    for ind in range(n**2):\n",
    "        #if (ind%10000) == 0:\n",
    "            #print (ind, \"from\", n**2)\n",
    "        sum_ = 0.0\n",
    "        for jnd, elem in enumerate(x):\n",
    "            #print (\"r\", jnd, ind)\n",
    "            sum_+= getitem_fmatrix_permuted(A1, jnd, ind)*elem\n",
    "        res[ind] = sum_\n",
    "    return res\n",
    "    \n",
    "\n",
    "print (\"start to create operator\", flush = True)\n",
    "\n",
    "\n",
    "linop_v = LinearOperator(\n",
    "                shape=(m**2,n**2),\n",
    "                matvec=matvec_item_custom,\n",
    "                rmatvec=rmatvec_item_custom\n",
    "                )\n",
    "\n",
    "\n",
    "print (\"operator created\", flush = True)\n",
    "\n",
    "print (\"svds...\", flush = True)\n",
    "\n",
    "v, s, u = svds(linop_v, k = 3, return_singular_vectors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.67000299e-07, 6.04088830e-07, 6.48285812e+01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2854315783118753e-07\n"
     ]
    }
   ],
   "source": [
    "C1 = s[-1] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "print (np.linalg.norm(A-np.kron(B1, C1))/np.linalg.norm(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check decomposition of torch column-wise permuted matrix with parrallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_permute(A, m, n):\n",
    "    # Reshape to (m, n, m, n) in row-major order (default in PyTorch)\n",
    "    A_reshaped = A.reshape(m, n, m, n)\n",
    "    \n",
    "    # Permute the axes (0, 2, 1, 3) to interleave dimensions\n",
    "    A_permuted = A_reshaped.permute(0, 2, 1, 3)\n",
    "    \n",
    "    # Reshape to (m*m, n*n) in column-major order\n",
    "    RA = A_permuted.reshape(m * m, n * n)  # Transpose for column-major layout\n",
    "    \n",
    "    return RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cupyx.scipy.sparse.linalg import svds, LinearOperator\n",
    "import numba\n",
    "from numba import jit\n",
    "from numba import cuda\n",
    "\n",
    "#@cuda.jit\n",
    "\n",
    "# Load the tensor and convert to CuPy array\n",
    "#a = cp.asarray(torch.load(\"last_one.pt\")) old\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "import torch\n",
    "\n",
    "m = 500\n",
    "n = 100\n",
    "\n",
    "B = torch.rand(m, m)\n",
    "B = B + B.T\n",
    "C = torch.rand(n, n)\n",
    "C = C + C.T\n",
    "\n",
    "A = torch.kron(B, C)\n",
    "\n",
    "noise1=torch.randn(A.size())*0.01\n",
    "A1 = reshape_and_permute(A, m, n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#import numpy as np\n",
    "d_A1 = cuda.to_device(A1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    #pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_A1[np.int32(idx)][jnd]\n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        #pd, pn = divmod(np.int32(idx), m)\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*d_A1[jnd][np.int32(idx)]\n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n",
      "Performing SVD...\n",
      "matvec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 40 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n"
     ]
    }
   ],
   "source": [
    "linop_v = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n",
    "# Compute SVD\n",
    "print(\"Performing SVD...\", flush=True)\n",
    "v, s, u = svds(linop_v, k = 10, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8762172e+04, 4.5752557e-05, 2.8291899e-05, 2.7793820e-05,\n",
       "       2.7698212e-05, 2.7515733e-05, 2.6975136e-05, 2.6144406e-05,\n",
       "       2.4383276e-05, 1.7502996e-05], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8999048e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(A-np.kron(B1, C1))/np.linalg.norm(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check the correspondance between vector and matrix A1\n",
    "\n",
    "### 3.2 Vector of ints\n",
    "\n",
    "where\n",
    "\n",
    "A = torch.outer(grad_vector, grad_vector)\n",
    "\n",
    "A = permute_and_reshape(A1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "grad_matrix = torch.tensor(np.array([[1, 2, 3, 4],[5, 6, 7, 8], [9, 10, 11, 12],[10, 20, 30, 40],[50, 60, 70, 80]]))\n",
    "grad_vector = grad_matrix.reshape(grad_matrix.shape[0]*grad_matrix.shape[1])\n",
    "#grad_vector = grad_matrix.T.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = grad_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_matrix = torch.outer(grad_vector,grad_vector)\n",
    "\n",
    "grad_vector = grad_matrix.T.reshape(-1)\n",
    "\n",
    "# Same as in\n",
    "    # def reshape_and_permute(A, m, n):\n",
    "    # Reshape to (m, n, m, n) in row-major order (default in PyTorch)\n",
    "    # A_reshaped = A.reshape(m, n, m, n)\n",
    "    \n",
    "    # Permute the axes (0, 2, 1, 3) to interleave dimensions\n",
    "    # A_permuted = A_reshaped.permute(0, 2, 1, 3)\n",
    "    \n",
    "    # Reshape to (m*m, n*n) in column-major order\n",
    "    #RA = A_permuted.reshape(m * m, n * n)  # Transpose for column-major layout\n",
    "    \n",
    "reshaped1 = fisher_matrix.reshape(m, n, m, n) # i, j -> k = j //m, l = j % m <=> j = k*n + l , i = i (i - number of row, j - number of column) \n",
    "reshaped2 = reshaped1.permute(0, 2, 1, 3) # i j k l -> i k j l\n",
    "#i, k, l => k, i, l <=> given: i, k, l,  reshaped1: k, i, l, fisher_matrix: k, i*n + l\n",
    "reshaped3 = reshaped2.reshape(m * m, n * n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in range(reshaped3.shape[0]):\n",
    "    for q in range(reshaped3.shape[1]):\n",
    "            #print (i, j, \"__\", i//n, i%n, j//n, j%n)\n",
    "            assert (reshaped3[p][q] == fisher_matrix[(p//m)*n +q//n, (p%m)*n + q%n]), print (p, q, \"__\", p//m, p%m, q//n, q%n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(reshaped3.T.shape[0]):\n",
    "    for q in range(reshaped3.T.shape[1]):\n",
    "            #print (i, j, \"__\", i//n, i%n, j//n, j%n)\n",
    "            assert reshaped3.T[p][q] == grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n], print (p, q, \"__\", q//m, q%m, p//n, p%n, reshaped3.T[p][q], grad_vector[(q // m)*n +p // n], grad_vector[(q % m)*n + p % n], \"X\", grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshaped3[p][q] == fisher_matrix[(p // m)*n +q // n, (p % m)*n + q % n] ==grad_vector[(p // m)*n +q // n] $\\times$ \n",
    "grad_vector[(p % m)*n + q % n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped3[q][p] == fisher_matrix[(q // m)*n +p // n, (q % m)*n + p % n] ==grad_vector[(q // m)*n +p // n] $\\times$ \n",
    "grad_vector[(q % m)*n + p % n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ...and random vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = (5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = (5,4)\n",
    "import numpy as np\n",
    "import torch\n",
    "grad_matrix = torch.randn(m,n)\n",
    "\n",
    "#grad_vector = grad_matrix.reshape(grad_matrix.shape[0]*grad_matrix.shape[1])\n",
    "grad_vector = grad_matrix.T.reshape(-1)\n",
    "fisher_matrix = torch.outer(grad_vector,grad_vector)\n",
    "permuted_fisher_matrix = reshape_and_permute(fisher_matrix, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(permuted_fisher_matrix.shape[0]):\n",
    "    for q in range(permuted_fisher_matrix.shape[1]):\n",
    "            assert (permuted_fisher_matrix[p][q] == fisher_matrix[(p//m)*n +q//n, (p%m)*n + q%n]), print (p, q, \"__\", p//m, p%m, q//n, q%n)\n",
    "            assert (permuted_fisher_matrix[p][q] == grad_vector[(p//m)*n +q//n]*grad_vector[(p%m)*n + q%n]), print (p, q, \"__\", p//m, p%m, q//n, q%n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(permuted_fisher_matrix.T.shape[0]):\n",
    "    for q in range(permuted_fisher_matrix.T.shape[1]):\n",
    "            assert permuted_fisher_matrix.T[p][q] == grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n], print (p, q, \"__\", q//m, q%m, p//n, p%n, permuted_fisher_matrix.T[p][q], grad_vector[(q // m)*n +p // n], grad_vector[(q % m)*n + p % n], \"X\", grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d_A1[jnd] q = [np.int32(idx)]  (ind // m)*n + idx//n  (ind%m)*n + idx%n  rmatvec\n",
    "p = d_A1[np.int32(idx)] q = [jnd]  (idx // m)*n + ind//n   (idx%m)*n + ind%n   matvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vector[(p//m)*n +q//n]*grad_vector[(p%m)*n + q%n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check the parrallel computing in case of full matrix A1 and grad_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "import numba\n",
    "from numba import jit\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_permute(A, m, n):\n",
    "    # Reshape to (m, n, m, n) in row-major order (default in PyTorch)\n",
    "    A_reshaped = A.reshape(m, n, m, n)\n",
    "    \n",
    "    # Permute the axes (0, 2, 1, 3) to interleave dimensions\n",
    "    A_permuted = A_reshaped.permute(0, 2, 1, 3)\n",
    "    \n",
    "    # Reshape to (m*m, n*n) in column-major order\n",
    "    RA = A_permuted.reshape(m * m, n * n)  # Transpose for column-major layout\n",
    "    \n",
    "    return RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "m = 50\n",
    "n = 150\n",
    "\n",
    "B = torch.rand(m, n)\n",
    "#B = B + B.T\n",
    "\n",
    "\n",
    "grad_matrix = B\n",
    "\n",
    "\n",
    "#m,n = grad_matrix.shape\n",
    "\n",
    "#grad_vector = torch.rand(m*n)#grad_matrix.reshape(grad_matrix.shape[0]*grad_matrix.shape[1])\n",
    "grad_vector = grad_matrix.T.reshape(-1)\n",
    "#grad_vector = grad_matrix.reshape(grad_matrix.shape[0]*grad_matrix.shape[1])\n",
    "fisher_matrix = torch.outer(grad_vector,grad_vector)\n",
    "permuted_fisher_matrix = reshape_and_permute(fisher_matrix, m, n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_A1 = cuda.to_device(permuted_fisher_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_grad_vector = cuda.to_device(grad_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A1 = cuda.to_device(permuted_fisher_matrix)\n",
    "@cuda.jit\n",
    "def matvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    #pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_A1[np.int32(idx)][jnd]\n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        #pd, pn = divmod(np.int32(idx), m)\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*d_A1[jnd][np.int32(idx)]\n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matvec_kernel_v(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_grad_vector[(pd)*n +qd]*d_grad_vector[(pn)*n + qn] \n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel_v(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    idx_d, idx_m = divmod(np.int32(idx), n)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            jd, jn = divmod(jnd, m)\n",
    "            sum_ += x[jnd]*d_grad_vector[jd*n +idx_d]*d_grad_vector[jn*n + idx_m]\n",
    "            #sum_ += x[jnd]*d_grad_vector[(jnd//n)*n +pd]*d_grad_vector[(jnd%n)*n + pn] \n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom_v(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel_v[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom_v(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel_v[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matvec_kernel_v1(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_grad_vector[(pd)*n +qd]*d_grad_vector[(pn)*n + qn] \n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel_v1(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        pd, pn = divmod(np.int32(idx), m)\n",
    "        for jnd in range(x.size):\n",
    "            sum_ += x[jnd]*d_grad_vector[(jnd//m)*n +pd]*d_grad_vector[(jnd%m)*n + pn] \n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom_v1(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel_v1[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom_v1(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    print (\"rmatvec\")\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 10\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel_v1[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n"
     ]
    }
   ],
   "source": [
    "linop_m = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n"
     ]
    }
   ],
   "source": [
    "linop_v = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom_v,\n",
    "    rmatvec=rmatvec_item_custom_v\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Op\n"
     ]
    }
   ],
   "source": [
    "linop_v1 = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom_v1,\n",
    "    rmatvec=rmatvec_item_custom_v1\n",
    ")\n",
    "print(\"Op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = torch.rand(n*n)\n",
    "right = torch.rand(m*m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmatvec\n"
     ]
    }
   ],
   "source": [
    "resr_1 = linop_v.rmatvec(right)\n",
    "resr_2 = linop_m.rmatvec(right)\n",
    "resr_3 = linop_v1.rmatvec(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([257.7887 , 266.3341 , 249.62654, ..., 286.33588, 342.83432,\n",
       "       351.9065 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(resr_1, resr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(resr_3, resr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "matvec\n"
     ]
    }
   ],
   "source": [
    "resl_1 = linop_v1.matvec(left)\n",
    "resl_2 = linop_m.matvec(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(resl_1, resl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing SVD on linop_v...\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "[1935.7174   245.90405  228.84325  207.0067   193.24542  186.1593\n",
      "  184.9206   176.87302  160.94855   41.30406]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6638949"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute SVD\n",
    "print(\"Performing SVD on linop_v...\", flush=True)\n",
    "v, s, u = svds(linop_v1, k = 10, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]\n",
    "print (s)\n",
    "\n",
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(fisher_matrix-np.kron(B1, C1))/np.linalg.norm(fisher_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing SVD on linop_m...\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "[1896.4788   231.66359  231.66359  227.55841  227.55836  225.07861\n",
      "  225.07849  215.91583  215.91582  207.23445]\n"
     ]
    }
   ],
   "source": [
    "# Compute SVD\n",
    "print(\"Performing SVD on linop_m...\", flush=True)\n",
    "v, s, u = svds(linop_m, k = 10, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(fisher_matrix-np.kron(B1, C1))/np.linalg.norm(fisher_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing SVD on linop_m...\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "[1896.4789   231.66362  231.6636   227.55838  227.55836  225.07848\n",
      "  225.07845  215.9159   215.91579  207.23444]\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing SVD on linop_m...\", flush=True)\n",
    "v, s, u = svds(linop_v, k = 10, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521983"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(fisher_matrix-np.kron(B1, C1))/np.linalg.norm(fisher_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decompose gradient tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "import numba\n",
    "from numba import jit\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87fb96a5f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_577923/3375906804.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  a = torch.load(\"last_one.pt\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "a = torch.load(\"last_one.pt\")\n",
    "m = a.shape[0]\n",
    "n = a.shape[1]\n",
    "\n",
    "#grad_vector = a.T.reshape(-1)\n",
    "grad_vector = a.reshape(a.shape[0]*a.shape[1])\n",
    "\n",
    "d_grad_vector = cuda.to_device(grad_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matvec_kernel(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_grad_vector[(pd)*n +qd]*d_grad_vector[(pn)*n + qn] \n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        pd, pn = divmod(np.int32(idx), n)\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*d_grad_vector[(jnd//m)*n +pd]*d_grad_vector[(jnd%m)*n + pn]  #grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n]\n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 1024\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    print (\"rmatvec\")\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 1024\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n",
      "Performing SVD...\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n"
     ]
    }
   ],
   "source": [
    "# Create the operator\n",
    "#print(\"Start to create operator\", flush=True)\n",
    "linop_v = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n",
    "#right = torch.rand(m*m)\n",
    "#resr_2 = linop_v.rmatvec(right)\n",
    "\n",
    "print(\"Performing SVD...\", flush=True)\n",
    "v, s, u = svds(linop_v, k = 3, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02324359, 0.01793001, 0.01793   ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05736788, 0.01356099, 0.01356099], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00679347, 0.00094499, 0.00055086], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00134553, 0.00083746, 0.00066922], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = (C1 + C1.T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "is_pos_def(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = (s[0] * u[-1, :]).reshape(n, n).T\n",
    "B1 = v[:, -1].reshape(m, m).T\n",
    "\n",
    "C1 = (C1 + C1.T)/2\n",
    "\n",
    "is_pos_def(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check the order of singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "import numba\n",
    "from numba import jit\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_578904/1573670655.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  a = torch.load(\"linlayer.pt\")/800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "a = torch.load(\"linlayer.pt\")/800\n",
    "m = a.shape[0]\n",
    "n = a.shape[1]\n",
    "\n",
    "#grad_vector = a.T.reshape(-1)\n",
    "grad_vector = a.reshape(a.shape[0]*a.shape[1])\n",
    "\n",
    "d_grad_vector = cuda.to_device(grad_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matvec_kernel(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_grad_vector[(pd)*n +qd]*d_grad_vector[(pn)*n + qn] \n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_grad_vector, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        pd, pn = divmod(np.int32(idx), n)\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*d_grad_vector[(jnd//m)*n +pd]*d_grad_vector[(jnd%m)*n + pn]  #grad_vector[(q // m)*n +p // n]*grad_vector[(q % m)*n + p % n]\n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 1\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    print (\"rmatvec\")\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 1\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_grad_vector, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n",
      "Performing SVD...\n",
      "rmatvec\n",
      "matvec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "matvec\n",
      "rmatvec\n",
      "rmatvec\n",
      "rmatvec\n"
     ]
    }
   ],
   "source": [
    "linop_v = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n",
    "#right = torch.rand(m*m)\n",
    "#resr_2 = linop_v.rmatvec(right)\n",
    "\n",
    "print(\"Performing SVD...\", flush=True)\n",
    "v, s, u = svds(linop_v, k = 3, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00514201, 0.00307254, 0.00307254], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_matrix = torch.outer(grad_vector,grad_vector)\n",
    "permuted_fisher_matrix = reshape_and_permute(fisher_matrix, m, n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76467013"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(fisher_matrix-np.kron(B1, C1))/np.linalg.norm(fisher_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A1 = cuda.to_device(permuted_fisher_matrix)\n",
    "@cuda.jit\n",
    "def matvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute matvec operation (A * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    #pd, pn = divmod(np.int32(idx), m)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            sum_ += x[jnd]*d_A1[np.int32(idx)][jnd]\n",
    "        res[idx] = sum_\n",
    "        \n",
    "@cuda.jit\n",
    "def rmatvec_kernel(d_A1, x, res, m, n):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute rmatvec operation (A.T * x).\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < res.size:  # Each thread computes one element of the result\n",
    "        sum_ = 0.0\n",
    "        #pd, pn = divmod(np.int32(idx), m)\n",
    "        for jnd in range(x.size):\n",
    "            #qd, qn = divmod(jnd, n)\n",
    "            #jnd, idx\n",
    "            sum_ += x[jnd]*d_A1[jnd][np.int32(idx)]\n",
    "        res[idx] = sum_\n",
    "\n",
    "def matvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch matvec_kernel.\n",
    "    \"\"\"\n",
    "    print (\"matvec\")\n",
    "    x = x.ravel()\n",
    "    res = np.zeros((m**2), dtype=np.float32)\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (m**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((m**2), dtype=np.float32)\n",
    "\n",
    "    matvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n",
    "\n",
    "def rmatvec_item_custom(x):\n",
    "    \"\"\"\n",
    "    Host function to launch rmatvec_kernel.\n",
    "    \"\"\"\n",
    "    res = np.zeros((n**2), dtype=np.float32)\n",
    "    x = x.ravel()\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (n**2 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    #d_grad_vector = cuda.to_device(grad_vector)\n",
    "    d_x = cuda.to_device(x)\n",
    "    d_res = cuda.device_array((n**2), dtype=np.float32)\n",
    "\n",
    "    rmatvec_kernel[blocks_per_grid, threads_per_block](d_A1, d_x, d_res, m, n)\n",
    "\n",
    "    # Copy result back to host\n",
    "    res = d_res.copy_to_host()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matvec\n",
      "Operator created\n",
      "Performing SVD...\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n",
      "matvec\n"
     ]
    }
   ],
   "source": [
    "linop_m = LinearOperator(\n",
    "    shape=(m**2, n**2),\n",
    "    matvec=matvec_item_custom,\n",
    "    rmatvec=rmatvec_item_custom\n",
    ")\n",
    "print(\"Operator created\", flush=True)\n",
    "\n",
    "print(\"Performing SVD...\", flush=True)\n",
    "v, s, u = svds(linop_m, k = 10, return_singular_vectors=True)\n",
    "s = np.sort(s)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00514201, 0.00307254, 0.00307254, 0.00183595, 0.00151782,\n",
       "       0.00151782, 0.00116446, 0.00116446, 0.00096295, 0.00096295],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76467013"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = s[0] * u[-1, :].reshape(n, n)\n",
    "B1 = v[:, -1].reshape(m, m)\n",
    "np.linalg.norm(fisher_matrix-np.kron(B1, C1))/np.linalg.norm(fisher_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-video_vika]",
   "language": "python",
   "name": "conda-env-.mlspace-video_vika-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
